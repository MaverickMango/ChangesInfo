diff --git a/LICENSE.txt b/LICENSE.txt
new file mode 100644
index 0000000..261eeb9
--- /dev/null
+++ b/LICENSE.txt
@@ -0,0 +1,201 @@
+                                 Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
+   APPENDIX: How to apply the Apache License to your work.
+
+      To apply the Apache License to your work, attach the following
+      boilerplate notice, with the fields enclosed by brackets "[]"
+      replaced with your own identifying information. (Don't include
+      the brackets!)  The text should be enclosed in the appropriate
+      comment syntax for the file format. We also recommend that a
+      file or class name and description of purpose be included on the
+      same "printed page" as the copyright notice for easier
+      identification within third-party archives.
+
+   Copyright [yyyy] [name of copyright owner]
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
diff --git a/NOTICE.txt b/NOTICE.txt
new file mode 100644
index 0000000..4f76aca
--- /dev/null
+++ b/NOTICE.txt
@@ -0,0 +1,5 @@
+Apache Commons Compress
+Copyright 2002-2004 The Apache Software Foundation
+
+This product includes software developed by
+The Apache Software Foundation (http://www.apache.org/).
diff --git a/checkstyle.xml b/checkstyle.xml
new file mode 100644
index 0000000..1ddc6e0
--- /dev/null
+++ b/checkstyle.xml
@@ -0,0 +1,175 @@
+<?xml version="1.0"?>
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one or more
+   contributor license agreements.  See the NOTICE file distributed with
+   this work for additional information regarding copyright ownership.
+   The ASF licenses this file to You under the Apache License, Version 2.0
+   (the "License"); you may not use this file except in compliance with
+   the License.  You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+-->
+<!DOCTYPE module PUBLIC
+    "-//Puppy Crawl//DTD Check Configuration 1.1//EN"
+    "http://www.puppycrawl.com/dtds/configuration_1_1.dtd">
+
+<!--
+  Checkstyle checks configured for Maven.
+-->
+
+<module name="Checker">
+
+    <!-- Checks that a package.html file exists for each package.     -->
+    <!-- See http://checkstyle.sf.net/config_javadoc.html#PackageHtml -->
+    <module name="PackageHtml"/>
+
+    <!-- Checks whether files end with a new line.                        -->
+    <!-- See http://checkstyle.sf.net/config_misc.html#NewlineAtEndOfFile -->
+    <module name="NewlineAtEndOfFile"/>
+
+    <!-- Checks that property files contain the same keys.         -->
+    <!-- See http://checkstyle.sf.net/config_misc.html#Translation -->
+    <module name="Translation"/>
+
+    <module name="TreeWalker">
+
+        <property name="cacheFile" value="${checkstyle.cache.file}"/>
+
+        <!-- ************************************************************** -->
+        <!-- Checks that are different from the sun coding conventions ones -->
+        <!-- ************************************************************** -->
+        <module name="Header">
+            <property name="headerFile" value="license-header.txt"/>
+        </module>
+        <property name="tabWidth" value="4"/>
+        <module name="LeftCurly">
+          <property name="option" value="eol"/>
+        </module>
+        <module name="RightCurly">
+          <property name="option" value="alone"/>
+        </module>
+        <module name="LineLength">
+          <property name="max" value="132"/>
+        </module>
+        <module name="MethodLength">
+          <property name="max" value="175"/>
+        </module>
+        <!-- No Paren pad check
+        <module name="ParenPad"/>
+        -->
+        <module name="ConstantName">
+          <property name="format" value="log|^[a-zA-Z][a-zA-Z0-9_]*$"/>
+        </module>
+        
+        <!-- ************************************************************** -->
+        <!-- Default Sun coding conventions checks                          -->
+        <!-- ************************************************************** -->
+
+        <!-- Checks for Javadoc comments.                     -->
+        <!-- See http://checkstyle.sf.net/config_javadoc.html -->
+        <module name="JavadocMethod"/>
+        <module name="JavadocType"/>
+        <module name="JavadocVariable"/>
+
+
+        <!-- Checks for Naming Conventions.                  -->
+        <!-- See http://checkstyle.sf.net/config_naming.html -->
+        <module name="LocalFinalVariableName"/>
+        <module name="LocalVariableName"/>
+        <module name="MethodName"/>
+        <module name="PackageName"/>
+        <module name="ParameterName"/>
+        <module name="StaticVariableName"/>
+        <module name="TypeName"/>
+        <module name="MemberName"/>
+
+        <!-- Checks for imports                              -->
+        <!-- See http://checkstyle.sf.net/config_import.html -->
+        <module name="AvoidStarImport"/>
+        <module name="IllegalImport"/> <!-- defaults to sun.* packages -->
+        <module name="RedundantImport"/>
+        <module name="UnusedImports"/>
+
+
+        <!-- Checks for Size Violations.                    -->
+        <!-- See http://checkstyle.sf.net/config_sizes.html -->
+        <module name="FileLength"/>
+        <module name="ParameterNumber"/>
+
+
+        <!-- Checks for whitespace                               -->
+        <!-- See http://checkstyle.sf.net/config_whitespace.html -->
+        <module name="EmptyForIteratorPad"/>
+        <module name="NoWhitespaceAfter"/>
+        <module name="NoWhitespaceBefore"/>
+        <module name="OperatorWrap"/>
+        <module name="TabCharacter"/>
+        <module name="WhitespaceAfter"/>
+        <module name="WhitespaceAround"/>
+
+
+        <!-- Modifier Checks                                    -->
+        <!-- See http://checkstyle.sf.net/config_modifiers.html -->
+        <module name="ModifierOrder"/>
+        <module name="RedundantModifier"/>
+
+
+        <!-- Checks for blocks. You know, those {}'s         -->
+        <!-- See http://checkstyle.sf.net/config_blocks.html -->
+        <module name="AvoidNestedBlocks"/>
+        <module name="EmptyBlock"/>
+        
+        <module name="NeedBraces"/>
+
+
+        <!-- Checks for common coding problems               -->
+        <!-- See http://checkstyle.sf.net/config_coding.html -->
+        <module name="AvoidInlineConditionals"/>
+        <module name="DoubleCheckedLocking"/>
+        <module name="EmptyStatement"/>
+        <module name="EqualsHashCode"/>
+        <module name="HiddenField"/>
+        <module name="IllegalInstantiation"/>
+        <module name="InnerAssignment"/>
+        <module name="MagicNumber"/>
+        <module name="MissingSwitchDefault"/>
+        <module name="RedundantThrows">
+            <property name="allowUnchecked" value="true"/>   <!-- DISABLED -->
+            <property name="allowSubclasses" value="true"/>   <!-- DISABLED -->
+        </module>
+        <module name="SimplifyBooleanExpression"/>
+        <module name="SimplifyBooleanReturn"/>
+
+        <!-- Checks for class design                         -->
+        <!-- See http://checkstyle.sf.net/config_design.html -->
+        <module name="DesignForExtension">
+            <property name="severity" value="ignore"/>   <!-- DISABLED -->
+        </module>
+        <module name="FinalClass"/>
+        <module name="HideUtilityClassConstructor"/>
+        <module name="InterfaceIsType"/>
+        <module name="VisibilityModifier"/>
+
+
+        <!-- Miscellaneous other checks.                   -->
+        <!-- See http://checkstyle.sf.net/config_misc.html -->
+        <module name="ArrayTypeStyle"/>
+        <module name="FinalParameters">
+            <property name="severity" value="ignore"/>   <!-- DISABLED -->
+        </module>
+        <module name="GenericIllegalRegexp">
+            <property name="format" value="\s+$"/>
+            <property name="message" value="Line has trailing spaces."/>
+        </module>
+        <module name="TodoComment"/>
+        <module name="UpperEll"/>
+
+    </module>
+
+</module>
diff --git a/license-header.txt b/license-header.txt
new file mode 100644
index 0000000..7220975
--- /dev/null
+++ b/license-header.txt
@@ -0,0 +1,18 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
\ No newline at end of file
diff --git a/pom.xml b/pom.xml
new file mode 100644
index 0000000..70f9f46
--- /dev/null
+++ b/pom.xml
@@ -0,0 +1,107 @@
+<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
+         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
+  <modelVersion>4.0.0</modelVersion>
+  <parent>
+    <groupId>org.apache.commons</groupId>
+    <artifactId>commons-sandbox-parent</artifactId>
+    <version>4</version>
+  </parent>
+
+  <artifactId>commons-compress</artifactId>
+  <version>1.0-SNAPSHOT</version>
+  <name>Commons Compress (Sandbox)</name>
+  <url>http://commons.apache.org/sandbox/compress/</url>
+  <description>Commons Compress is a component that contains Tar, Zip and BZip2 packages</description>
+  
+  <dependencies>
+    <dependency>
+      <groupId>junit</groupId>
+      <artifactId>junit</artifactId>
+      <version>3.8.1</version>
+      <scope>test</scope>
+    </dependency>
+  </dependencies>
+
+  <developers>
+    <developer>
+      <!-- In that I moved them to their new location -->
+      <name>Henri Yandell</name>
+      <id>bayard</id>
+      <email>bayard@apache.org</email>
+      <organization></organization>
+      <roles>
+        <role>Java Developer</role>
+      </roles>
+    </developer>
+    <developer>
+      <name>Dirk Verbeeck</name>
+      <id>dirkv</id>
+      <email></email>
+      <organization></organization>
+      <roles>
+        <role>Java Developer</role>
+      </roles>
+    </developer>
+  </developers>
+    
+  <scm>
+    <connection>scm:svn:http://svn.apache.org/repos/asf/commons/sandbox/compress/trunk</connection>
+    <developerConnection>scm:svn:https://svn.apache.org/repos/asf/commons/sandbox/compress/trunk</developerConnection>
+    <url>http://svn.apache.org/repos/asf/commons/sandbox/compress/trunk</url>
+  </scm>
+
+  <distributionManagement>
+    <site>
+      <id>website</id>
+      <name>Apache Website</name>
+      <url>scp://people.apache.org/www/commons.apache.org/sandbox/compress/</url>
+    </site>
+  </distributionManagement>
+
+  <properties>
+    <commons.componentid>compress</commons.componentid>
+    <commons.jira.componentid>12311183</commons.jira.componentid>
+  </properties> 
+
+  <build>
+      <sourceDirectory>src/main/java</sourceDirectory>
+      <testSourceDirectory>src/test/test</testSourceDirectory> 
+
+    <!-- turn off cobertura until we figure out why it's hanging -->
+    <plugins>
+      <plugin>
+        <groupId>org.codehaus.mojo</groupId>
+        <artifactId>cobertura-maven-plugin</artifactId>
+        <configuration>
+          <instrumentation>
+            <excludes>
+            <exclude>org/apache/commons/compress/bzip2/**/*.class</exclude>
+            <exclude>org/apache/commons/compress/compressors/bzip2/**/*.class</exclude>
+            </excludes>
+          </instrumentation>
+        </configuration>
+        <executions>
+          <execution>
+            <goals>
+              <goal>clean</goal>
+            </goals>
+          </execution>
+        </executions>
+      </plugin>
+    </plugins>
+      
+  </build>
+
+  <reporting>
+    <plugins>
+      <plugin>
+        <groupId>org.apache.maven.plugins</groupId>
+        <artifactId>maven-checkstyle-plugin</artifactId>
+        <configuration>
+          <configLocation>checkstyle.xml</configLocation>
+        </configuration>
+      </plugin>
+    </plugins>
+  </reporting>
+
+</project>
diff --git a/project.properties b/project.properties
new file mode 100644
index 0000000..6c37c76
--- /dev/null
+++ b/project.properties
@@ -0,0 +1,54 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+maven.repo.remote=http://repo1.maven.org/maven
+
+maven.xdoc.jsl=../commons-build/commons-site.jsl
+maven.xdoc.date=bottom
+maven.xdoc.poweredby.image=maven-feather.png
+maven.xdoc.version=${pom.currentVersion}
+maven.xdoc.developmentProcessUrl=http://commons.apache.org/charter.html
+maven.xdoc.includeProjectDocumentation=yes
+
+maven.checkstyle.properties = checkstyle.xml
+
+# Compile targets
+maven.compile.source=1.4
+maven.compile.target=1.4
+
+# Jar Manifest Additional Attributes
+maven.jar.manifest.attributes.list=Implementation-Vendor-Id,X-Compile-Source-JDK,X-Compile-Target-JDK
+maven.jar.manifest.attribute.Implementation-Vendor-Id=org.apache
+maven.jar.manifest.attribute.X-Compile-Source-JDK=${maven.compile.source}
+maven.jar.manifest.attribute.X-Compile-Target-JDK=${maven.compile.target}
+
+# uncomment the next line to work in offline mode (no jar download & no linkcheck)
+#maven.mode.online=
+maven.changelog.factory=org.apache.maven.svnlib.SvnChangeLogFactory
+
+maven.javadoc.author=false
+maven.javadoc.links=http://java.sun.com/products/jdk/1.4/docs/api,http://commons.apache.org/dbcp/apidocs
+
+maven.compile.debug=on
+maven.compile.deprecation=off
+maven.compile.optimize=off
+
+maven.jarResources.basedir=src/java
+maven.jar.excludes=**/package.html
+maven.junit.fork=true
+maven.junit.sysproperties=org.xml.sax.driver
+org.xml.sax.driver=org.apache.xerces.parsers.SAXParser
+
+clover.excludes=**/Test*.java
diff --git a/project.xml b/project.xml
new file mode 100644
index 0000000..711de4d
--- /dev/null
+++ b/project.xml
@@ -0,0 +1,74 @@
+<?xml version="1.0"?>
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one or more
+   contributor license agreements.  See the NOTICE file distributed with
+   this work for additional information regarding copyright ownership.
+   The ASF licenses this file to You under the Apache License, Version 2.0
+   (the "License"); you may not use this file except in compliance with
+   the License.  You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+-->
+<project>
+  <extend>../commons-build/sandbox-project.xml</extend>
+  <name>Commons Compress</name>
+  <id>commons-compress</id>
+  <logo>/images/compress-logo-white.png</logo>
+  <inceptionYear>2002</inceptionYear>
+  <shortDescription>Commons Compress</shortDescription>
+  <description>
+    Commons Compress is a component that contains Tar, Zip and BZip2 packages.
+  </description>
+  <currentVersion>0.1-dev</currentVersion>
+  <issueTrackingUrl>http://issues.apache.org/bugzilla/</issueTrackingUrl>
+  <siteAddress>cvs.apache.org</siteAddress>
+  <logo></logo>
+  
+  <versions>
+  </versions>
+  <branches>
+  </branches>
+
+  <developers>
+    <developer>
+      <!-- In that I moved them to their new location -->
+      <name>Henri Yandell</name>
+      <id>bayard</id>
+      <email>bayard@apache.org</email>
+      <organization></organization>
+      <roles>
+        <role>Java Developer</role>
+      </roles>
+    </developer>
+    <developer>
+      <name>Dirk Verbeeck</name>
+      <id>dirkv</id>
+      <email></email>
+      <organization></organization>
+      <roles>
+        <role>Java Developer</role>
+      </roles>
+    </developer>
+  </developers>
+    
+  <dependencies>
+    <dependency>
+      <id>junit</id>
+      <version>3.8.1</version>
+    </dependency>
+  </dependencies>
+
+  <build>
+    <unitTest>
+      <includes>
+        <include>**/*Test*</include>
+      </includes>
+    </unitTest>
+  </build>
+</project>
diff --git a/src/main/java/org/apache/commons/compress/archivers/ArchiveEntry.java b/src/main/java/org/apache/commons/compress/archivers/ArchiveEntry.java
new file mode 100644
index 0000000..6fa60a3
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/ArchiveEntry.java
@@ -0,0 +1,32 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers;
+
+/**
+ * Represents an entry of an archive.
+ */
+public interface ArchiveEntry {
+	/**
+	 * Returns the name of this entry.
+	 * @return the name of this entry
+	 */
+	public String getName();
+	
+	public long getSize();
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/ArchiveException.java b/src/main/java/org/apache/commons/compress/archivers/ArchiveException.java
new file mode 100644
index 0000000..c6e91ec
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/ArchiveException.java
@@ -0,0 +1,40 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers;
+
+/**
+ * Archiver related Exception 
+ */
+public class ArchiveException extends Exception {
+
+	private static final long serialVersionUID = 3256440322136748848L;
+
+	public ArchiveException() {
+		super();
+	}
+
+	public ArchiveException(String message) {
+		super(message);
+	}
+	
+	public ArchiveException(String message, Exception e) {
+		super(message);
+		this.initCause(e);
+	}
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/ArchiveInputStream.java b/src/main/java/org/apache/commons/compress/archivers/ArchiveInputStream.java
new file mode 100644
index 0000000..ddfaec5
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/ArchiveInputStream.java
@@ -0,0 +1,32 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers;
+
+import java.io.IOException;
+import java.io.InputStream;
+
+public abstract class ArchiveInputStream extends InputStream {
+    /**
+     * Returns the next Archive Entry in this Stream.
+     * @return the next entry
+     * @throws IOException if the next entry could not be read
+     */
+    public abstract ArchiveEntry getNextEntry() throws IOException;
+    
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/ArchiveOutputStream.java b/src/main/java/org/apache/commons/compress/archivers/ArchiveOutputStream.java
new file mode 100644
index 0000000..69753cc
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/ArchiveOutputStream.java
@@ -0,0 +1,29 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers;
+
+import java.io.IOException;
+import java.io.OutputStream;
+
+public abstract class ArchiveOutputStream extends OutputStream {
+
+	public abstract void putArchiveEntry(ArchiveEntry entry) throws IOException;
+	
+    public abstract void closeArchiveEntry() throws IOException;
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/ArchiveStreamFactory.java b/src/main/java/org/apache/commons/compress/archivers/ArchiveStreamFactory.java
new file mode 100644
index 0000000..680fa65
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/ArchiveStreamFactory.java
@@ -0,0 +1,169 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.lang.reflect.Constructor;
+import java.lang.reflect.InvocationTargetException;
+import java.lang.reflect.Method;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.Map;
+
+import org.apache.commons.compress.archivers.ar.ArArchiveInputStream;
+import org.apache.commons.compress.archivers.ar.ArArchiveOutputStream;
+import org.apache.commons.compress.archivers.jar.JarArchiveInputStream;
+import org.apache.commons.compress.archivers.jar.JarArchiveOutputStream;
+import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;
+import org.apache.commons.compress.archivers.tar.TarArchiveOutputStream;
+import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;
+import org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream;
+import org.apache.commons.compress.utils.ReflectionUtils;
+
+public class ArchiveStreamFactory {
+
+	final Map inputStreamClasses = new HashMap();
+	final Map outputStreamClasses = new HashMap();
+	
+	public ArchiveStreamFactory() throws ArchiveException {
+		registerArchiveInputStream("zip", ZipArchiveInputStream.class);
+		registerArchiveOutputStream("zip", ZipArchiveOutputStream.class);
+
+        registerArchiveInputStream("tar", TarArchiveInputStream.class);
+        registerArchiveOutputStream("tar", TarArchiveOutputStream.class);
+
+        registerArchiveInputStream("ar", ArArchiveInputStream.class);
+        registerArchiveOutputStream("ar", ArArchiveOutputStream.class);
+
+        registerArchiveInputStream("jar", JarArchiveInputStream.class);		
+        registerArchiveOutputStream("jar", JarArchiveOutputStream.class);
+	}
+	
+	
+	public void registerArchiveInputStream( final String name, final Class stream ) throws ArchiveException {
+		if (ArchiveInputStream.class.isAssignableFrom(stream) && !(stream.isInterface())) {
+			inputStreamClasses.put(name, stream);
+        } else {
+            throw new ArchiveException("Archive does not implement the ArchiveInputStream interface.");
+        }	
+	}
+
+	public void registerArchiveOutputStream( final String name, final Class stream ) throws ArchiveException {
+		ReflectionUtils.registerClazz(outputStreamClasses, name, ArchiveOutputStream.class, stream);		
+		if (ArchiveOutputStream.class.isAssignableFrom(stream) && !(stream.isInterface())) {
+			outputStreamClasses.put(name, stream);
+        } else {
+            throw new ArchiveException("Archive does not implement the ArchiveOutputStream interface.");
+        }
+	}
+	
+    public ArchiveInputStream createArchiveInputStream( final String archiverName, final InputStream out ) throws ArchiveException {
+        try {
+            final Class clazz = (Class) inputStreamClasses.get(archiverName);
+
+            if (clazz == null) {
+            	throw new ArchiveException("ArchiverFactory could not create instance");
+            }
+
+            final Class[] params = { InputStream.class };
+            final Constructor constructor = clazz.getConstructor(params);
+            final Object[] initargs = { out };
+            return (ArchiveInputStream) constructor.newInstance(initargs);
+        } catch (InstantiationException e) {
+            throw new ArchiveException("ArchiverFactory could not create instance", e);
+        } catch (IllegalAccessException e) {
+            throw new ArchiveException("ArchiverFactory could not create instance", e);
+        } catch (SecurityException e) {
+            throw new ArchiveException("ArchiverFactory could not create instance", e);
+        } catch (NoSuchMethodException e) {
+            throw new ArchiveException("ArchiverFactory could not create instance", e);
+        } catch (IllegalArgumentException e) {
+            throw new ArchiveException("ArchiverFactory could not create instance", e);
+        } catch (InvocationTargetException e) {
+            throw new ArchiveException("ArchiverFactory could not create instance", e);
+        }
+    }
+
+    public ArchiveOutputStream createArchiveOutputStream( final String archiverName, final OutputStream out ) throws ArchiveException {
+        try {
+            final Class clazz = (Class) outputStreamClasses.get(archiverName);
+            
+            if (clazz == null) {
+            	throw new ArchiveException("ArchiverFactory could not create instance");
+            }
+            
+            final Class[] params = { OutputStream.class };
+            final Constructor constructor = clazz.getConstructor(params);
+            final Object[] initargs = { out };
+            return (ArchiveOutputStream) constructor.newInstance(initargs);
+        } catch (InstantiationException e) {
+            throw new ArchiveException("ArchiverFactory could not create instance", e);
+        } catch (IllegalAccessException e) {
+            throw new ArchiveException("ArchiverFactory could not create instance", e);
+        } catch (SecurityException e) {
+            throw new ArchiveException("ArchiverFactory could not create instance", e);
+        } catch (NoSuchMethodException e) {
+            throw new ArchiveException("ArchiverFactory could not create instance", e);
+        } catch (IllegalArgumentException e) {
+            throw new ArchiveException("ArchiverFactory could not create instance", e);
+        } catch (InvocationTargetException e) {
+            throw new ArchiveException("ArchiverFactory could not create instance", e);
+        }
+    }
+
+    public ArchiveInputStream createArchiveInputStream( final InputStream input ) throws IOException {
+
+		final byte[] signature = new byte[12];
+		input.mark(signature.length);
+		input.read(signature);
+		// reset not supported exception?
+		input.reset();
+
+//		for (int i = 0; i < signature.length; i++) {
+//			System.out.print(Integer.toHexString(signature[i]));
+//			System.out.print(",");
+//		}
+//		System.out.println("");
+		
+		for (Iterator it = inputStreamClasses.values().iterator(); it.hasNext();) {
+			final Class clazz = (Class) it.next();
+			try {
+				final Method method = clazz.getMethod("matches", new Class[] { byte[].class });
+				
+				final Object result = method.invoke(null, new Object[] { signature } );
+				
+				if (result.equals(Boolean.TRUE)) {
+		            final Class[] params = { InputStream.class };
+		            final Constructor constructor = clazz.getConstructor(params);
+		            final Object[] initargs = { input };
+		            return (ArchiveInputStream) constructor.newInstance(initargs);					
+				}
+			} catch (SecurityException e) {
+			} catch (NoSuchMethodException e) {
+			} catch (IllegalArgumentException e) {
+			} catch (IllegalAccessException e) {
+			} catch (InvocationTargetException e) {
+			} catch (InstantiationException e) {
+			}
+		}
+		return null;
+	}
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveEntry.java b/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveEntry.java
new file mode 100644
index 0000000..0582e11
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveEntry.java
@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.ar;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+
+public class ArArchiveEntry implements ArchiveEntry {
+
+	private final String name;
+	private int userId;
+	private int groupId;
+	private int mode;
+	private long lastModified;
+	private long length;
+
+	public ArArchiveEntry(String name, long length) {
+		this(name, length, 0, 0, 33188, System.currentTimeMillis());
+	}
+	
+	public ArArchiveEntry(String name, long length, int userId, int groupId, int mode, long lastModified) {
+		this.name = name;
+		this.length = length;
+		this.userId = userId;
+		this.groupId = groupId;
+		this.mode = mode;
+		this.lastModified = lastModified;
+	}
+
+	public long getSize() {
+		return this.getLength();
+	}
+	
+	public String getName() {
+		return name;
+	}
+	
+	public int getUserId() {
+		return userId;
+	}
+	
+	public int getGroupId() {
+		return groupId;
+	}
+	
+	public int getMode() {
+		return mode;
+	}
+	
+	public long getLastModified() {
+		return lastModified;
+	}
+	
+	public long getLength() {
+		return length;
+	}
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveInputStream.java b/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveInputStream.java
new file mode 100644
index 0000000..5fb74c6
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveInputStream.java
@@ -0,0 +1,134 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.ar;
+
+import java.io.IOException;
+import java.io.InputStream;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.ArchiveInputStream;
+
+public class ArArchiveInputStream extends ArchiveInputStream {
+
+	private final InputStream input;
+	private long offset = 0;
+	
+	public ArArchiveInputStream( final InputStream pInput ) {
+		input = pInput;
+	}
+	
+	public ArchiveEntry getNextEntry() throws IOException {
+		
+		if (offset == 0) {
+			final byte[] expected = "!<arch>\n".getBytes();			
+			final byte[] realized = new byte[expected.length]; 
+			final int read = input.read(realized);
+			if (read != expected.length) {
+				throw new IOException("failed to read header");
+			}
+			for (int i = 0; i < expected.length; i++) {
+				if (expected[i] != realized[i]) {
+					throw new IOException("invalid header " + new String(realized));
+				}
+			}
+		}
+
+		if (input.available() == 0) {
+			return null;
+		}
+				
+		if (offset % 2 != 0) {
+			read();
+		}
+
+		final byte[] name = new byte[16];
+		final byte[] lastmodified = new byte[12];
+		final byte[] userid = new byte[6];
+		final byte[] groupid = new byte[6];
+		final byte[] filemode = new byte[8];
+		final byte[] length = new byte[10];
+		
+		read(name);
+		read(lastmodified);
+		read(userid);
+		read(groupid);
+		read(filemode);
+		read(length);
+
+		{
+			final byte[] expected = "`\012".getBytes();			
+			final byte[] realized = new byte[expected.length]; 
+			final int read = input.read(realized);
+			if (read != expected.length) {
+				throw new IOException("failed to read entry header");
+			}
+			for (int i = 0; i < expected.length; i++) {
+				if (expected[i] != realized[i]) {
+					throw new IOException("invalid entry header. not read the content?");
+				}
+			}
+		}
+		
+		return new ArArchiveEntry(new String(name).trim(), Long.parseLong(new String(length).trim()));
+	
+	}
+	
+	
+	public int read() throws IOException {
+		final int ret = input.read();
+		offset++;
+		return ret;
+	}
+
+	public int read(byte[] b, int off, int len) throws IOException {
+		return this.input.read(b, off, len);
+	}
+	
+	public static boolean matches( byte[] signature ) {
+		// 3c21 7261 6863 0a3e
+    	
+    	if (signature[0] != 0x21) {
+    		return false;
+    	}
+    	if (signature[1] != 0x3c) {
+    		return false;
+    	}
+    	if (signature[2] != 0x61) {
+    		return false;
+    	}
+    	if (signature[3] != 0x72) {
+    		return false;
+    	}
+    	if (signature[4] != 0x63) {
+    		return false;
+    	}
+    	if (signature[5] != 0x68) {
+    		return false;
+    	}
+    	if (signature[6] != 0x3e) {
+    		return false;
+    	}
+    	if (signature[7] != 0x0a) {
+    		return false;
+    	}
+    	
+    	return true;
+	}
+
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveOutputStream.java b/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveOutputStream.java
new file mode 100644
index 0000000..f362f4c
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/ar/ArArchiveOutputStream.java
@@ -0,0 +1,174 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.ar;
+
+import java.io.IOException;
+import java.io.OutputStream;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.ArchiveOutputStream;
+
+public class ArArchiveOutputStream extends ArchiveOutputStream {
+
+	private final OutputStream out;
+	private long archiveOffset = 0;
+	private long entryOffset = 0;
+	private ArArchiveEntry prevEntry;
+
+	public ArArchiveOutputStream( final OutputStream pOut ) {
+		out = pOut;
+		
+	}
+
+	private long writeArchiveHeader() throws IOException {		
+		final String header = "!<arch>\n";
+		out.write(header.getBytes());
+		return header.length();
+	}
+
+	public void closeArchiveEntry() throws IOException {
+		if ((entryOffset % 2) != 0) {
+        	write('\n');
+        	archiveOffset++;
+        }		
+	}
+	
+	public void putArchiveEntry( final ArchiveEntry pEntry ) throws IOException {
+		ArArchiveEntry pArEntry = (ArArchiveEntry)pEntry;
+		if (prevEntry == null) {
+			archiveOffset += writeArchiveHeader();			
+		} else {
+			if (prevEntry.getLength() != entryOffset) {
+				throw new IOException("length does not match entry (" + prevEntry.getLength() + " != " + entryOffset);
+			}
+			
+			closeArchiveEntry();
+		}
+		
+		prevEntry = pArEntry;
+		
+		archiveOffset += writeEntryHeader(pArEntry);
+
+		entryOffset = 0;
+	}
+
+	private long fill( final long pOffset, final long pNewOffset, final char pFill ) throws IOException { 
+		final long diff = pNewOffset - pOffset;
+	
+		if (diff > 0) {
+			for (int i = 0; i < diff; i++) {
+				write(pFill);
+			}
+		}
+
+		return pNewOffset;
+	}
+	
+	private long write( final String data ) throws IOException {
+		final byte[] bytes = data.getBytes("ascii");
+		write(bytes);
+		return bytes.length;
+	}
+	
+	private long writeEntryHeader( final ArArchiveEntry pEntry ) throws IOException {
+		
+		long offset = 0;
+		
+		final String n = pEntry.getName();
+		if (n.length() > 16) {
+			throw new IOException("filename too long");
+		}		
+		offset += write(n);
+		
+		offset = fill(offset, 16, ' ');
+		final String m = "" + (pEntry.getLastModified() / 1000);
+		if (m.length() > 12) {
+			throw new IOException("modified too long");
+		}		
+		offset += write(m);		
+
+		offset = fill(offset, 28, ' ');
+		final String u = "" + pEntry.getUserId();
+		if (u.length() > 6) {
+			throw new IOException("userid too long");
+		}		
+		offset += write(u);
+
+		offset = fill(offset, 34, ' ');
+		final String g = "" + pEntry.getGroupId();
+		if (g.length() > 6) {
+			throw new IOException("groupid too long");
+		}		
+		offset += write(g);
+
+		offset = fill(offset, 40, ' ');
+		final String fm = "" + Integer.toString(pEntry.getMode(), 8);
+		if (fm.length() > 8) {
+			throw new IOException("filemode too long");
+		}		
+		offset += write(fm);
+
+		offset = fill(offset, 48, ' ');
+		final String s = "" + pEntry.getLength();
+		if (s.length() > 10) {
+			throw new IOException("size too long");
+		}		
+		offset += write(s);
+
+		offset = fill(offset, 58, ' ');
+
+		offset += write("`\012");
+		
+		return offset;
+	}		
+	
+	public void write(int b) throws IOException {
+		out.write(b);
+		entryOffset++;
+	}
+
+	public void write(byte[] b, int off, int len) throws IOException {
+		out.write(b, off, len);
+		entryOffset += len;
+	}
+
+	public void write(byte[] b) throws IOException {
+		out.write(b);
+		entryOffset += b.length;
+	}
+
+	public void close() throws IOException {
+		closeArchiveEntry();
+		out.close();
+		prevEntry = null;
+	}
+
+	public String getDefaultFileExtension() {
+		return "ar";
+	}
+
+	public byte[] getHeader() {
+		// TODO Auto-generated method stub
+		return null;
+	}
+
+	public String getName() {
+		return "ar";
+	}
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/jar/JarArchiveEntry.java b/src/main/java/org/apache/commons/compress/archivers/jar/JarArchiveEntry.java
new file mode 100644
index 0000000..4853d82
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/jar/JarArchiveEntry.java
@@ -0,0 +1,59 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.jar;
+
+import java.security.cert.Certificate;
+import java.util.jar.Attributes;
+import java.util.jar.JarEntry;
+import java.util.zip.ZipEntry;
+import java.util.zip.ZipException;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;
+
+public class JarArchiveEntry extends ZipArchiveEntry implements ArchiveEntry {
+
+	private Attributes manifestAttributes = null;
+	private Certificate[] certificates = null; 
+	
+	public JarArchiveEntry(ZipEntry entry) throws ZipException {
+		super(entry);
+	}
+
+	public JarArchiveEntry(String name) {
+		super(name);
+	}
+
+	public JarArchiveEntry(ZipArchiveEntry entry) throws ZipException {
+		super(entry);
+	}
+
+	public JarArchiveEntry(JarEntry entry) throws ZipException {
+		super(entry);
+		
+	}
+
+	public Attributes getManifestAttributes() {
+		return manifestAttributes;
+	}
+
+	public Certificate[] getCertificates() {
+		return certificates;
+	}
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/jar/JarArchiveInputStream.java b/src/main/java/org/apache/commons/compress/archivers/jar/JarArchiveInputStream.java
new file mode 100644
index 0000000..61f111e
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/jar/JarArchiveInputStream.java
@@ -0,0 +1,68 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.jar;
+
+import java.io.IOException;
+import java.io.InputStream;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;
+import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;
+
+public class JarArchiveInputStream extends ZipArchiveInputStream {
+
+	public JarArchiveInputStream( final InputStream inputStream ) throws IOException {
+		super(inputStream);
+	}
+	
+	public ArchiveEntry getNextEntry() throws IOException {
+		return (ArchiveEntry)new JarArchiveEntry((ZipArchiveEntry)super.getNextEntry());
+	}
+	
+	public static boolean matches( byte[] signature ) {
+		// 4b50 0403 0014 0008
+
+    	if (signature[0] != 0x50) {
+    		return false;
+    	}
+    	if (signature[1] != 0x4b) {
+    		return false;
+    	}
+    	if (signature[2] != 0x03) {
+    		return false;
+    	}
+    	if (signature[3] != 0x04) {
+    		return false;
+    	}
+    	if (signature[4] != 0x14) {
+    		return false;
+    	}
+    	if (signature[5] != 0x00) {
+    		return false;
+    	}
+    	if (signature[6] != 0x08) {
+    		return false;
+    	}
+    	if (signature[7] != 0x00) {
+    		return false;
+    	}
+    	
+    	return true;
+	}
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/jar/JarArchiveOutputStream.java b/src/main/java/org/apache/commons/compress/archivers/jar/JarArchiveOutputStream.java
new file mode 100644
index 0000000..e6f6b5c
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/jar/JarArchiveOutputStream.java
@@ -0,0 +1,38 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.jar;
+
+import java.io.IOException;
+import java.io.OutputStream;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;
+import org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream;
+
+public class JarArchiveOutputStream extends ZipArchiveOutputStream {
+
+	public JarArchiveOutputStream( final OutputStream out ) {
+		super(out);
+	}
+
+	public void putArchiveEntry(ArchiveEntry entry) throws IOException {
+		// TODO special jar stuff
+		 super.putArchiveEntry((ZipArchiveEntry) entry);
+	}
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveEntry.java b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveEntry.java
new file mode 100644
index 0000000..a6c9310
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveEntry.java
@@ -0,0 +1,692 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.tar;
+
+import java.io.File;
+import java.util.Date;
+import java.util.Locale;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+
+/**
+ * This class represents an entry in a Tar archive. It consists of the entry's
+ * header, as well as the entry's File. Entries can be instantiated in one of
+ * three ways, depending on how they are to be used. <p>
+ *
+ * TarEntries that are created from the header bytes read from an archive are
+ * instantiated with the TarEntry( byte[] ) constructor. These entries will be
+ * used when extracting from or listing the contents of an archive. These
+ * entries have their header filled in using the header bytes. They also set the
+ * File to null, since they reference an archive entry not a file. <p>
+ *
+ * TarEntries that are created from Files that are to be written into an archive
+ * are instantiated with the TarEntry( File ) constructor. These entries have
+ * their header filled in using the File's information. They also keep a
+ * reference to the File for convenience when writing entries. <p>
+ *
+ * Finally, TarEntries can be constructed from nothing but a name. This allows
+ * the programmer to construct the entry by hand, for instance when only an
+ * InputStream is available for writing to the archive, and the header
+ * information is constructed from other information. In this case the header
+ * fields are set to defaults and the File is set to null. <p>
+ *
+ * The C structure for a Tar Entry's header is: <pre>
+ * struct header {
+ * char name[NAMSIZ];
+ * char mode[8];
+ * char uid[8];
+ * char gid[8];
+ * char size[12];
+ * char mtime[12];
+ * char chksum[8];
+ * char linkflag;
+ * char linkname[NAMSIZ];
+ * char magic[8];
+ * char uname[TUNMLEN];
+ * char gname[TGNMLEN];
+ * char devmajor[8];
+ * char devminor[8];
+ * } header;
+ * </pre>
+ *
+ * @author <a href="mailto:time@ice.com">Timothy Gerard Endres</a>
+ * @author <a href="mailto:stefano@apache.org">Stefano Mazzocchi</a>
+ * @author <a href="mailto:peter@apache.org">Peter Donald</a>
+ * @version $Revision$ $Date$
+ * @see TarInputStream
+ * @see TarArchiveOutputStream
+ */
+public class TarArchiveEntry implements ArchiveEntry {
+    /**
+     * The length of the name field in a header buffer.
+     */
+    public static final int NAMELEN = 100;
+
+    /**
+     * The entry's modification time.
+     */
+    private int m_checkSum;
+
+    /**
+     * The entry's group name.
+     */
+    private int m_devMajor;
+
+    /**
+     * The entry's major device number.
+     */
+    private int m_devMinor;
+
+    /**
+     * The entry's minor device number.
+     */
+    private File m_file;
+
+    /**
+     * The entry's user id.
+     */
+    private int m_groupID;
+
+    /**
+     * The entry's user name.
+     */
+    private StringBuffer m_groupName;
+
+    /**
+     * The entry's checksum.
+     */
+    private byte m_linkFlag;
+
+    /**
+     * The entry's link flag.
+     */
+    private StringBuffer m_linkName;
+
+    /**
+     * The entry's link name.
+     */
+    private StringBuffer m_magic;
+
+    /**
+     * The entry's size.
+     */
+    private long m_modTime;
+
+    /**
+     * The entry's name.
+     */
+    private int m_mode;
+
+    private StringBuffer m_name;
+
+    /**
+     * The entry's group id.
+     */
+    private long m_size;
+
+    /**
+     * The entry's permission mode.
+     */
+    private int m_userID;
+
+    /**
+     * The entry's magic tag.
+     */
+    private StringBuffer m_userName;
+
+    /**
+     * Construct an entry with only a name. This allows the programmer to
+     * construct the entry's header "by hand". File is set to null.
+     *
+     * @param name the name of the entry
+     */
+    public TarArchiveEntry( final String name )
+    {
+        this();
+
+        final boolean isDir = name.endsWith( "/" );
+
+        m_name = new StringBuffer( name );
+        m_mode = isDir ? 040755 : 0100644;
+        m_linkFlag = isDir ? TarConstants.LF_DIR : TarConstants.LF_NORMAL;
+        m_modTime = ( new Date() ).getTime() / 1000;
+        m_linkName = new StringBuffer( "" );
+        m_userName = new StringBuffer( "" );
+        m_groupName = new StringBuffer( "" );
+    }
+
+    /**
+     * Construct an entry with a name an a link flag.
+     *
+     * @param name Description of Parameter
+     * @param linkFlag Description of Parameter
+     */
+    public TarArchiveEntry( final String name, final byte linkFlag )
+    {
+        this( name );
+        m_linkFlag = linkFlag;
+    }
+
+    /**
+     * Construct an entry for a file. File is set to file, and the header is
+     * constructed from information from the file.
+     *
+     * @param file The file that the entry represents.
+     */
+    public TarArchiveEntry( final File file )
+    {
+        this();
+
+        m_file = file;
+
+        String name = file.getPath();
+
+        // Strip off drive letters!
+        final String osName =
+            System.getProperty( "os.name" ).toLowerCase( Locale.US );
+        if( -1 != osName.indexOf( "netware" ) )
+        {
+            if( name.length() > 2 )
+            {
+                final char ch1 = name.charAt( 0 );
+                final char ch2 = name.charAt( 1 );
+
+                if( ch2 == ':' &&
+                    ( ( ch1 >= 'a' && ch1 <= 'z' ) ||
+                    ( ch1 >= 'A' && ch1 <= 'Z' ) ) )
+                {
+                    name = name.substring( 2 );
+                }
+            }
+        }
+        else if( -1 != osName.indexOf( "netware" ) )
+        {
+            final int colon = name.indexOf( ':' );
+            if( colon != -1 )
+            {
+                name = name.substring( colon + 1 );
+            }
+        }
+
+        name = name.replace( File.separatorChar, '/' );
+
+        // No absolute pathnames
+        // Windows (and Posix?) paths can start with "\\NetworkDrive\",
+        // so we loop on starting /'s.
+        while( name.startsWith( "/" ) )
+        {
+            name = name.substring( 1 );
+        }
+
+        m_linkName = new StringBuffer( "" );
+        m_name = new StringBuffer( name );
+
+        if( file.isDirectory() )
+        {
+            m_mode = 040755;
+            m_linkFlag = TarConstants.LF_DIR;
+
+            if( m_name.charAt( m_name.length() - 1 ) != '/' )
+            {
+                m_name.append( "/" );
+            }
+        }
+        else
+        {
+            m_mode = 0100644;
+            m_linkFlag = TarConstants.LF_NORMAL;
+        }
+
+        m_size = file.length();
+        m_modTime = file.lastModified() / 1000;
+        m_checkSum = 0;
+        m_devMajor = 0;
+        m_devMinor = 0;
+    }
+
+    /**
+     * Construct an entry from an archive's header bytes. File is set to null.
+     *
+     * @param header The header bytes from a tar archive entry.
+     */
+    public TarArchiveEntry( final byte[] header )
+    {
+        this();
+        parseTarHeader( header );
+    }
+
+    /**
+     * Construct an empty entry and prepares the header values.
+     */
+    private TarArchiveEntry()
+    {
+        m_magic = new StringBuffer( TarConstants.TMAGIC );
+        m_name = new StringBuffer();
+        m_linkName = new StringBuffer();
+
+        String user = System.getProperty( "user.name", "" );
+        if( user.length() > 31 )
+        {
+            user = user.substring( 0, 31 );
+        }
+
+        m_userName = new StringBuffer( user );
+        m_groupName = new StringBuffer( "" );
+    }
+
+    /**
+     * Set this entry's group id.
+     *
+     * @param groupId This entry's new group id.
+     */
+    public void setGroupID( final int groupId )
+    {
+        m_groupID = groupId;
+    }
+
+    /**
+     * Set this entry's group id.
+     *
+     * @param groupId This entry's new group id.
+     * @deprecated Use setGroupID() instead
+     * @see #setGroupID(int)
+     */
+    public void setGroupId( final int groupId )
+    {
+        m_groupID = groupId;
+    }
+
+    /**
+     * Set this entry's group name.
+     *
+     * @param groupName This entry's new group name.
+     */
+    public void setGroupName( final String groupName )
+    {
+        m_groupName = new StringBuffer( groupName );
+    }
+
+    /**
+     * Set this entry's modification time. The parameter passed to this method
+     * is in "Java time".
+     *
+     * @param time This entry's new modification time.
+     */
+    public void setModTime( final long time )
+    {
+        m_modTime = time / 1000;
+    }
+
+    /**
+     * Set this entry's modification time.
+     *
+     * @param time This entry's new modification time.
+     */
+    public void setModTime( final Date time )
+    {
+        m_modTime = time.getTime() / 1000;
+    }
+
+    /**
+     * Set the mode for this entry
+     *
+     * @param mode The new Mode value
+     */
+    public void setMode( final int mode )
+    {
+        m_mode = mode;
+    }
+
+    /**
+     * Set this entry's name.
+     *
+     * @param name This entry's new name.
+     */
+    public void setName( final String name )
+    {
+        m_name = new StringBuffer( name );
+    }
+
+    /**
+     * Set this entry's file size.
+     *
+     * @param size This entry's new file size.
+     */
+    public void setSize( final long size )
+    {
+        m_size = size;
+    }
+
+    /**
+     * Set this entry's user id.
+     *
+     * @param userId This entry's new user id.
+     */
+    public void setUserID( final int userId )
+    {
+        m_userID = userId;
+    }
+
+    /**
+     * Set this entry's user id.
+     *
+     * @param userId This entry's new user id.
+     * @deprecated Use setUserID() instead
+     * @see #setUserID(int)
+     */
+    public void setUserId( final int userId )
+    {
+        m_userID = userId;
+    }
+
+    /**
+     * Set this entry's user name.
+     *
+     * @param userName This entry's new user name.
+     */
+    public void setUserName( final String userName )
+    {
+        m_userName = new StringBuffer( userName );
+    }
+
+    /**
+     * If this entry represents a file, and the file is a directory, return an
+     * array of TarEntries for this entry's children.
+     *
+     * @return An array of TarEntry's for this entry's children.
+     */
+    public TarArchiveEntry[] getDirectoryEntries()
+    {
+        if( null == m_file || !m_file.isDirectory() )
+        {
+            return new TarArchiveEntry[ 0 ];
+        }
+
+        final String[] list = m_file.list();
+        final TarArchiveEntry[] result = new TarArchiveEntry[ list.length ];
+
+        for( int i = 0; i < list.length; ++i )
+        {
+            result[ i ] = new TarArchiveEntry( new File( m_file, list[ i ] ) );
+        }
+
+        return result;
+    }
+
+    /**
+     * Get this entry's file.
+     *
+     * @return This entry's file.
+     */
+    public File getFile()
+    {
+        return m_file;
+    }
+
+    /**
+     * Get this entry's group id.
+     *
+     * @return This entry's group id.
+     * @deprecated Use getGroupID() instead
+     * @see #getGroupID()
+     */
+    public int getGroupId()
+    {
+        return m_groupID;
+    }
+
+    /**
+     * Get this entry's group id.
+     *
+     * @return This entry's group id.
+     */
+    public int getGroupID()
+    {
+        return m_groupID;
+    }
+
+    /**
+     * Get this entry's group name.
+     *
+     * @return This entry's group name.
+     */
+    public String getGroupName()
+    {
+        return m_groupName.toString();
+    }
+
+    /**
+     * Set this entry's modification time.
+     *
+     * @return The ModTime value
+     */
+    public Date getModTime()
+    {
+        return new Date( m_modTime * 1000 );
+    }
+
+    /**
+     * Get this entry's mode.
+     *
+     * @return This entry's mode.
+     */
+    public int getMode()
+    {
+        return m_mode;
+    }
+
+    /**
+     * Get this entry's name.
+     *
+     * @return This entry's name.
+     */
+    public String getName()
+    {
+        return m_name.toString();
+    }
+
+    /**
+     * Get this entry's file size.
+     *
+     * @return This entry's file size.
+     */
+    public long getSize()
+    {
+        return m_size;
+    }
+
+    /**
+     * Get this entry's checksum.
+     *
+     * @return This entry's checksum.
+     */
+    public int getCheckSum()
+    {
+        return m_checkSum;
+    }
+
+    /**
+     * Get this entry's user id.
+     *
+     * @return This entry's user id.
+     * @deprecated Use getUserID() instead
+     * @see #getUserID()
+     */
+    public int getUserId()
+    {
+        return m_userID;
+    }
+
+    /**
+     * Get this entry's user id.
+     *
+     * @return This entry's user id.
+     */
+    public int getUserID()
+    {
+        return m_userID;
+    }
+
+    /**
+     * Get this entry's user name.
+     *
+     * @return This entry's user name.
+     */
+    public String getUserName()
+    {
+        return m_userName.toString();
+    }
+
+    /**
+     * Determine if the given entry is a descendant of this entry. Descendancy
+     * is determined by the name of the descendant starting with this entry's
+     * name.
+     *
+     * @param desc Entry to be checked as a descendent of
+     * @return True if entry is a descendant of
+     */
+    public boolean isDescendent( final TarArchiveEntry desc )
+    {
+        return desc.getName().startsWith( getName() );
+    }
+
+    /**
+     * Return whether or not this entry represents a directory.
+     *
+     * @return True if this entry is a directory.
+     */
+    public boolean isDirectory()
+    {
+        if( m_file != null )
+        {
+            return m_file.isDirectory();
+        }
+
+        if( m_linkFlag == TarConstants.LF_DIR )
+        {
+            return true;
+        }
+
+        if( getName().endsWith( "/" ) )
+        {
+            return true;
+        }
+
+        return false;
+    }
+
+    /**
+     * Indicate if this entry is a GNU long name block
+     *
+     * @return true if this is a long name extension provided by GNU tar
+     */
+    public boolean isGNULongNameEntry()
+    {
+        return m_linkFlag == TarConstants.LF_GNUTYPE_LONGNAME &&
+            m_name.toString().equals( TarConstants.GNU_LONGLINK );
+    }
+
+    /**
+     * Determine if the two entries are equal. Equality is determined by the
+     * header names being equal.
+     *
+     * @param other Entry to be checked for equality.
+     * @return True if the entries are equal.
+     */
+    public boolean equals( final TarArchiveEntry other )
+    {
+        return getName().equals( other.getName() );
+    }
+
+    /**
+     * Parse an entry's header information from a header buffer.
+     *
+     * @param header The tar entry header buffer to get information from.
+     */
+    private void parseTarHeader( final byte[] header )
+    {
+        int offset = 0;
+
+        m_name = TarUtils.parseName( header, offset, NAMELEN );
+        offset += NAMELEN;
+        m_mode = (int)TarUtils.parseOctal( header, offset, TarConstants.MODELEN );
+        offset += TarConstants.MODELEN;
+        m_userID = (int)TarUtils.parseOctal( header, offset, TarConstants.UIDLEN );
+        offset += TarConstants.UIDLEN;
+        m_groupID = (int)TarUtils.parseOctal( header, offset, TarConstants.GIDLEN );
+        offset += TarConstants.GIDLEN;
+        m_size = TarUtils.parseOctal( header, offset, TarConstants.SIZELEN );
+        offset += TarConstants.SIZELEN;
+        m_modTime = TarUtils.parseOctal( header, offset, TarConstants.MODTIMELEN );
+        offset += TarConstants.MODTIMELEN;
+        m_checkSum = (int)TarUtils.parseOctal( header, offset, TarConstants.CHKSUMLEN );
+        offset += TarConstants.CHKSUMLEN;
+        m_linkFlag = header[ offset++ ];
+        m_linkName = TarUtils.parseName( header, offset, NAMELEN );
+        offset += NAMELEN;
+        m_magic = TarUtils.parseName( header, offset, TarConstants.MAGICLEN );
+        offset += TarConstants.MAGICLEN;
+        m_userName = TarUtils.parseName( header, offset, TarConstants.UNAMELEN );
+        offset += TarConstants.UNAMELEN;
+        m_groupName = TarUtils.parseName( header, offset, TarConstants.GNAMELEN );
+        offset += TarConstants.GNAMELEN;
+        m_devMajor = (int)TarUtils.parseOctal( header, offset, TarConstants.DEVLEN );
+        offset += TarConstants.DEVLEN;
+        m_devMinor = (int)TarUtils.parseOctal( header, offset, TarConstants.DEVLEN );
+    }
+
+    /**
+     * Write an entry's header information to a header buffer.
+     *
+     * @param buffer The tar entry header buffer to fill in.
+     */
+    public void writeEntryHeader( final byte[] buffer )
+    {
+        int offset = 0;
+
+        offset = TarUtils.getNameBytes( m_name, buffer, offset, NAMELEN );
+        offset = TarUtils.getOctalBytes( m_mode, buffer, offset, TarConstants.MODELEN );
+        offset = TarUtils.getOctalBytes( m_userID, buffer, offset, TarConstants.UIDLEN );
+        offset = TarUtils.getOctalBytes( m_groupID, buffer, offset, TarConstants.GIDLEN );
+        offset = TarUtils.getLongOctalBytes( m_size, buffer, offset, TarConstants.SIZELEN );
+        offset = TarUtils.getLongOctalBytes( m_modTime, buffer, offset, TarConstants.MODTIMELEN );
+
+        final int checkSumOffset = offset;
+        for( int i = 0; i < TarConstants.CHKSUMLEN; ++i )
+        {
+            buffer[ offset++ ] = (byte)' ';
+        }
+
+        buffer[ offset++ ] = m_linkFlag;
+        offset = TarUtils.getNameBytes( m_linkName, buffer, offset, NAMELEN );
+        offset = TarUtils.getNameBytes( m_magic, buffer, offset, TarConstants.MAGICLEN );
+        offset = TarUtils.getNameBytes( m_userName, buffer, offset, TarConstants.UNAMELEN );
+        offset = TarUtils.getNameBytes( m_groupName, buffer, offset, TarConstants.GNAMELEN );
+        offset = TarUtils.getOctalBytes( m_devMajor, buffer, offset, TarConstants.DEVLEN );
+        offset = TarUtils.getOctalBytes( m_devMinor, buffer, offset, TarConstants.DEVLEN );
+
+        while( offset < buffer.length )
+        {
+            buffer[ offset++ ] = 0;
+        }
+
+        final long checkSum = TarUtils.computeCheckSum( buffer );
+        TarUtils.getCheckSumOctalBytes( checkSum, buffer, checkSumOffset, TarConstants.CHKSUMLEN );
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveInputStream.java b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveInputStream.java
new file mode 100644
index 0000000..72e9499
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveInputStream.java
@@ -0,0 +1,77 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.tar;
+
+import java.io.IOException;
+import java.io.InputStream;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.ArchiveInputStream;
+
+public class TarArchiveInputStream extends ArchiveInputStream {
+    private final TarInputStream in;
+    
+	public TarArchiveInputStream( InputStream inputStream ) {
+		in = new TarInputStream(inputStream);
+	}
+
+    public ArchiveEntry getNextEntry() throws IOException {
+        return (ArchiveEntry)in.getNextEntry();
+    }
+
+    public int read(byte[] b, int off, int len) throws IOException {
+        return in.read(b, off, len);
+    }
+
+    public int read() throws IOException {
+        return in.read();
+    }
+    
+    public static boolean matches( byte[] signature ) {
+    	// 6574 7473 2e31 6d78
+    	
+    	if (signature[0] != 0x74) {
+    		return false;
+    	}
+    	if (signature[1] != 0x65) {
+    		return false;
+    	}
+    	if (signature[2] != 0x73) {
+    		return false;
+    	}
+    	if (signature[3] != 0x74) {
+    		return false;
+    	}
+    	if (signature[4] != 0x31) {
+    		return false;
+    	}
+    	if (signature[5] != 0x2e) {
+    		return false;
+    	}
+    	if (signature[6] != 0x78) {
+    		return false;
+    	}
+    	if (signature[7] != 0x6d) {
+    		return false;
+    	}
+    	
+    	return true;
+    }
+    
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java
new file mode 100644
index 0000000..57358ea
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java
@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.tar;
+
+import java.io.IOException;
+import java.io.OutputStream;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.ArchiveOutputStream;
+
+public class TarArchiveOutputStream extends ArchiveOutputStream {
+
+    private TarOutputStream out = null;
+    
+    /**
+     * @param out
+     */
+    public TarArchiveOutputStream(OutputStream out) {
+        this.out = new TarOutputStream(out);
+    }
+    
+    public void close() throws IOException {
+        this.out.close();
+    }
+
+    public void closeArchiveEntry() throws IOException {
+        this.out.closeEntry();
+    }
+
+    public void putArchiveEntry(ArchiveEntry entry) throws IOException {
+        this.out.putNextEntry((TarArchiveEntry)entry);
+    }
+
+    public void write(byte[] buffer, int offset, int length) throws IOException {
+        this.out.write(buffer, offset, length);
+    }
+
+    public String getDefaultFileExtension() {
+        return "tar";
+    }
+
+    public byte[] getHeader() {
+        // TODO Auto-generated method stub
+        return null;
+    }
+
+    public String getName() {
+        return "tar";
+    }
+
+    public void write(int b) throws IOException {
+        this.out.write(b);
+    }
+}
+
diff --git a/src/main/java/org/apache/commons/compress/archivers/tar/TarBuffer.java b/src/main/java/org/apache/commons/compress/archivers/tar/TarBuffer.java
new file mode 100644
index 0000000..7a1a60b
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarBuffer.java
@@ -0,0 +1,509 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.tar;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.util.Arrays;
+
+/**
+ * The TarBuffer class implements the tar archive concept of a buffered input
+ * stream. This concept goes back to the days of blocked tape drives and special
+ * io devices. In the Java universe, the only real function that this class
+ * performs is to ensure that files have the correct "block" size, or other tars
+ * will complain. <p>
+ *
+ * You should never have a need to access this class directly. TarBuffers are
+ * created by Tar IO Streams.
+ *
+ * @author <a href="mailto:time@ice.com">Timothy Gerard Endres</a>
+ * @author <a href="mailto:peter@apache.org">Peter Donald</a>
+ * @version $Revision$ $Date$
+ */
+class TarBuffer
+{
+    public static final int DEFAULT_RECORDSIZE = ( 512 );
+    public static final int DEFAULT_BLOCKSIZE = ( DEFAULT_RECORDSIZE * 20 );
+
+    private byte[] m_blockBuffer;
+    private int m_blockSize;
+    private int m_currBlkIdx;
+    private int m_currRecIdx;
+    private boolean m_debug;
+
+    private InputStream m_input;
+    private OutputStream m_output;
+    private int m_recordSize;
+    private int m_recsPerBlock;
+
+    public TarBuffer( final InputStream input )
+    {
+        this( input, TarBuffer.DEFAULT_BLOCKSIZE );
+    }
+
+    public TarBuffer( final InputStream input, final int blockSize )
+    {
+        this( input, blockSize, TarBuffer.DEFAULT_RECORDSIZE );
+    }
+
+    public TarBuffer( final InputStream input,
+                      final int blockSize,
+                      final int recordSize )
+    {
+        m_input = input;
+        initialize( blockSize, recordSize );
+    }
+
+    public TarBuffer( final OutputStream output )
+    {
+        this( output, TarBuffer.DEFAULT_BLOCKSIZE );
+    }
+
+    public TarBuffer( final OutputStream output, final int blockSize )
+    {
+        this( output, blockSize, TarBuffer.DEFAULT_RECORDSIZE );
+    }
+
+    public TarBuffer( final OutputStream output,
+                      final int blockSize,
+                      final int recordSize )
+    {
+        m_output = output;
+        initialize( blockSize, recordSize );
+    }
+
+    /**
+     * Set the debugging flag for the buffer.
+     *
+     * @param debug If true, print debugging output.
+     */
+    public void setDebug( final boolean debug )
+    {
+        m_debug = debug;
+    }
+
+    /**
+     * Get the TAR Buffer's block size. Blocks consist of multiple records.
+     *
+     * @return The BlockSize value
+     */
+    public int getBlockSize()
+    {
+        return m_blockSize;
+    }
+
+    /**
+     * Get the current block number, zero based.
+     *
+     * @return The current zero based block number.
+     */
+    public int getCurrentBlockNum()
+    {
+        return m_currBlkIdx;
+    }
+
+    /**
+     * Get the current record number, within the current block, zero based.
+     * Thus, current offset = (currentBlockNum * recsPerBlk) + currentRecNum.
+     *
+     * @return The current zero based record number.
+     */
+    public int getCurrentRecordNum()
+    {
+        return m_currRecIdx - 1;
+    }
+
+    /**
+     * Get the TAR Buffer's record size.
+     *
+     * @return The RecordSize value
+     */
+    public int getRecordSize()
+    {
+        return m_recordSize;
+    }
+
+    /**
+     * Determine if an archive record indicate End of Archive. End of archive is
+     * indicated by a record that consists entirely of null bytes.
+     *
+     * @param record The record data to check.
+     * @return The EOFRecord value
+     */
+    public boolean isEOFRecord( final byte[] record )
+    {
+        final int size = getRecordSize();
+        for( int i = 0; i < size; ++i )
+        {
+            if( record[ i ] != 0 )
+            {
+                return false;
+            }
+        }
+
+        return true;
+    }
+
+    /**
+     * Close the TarBuffer. If this is an output buffer, also flush the current
+     * block before closing.
+     */
+    public void close()
+        throws IOException
+    {
+        if( m_debug )
+        {
+            debug( "TarBuffer.closeBuffer()." );
+        }
+
+        if( null != m_output )
+        {
+            flushBlock();
+
+            if( m_output != System.out && m_output != System.err )
+            {
+                m_output.close();
+                m_output = null;
+            }
+        }
+        else if( m_input != null )
+        {
+            if( m_input != System.in )
+            {
+                m_input.close();
+                m_input = null;
+            }
+        }
+    }
+
+    /**
+     * Read a record from the input stream and return the data.
+     *
+     * @return The record data.
+     * @exception IOException Description of Exception
+     */
+    public byte[] readRecord()
+        throws IOException
+    {
+        if( m_debug )
+        {
+            final String message = "ReadRecord: recIdx = " + m_currRecIdx +
+                " blkIdx = " + m_currBlkIdx;
+            debug( message );
+        }
+
+        if( null == m_input )
+        {
+            final String message = "reading from an output buffer";
+            throw new IOException( message );
+        }
+
+        if( m_currRecIdx >= m_recsPerBlock )
+        {
+            if( !readBlock() )
+            {
+                return null;
+            }
+        }
+
+        final byte[] result = new byte[ m_recordSize ];
+        System.arraycopy( m_blockBuffer,
+                          ( m_currRecIdx * m_recordSize ),
+                          result,
+                          0,
+                          m_recordSize );
+
+        m_currRecIdx++;
+
+        return result;
+    }
+
+    /**
+     * Skip over a record on the input stream.
+     */
+    public void skipRecord()
+        throws IOException
+    {
+        if( m_debug )
+        {
+            final String message = "SkipRecord: recIdx = " + m_currRecIdx +
+                " blkIdx = " + m_currBlkIdx;
+            debug( message );
+        }
+
+        if( null == m_input )
+        {
+            final String message = "reading (via skip) from an output buffer";
+            throw new IOException( message );
+        }
+
+        if( m_currRecIdx >= m_recsPerBlock )
+        {
+            if( !readBlock() )
+            {
+                return;// UNDONE
+            }
+        }
+
+        m_currRecIdx++;
+    }
+
+    /**
+     * Write an archive record to the archive.
+     *
+     * @param record The record data to write to the archive.
+     */
+    public void writeRecord( final byte[] record )
+        throws IOException
+    {
+        if( m_debug )
+        {
+            final String message = "WriteRecord: recIdx = " + m_currRecIdx +
+                " blkIdx = " + m_currBlkIdx;
+            debug( message );
+        }
+
+        if( null == m_output )
+        {
+            final String message = "writing to an input buffer";
+            throw new IOException( message );
+        }
+
+        if( record.length != m_recordSize )
+        {
+            final String message = "record to write has length '" +
+                record.length + "' which is not the record size of '" +
+                m_recordSize + "'";
+            throw new IOException( message );
+        }
+
+        if( m_currRecIdx >= m_recsPerBlock )
+        {
+            writeBlock();
+        }
+
+        System.arraycopy( record,
+                          0,
+                          m_blockBuffer,
+                          ( m_currRecIdx * m_recordSize ),
+                          m_recordSize );
+
+        m_currRecIdx++;
+    }
+
+    /**
+     * Write an archive record to the archive, where the record may be inside of
+     * a larger array buffer. The buffer must be "offset plus record size" long.
+     *
+     * @param buffer The buffer containing the record data to write.
+     * @param offset The offset of the record data within buf.
+     */
+    public void writeRecord( final byte[] buffer, final int offset )
+        throws IOException
+    {
+        if( m_debug )
+        {
+            final String message = "WriteRecord: recIdx = " + m_currRecIdx +
+                " blkIdx = " + m_currBlkIdx;
+            debug( message );
+        }
+
+        if( null == m_output )
+        {
+            final String message = "writing to an input buffer";
+            throw new IOException( message );
+        }
+
+        if( ( offset + m_recordSize ) > buffer.length )
+        {
+            final String message = "record has length '" + buffer.length +
+                "' with offset '" + offset + "' which is less than the record size of '" +
+                m_recordSize + "'";
+            throw new IOException( message );
+        }
+
+        if( m_currRecIdx >= m_recsPerBlock )
+        {
+            writeBlock();
+        }
+
+        System.arraycopy( buffer,
+                          offset,
+                          m_blockBuffer,
+                          ( m_currRecIdx * m_recordSize ),
+                          m_recordSize );
+
+        m_currRecIdx++;
+    }
+
+    /**
+     * Flush the current data block if it has any data in it.
+     */
+    private void flushBlock()
+        throws IOException
+    {
+        if( m_debug )
+        {
+            final String message = "TarBuffer.flushBlock() called.";
+            debug( message );
+        }
+
+        if( m_output == null )
+        {
+            final String message = "writing to an input buffer";
+            throw new IOException( message );
+        }
+
+        if( m_currRecIdx > 0 )
+        {
+            writeBlock();
+        }
+    }
+
+    /**
+     * Initialization common to all constructors.
+     */
+    private void initialize( final int blockSize, final int recordSize )
+    {
+        m_debug = false;
+        m_blockSize = blockSize;
+        m_recordSize = recordSize;
+        m_recsPerBlock = ( m_blockSize / m_recordSize );
+        m_blockBuffer = new byte[ m_blockSize ];
+
+        if( null != m_input )
+        {
+            m_currBlkIdx = -1;
+            m_currRecIdx = m_recsPerBlock;
+        }
+        else
+        {
+            m_currBlkIdx = 0;
+            m_currRecIdx = 0;
+        }
+    }
+
+    /**
+     * @return false if End-Of-File, else true
+     */
+    private boolean readBlock()
+        throws IOException
+    {
+        if( m_debug )
+        {
+            final String message = "ReadBlock: blkIdx = " + m_currBlkIdx;
+            debug( message );
+        }
+
+        if( null == m_input )
+        {
+            final String message = "reading from an output buffer";
+            throw new IOException( message );
+        }
+
+        m_currRecIdx = 0;
+
+        int offset = 0;
+        int bytesNeeded = m_blockSize;
+
+        while( bytesNeeded > 0 )
+        {
+            final long numBytes = m_input.read( m_blockBuffer, offset, bytesNeeded );
+
+            //
+            // NOTE
+            // We have fit EOF, and the block is not full!
+            //
+            // This is a broken archive. It does not follow the standard
+            // blocking algorithm. However, because we are generous, and
+            // it requires little effort, we will simply ignore the error
+            // and continue as if the entire block were read. This does
+            // not appear to break anything upstream. We used to return
+            // false in this case.
+            //
+            // Thanks to 'Yohann.Roussel@alcatel.fr' for this fix.
+            //
+            if( numBytes == -1 )
+            {
+                // However, just leaving the unread portion of the buffer dirty does
+                // cause problems in some cases.  This problem is described in
+                // http://issues.apache.org/bugzilla/show_bug.cgi?id=29877
+                //
+                // The solution is to fill the unused portion of the buffer with zeros.
+
+                Arrays.fill(m_blockBuffer, offset, offset + bytesNeeded, (byte) 0);
+
+                break;
+            }
+
+            offset += numBytes;
+            bytesNeeded -= numBytes;
+
+            if( numBytes != m_blockSize )
+            {
+                if( m_debug )
+                {
+                    System.err.println( "ReadBlock: INCOMPLETE READ "
+                                        + numBytes + " of " + m_blockSize
+                                        + " bytes read." );
+                }
+            }
+        }
+
+        m_currBlkIdx++;
+
+        return true;
+    }
+
+    /**
+     * Write a TarBuffer block to the archive.
+     *
+     * @exception IOException Description of Exception
+     */
+    private void writeBlock()
+        throws IOException
+    {
+        if( m_debug )
+        {
+            final String message = "WriteBlock: blkIdx = " + m_currBlkIdx;
+            debug( message );
+        }
+
+        if( null == m_output )
+        {
+            final String message = "writing to an input buffer";
+            throw new IOException( message );
+        }
+
+        m_output.write( m_blockBuffer, 0, m_blockSize );
+        m_output.flush();
+
+        m_currRecIdx = 0;
+        m_currBlkIdx++;
+    }
+
+    protected void debug( final String message )
+    {
+        if( m_debug )
+        {
+            System.err.println( message );
+        }
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/tar/TarConstants.java b/src/main/java/org/apache/commons/compress/archivers/tar/TarConstants.java
new file mode 100644
index 0000000..825e87e
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarConstants.java
@@ -0,0 +1,145 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.tar;
+
+/**
+ * This interface contains all the definitions used in the package.
+ *
+ * @author <a href="mailto:time@ice.com">Timothy Gerard Endres</a>
+ * @author <a href="mailto:stefano@apache.org">Stefano Mazzocchi</a>
+ * @version $Revision$ $Date$
+ */
+interface TarConstants
+{
+    /**
+     * The length of the mode field in a header buffer.
+     */
+    int MODELEN = 8;
+
+    /**
+     * The length of the user id field in a header buffer.
+     */
+    int UIDLEN = 8;
+
+    /**
+     * The length of the group id field in a header buffer.
+     */
+    int GIDLEN = 8;
+
+    /**
+     * The length of the checksum field in a header buffer.
+     */
+    int CHKSUMLEN = 8;
+
+    /**
+     * The length of the size field in a header buffer.
+     */
+    int SIZELEN = 12;
+
+    /**
+     * The length of the magic field in a header buffer.
+     */
+    int MAGICLEN = 8;
+
+    /**
+     * The length of the modification time field in a header buffer.
+     */
+    int MODTIMELEN = 12;
+
+    /**
+     * The length of the user name field in a header buffer.
+     */
+    int UNAMELEN = 32;
+
+    /**
+     * The length of the group name field in a header buffer.
+     */
+    int GNAMELEN = 32;
+
+    /**
+     * The length of the devices field in a header buffer.
+     */
+    int DEVLEN = 8;
+
+    /**
+     * LF_ constants represent the "link flag" of an entry, or more commonly,
+     * the "entry type". This is the "old way" of indicating a normal file.
+     */
+    byte LF_OLDNORM = 0;
+
+    /**
+     * Normal file type.
+     */
+    byte LF_NORMAL = (byte)'0';
+
+    /**
+     * Link file type.
+     */
+    byte LF_LINK = (byte)'1';
+
+    /**
+     * Symbolic link file type.
+     */
+    byte LF_SYMLINK = (byte)'2';
+
+    /**
+     * Character device file type.
+     */
+    byte LF_CHR = (byte)'3';
+
+    /**
+     * Block device file type.
+     */
+    byte LF_BLK = (byte)'4';
+
+    /**
+     * Directory file type.
+     */
+    byte LF_DIR = (byte)'5';
+
+    /**
+     * FIFO (pipe) file type.
+     */
+    byte LF_FIFO = (byte)'6';
+
+    /**
+     * Contiguous file type.
+     */
+    byte LF_CONTIG = (byte)'7';
+
+    /**
+     * The magic tag representing a POSIX tar archive.
+     */
+    String TMAGIC = "ustar";
+
+    /**
+     * The magic tag representing a GNU tar archive.
+     */
+    String GNU_TMAGIC = "ustar  ";
+
+    /**
+     * The namr of the GNU tar entry which contains a long name.
+     */
+    String GNU_LONGLINK = "././@LongLink";
+
+    /**
+     * Identifies the *next* file on the tape as having a long name.
+     */
+    byte LF_GNUTYPE_LONGNAME = (byte)'L';
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/tar/TarInputStream.java b/src/main/java/org/apache/commons/compress/archivers/tar/TarInputStream.java
new file mode 100644
index 0000000..3e2be58
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarInputStream.java
@@ -0,0 +1,475 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.tar;
+
+import java.io.FilterInputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+
+/**
+ * The TarInputStream reads a UNIX tar archive as an InputStream. methods are
+ * provided to position at each successive entry in the archive, and the read
+ * each entry as a normal input stream using read().
+ *
+ * @author <a href="mailto:time@ice.com">Timothy Gerard Endres</a>
+ * @author <a href="mailto:stefano@apache.org">Stefano Mazzocchi</a>
+ * @author <a href="mailto:peter@apache.org">Peter Donald</a>
+ * @version $Revision$ $Date$
+ * @see TarInputStream
+ * @see TarArchiveEntry
+ */
+public class TarInputStream
+    extends FilterInputStream
+{
+    private TarBuffer m_buffer;
+    private TarArchiveEntry m_currEntry;
+    private boolean m_debug;
+    private int m_entryOffset;
+    private int m_entrySize;
+    private boolean m_hasHitEOF;
+    private byte[] m_oneBuf;
+    private byte[] m_readBuf;
+
+    /**
+     * Construct a TarInputStream using specified input
+     * stream and default block and record sizes.
+     *
+     * @param input stream to create TarInputStream from
+     * @see TarBuffer#DEFAULT_BLOCKSIZE
+     * @see TarBuffer#DEFAULT_RECORDSIZE
+     */
+    public TarInputStream( final InputStream input )
+    {
+        this( input, TarBuffer.DEFAULT_BLOCKSIZE, TarBuffer.DEFAULT_RECORDSIZE );
+    }
+
+    /**
+     * Construct a TarInputStream using specified input
+     * stream, block size and default record sizes.
+     *
+     * @param input stream to create TarInputStream from
+     * @param blockSize the block size to use
+     * @see TarBuffer#DEFAULT_RECORDSIZE
+     */
+    public TarInputStream( final InputStream input,
+                           final int blockSize )
+    {
+        this( input, blockSize, TarBuffer.DEFAULT_RECORDSIZE );
+    }
+
+    /**
+     * Construct a TarInputStream using specified input
+     * stream, block size and record sizes.
+     *
+     * @param input stream to create TarInputStream from
+     * @param blockSize the block size to use
+     * @param recordSize the record size to use
+     */
+    public TarInputStream( final InputStream input,
+                           final int blockSize,
+                           final int recordSize )
+    {
+        super( input );
+
+        m_buffer = new TarBuffer( input, blockSize, recordSize );
+        m_oneBuf = new byte[ 1 ];
+    }
+
+    /**
+     * Sets the debugging flag.
+     *
+     * @param debug The new Debug value
+     */
+    public void setDebug( final boolean debug )
+    {
+        m_debug = debug;
+        m_buffer.setDebug( debug );
+    }
+
+    /**
+     * Get the next entry in this tar archive. This will skip over any remaining
+     * data in the current entry, if there is one, and place the input stream at
+     * the header of the next entry, and read the header and instantiate a new
+     * TarEntry from the header bytes and return that entry. If there are no
+     * more entries in the archive, null will be returned to indicate that the
+     * end of the archive has been reached.
+     *
+     * @return The next TarEntry in the archive, or null.
+     * @exception IOException Description of Exception
+     */
+    public TarArchiveEntry getNextEntry()
+        throws IOException
+    {
+        if( m_hasHitEOF )
+        {
+            return null;
+        }
+
+        if( m_currEntry != null )
+        {
+            final int numToSkip = m_entrySize - m_entryOffset;
+
+            if( m_debug )
+            {
+                final String message = "TarInputStream: SKIP currENTRY '" +
+                    m_currEntry.getName() + "' SZ " + m_entrySize +
+                    " OFF " + m_entryOffset + "  skipping " + numToSkip + " bytes";
+                debug( message );
+            }
+
+            if( numToSkip > 0 )
+            {
+                skip( numToSkip );
+            }
+
+            m_readBuf = null;
+        }
+
+        final byte[] headerBuf = m_buffer.readRecord();
+        if( headerBuf == null )
+        {
+            if( m_debug )
+            {
+                debug( "READ NULL RECORD" );
+            }
+            m_hasHitEOF = true;
+        }
+        else if( m_buffer.isEOFRecord( headerBuf ) )
+        {
+            if( m_debug )
+            {
+                debug( "READ EOF RECORD" );
+            }
+            m_hasHitEOF = true;
+        }
+
+        if( m_hasHitEOF )
+        {
+            m_currEntry = null;
+        }
+        else
+        {
+            m_currEntry = new TarArchiveEntry( headerBuf );
+
+            if( !( headerBuf[ 257 ] == 'u' && headerBuf[ 258 ] == 's' &&
+                headerBuf[ 259 ] == 't' && headerBuf[ 260 ] == 'a' &&
+                headerBuf[ 261 ] == 'r' ) )
+            {
+                //Must be v7Format
+            }
+
+            if( m_debug )
+            {
+                final String message = "TarInputStream: SET CURRENTRY '" +
+                    m_currEntry.getName() + "' size = " + m_currEntry.getSize();
+                debug( message );
+            }
+
+            m_entryOffset = 0;
+
+            // REVIEW How do we resolve this discrepancy?!
+            m_entrySize = (int)m_currEntry.getSize();
+        }
+
+        if( null != m_currEntry && m_currEntry.isGNULongNameEntry() )
+        {
+            // read in the name
+            final StringBuffer longName = new StringBuffer();
+            final byte[] buffer = new byte[ 256 ];
+            int length = 0;
+            while( ( length = read( buffer ) ) >= 0 )
+            {
+                final String str = new String( buffer, 0, length );
+                longName.append( str );
+            }
+            getNextEntry();
+
+            // remove trailing null terminator
+            if (longName.length() > 0
+                && longName.charAt(longName.length() - 1) == 0) {
+                longName.deleteCharAt(longName.length() - 1);
+            }
+            
+            m_currEntry.setName( longName.toString() );
+        }
+
+        return m_currEntry;
+    }
+
+    /**
+     * Get the record size being used by this stream's TarBuffer.
+     *
+     * @return The TarBuffer record size.
+     */
+    public int getRecordSize()
+    {
+        return m_buffer.getRecordSize();
+    }
+
+    /**
+     * Get the available data that can be read from the current entry in the
+     * archive. This does not indicate how much data is left in the entire
+     * archive, only in the current entry. This value is determined from the
+     * entry's size header field and the amount of data already read from the
+     * current entry.
+     *
+     * @return The number of available bytes for the current entry.
+     * @exception IOException when an IO error causes operation to fail
+     */
+    public int available()
+        throws IOException
+    {
+        return m_entrySize - m_entryOffset;
+    }
+
+    /**
+     * Closes this stream. Calls the TarBuffer's close() method.
+     *
+     * @exception IOException when an IO error causes operation to fail
+     */
+    public void close()
+        throws IOException
+    {
+        m_buffer.close();
+    }
+
+    /**
+     * Copies the contents of the current tar archive entry directly into an
+     * output stream.
+     *
+     * @param output The OutputStream into which to write the entry's data.
+     * @exception IOException when an IO error causes operation to fail
+     */
+    public void copyEntryContents( final OutputStream output )
+        throws IOException
+    {
+        final byte[] buffer = new byte[ 32 * 1024 ];
+        while( true )
+        {
+            final int numRead = read( buffer, 0, buffer.length );
+            if( numRead == -1 )
+            {
+                break;
+            }
+
+            output.write( buffer, 0, numRead );
+        }
+    }
+
+    /**
+     * Since we do not support marking just yet, we do nothing.
+     *
+     * @param markLimit The limit to mark.
+     */
+    public void mark( int markLimit )
+    {
+    }
+
+    /**
+     * Since we do not support marking just yet, we return false.
+     *
+     * @return False.
+     */
+    public boolean markSupported()
+    {
+        return false;
+    }
+
+    /**
+     * Reads a byte from the current tar archive entry. This method simply calls
+     * read( byte[], int, int ).
+     *
+     * @return The byte read, or -1 at EOF.
+     * @exception IOException when an IO error causes operation to fail
+     */
+    public int read()
+        throws IOException
+    {
+        final int num = read( m_oneBuf, 0, 1 );
+        if( num == -1 )
+        {
+            return num;
+        }
+        else
+        {
+            return (int)m_oneBuf[ 0 ];
+        }
+    }
+
+    /**
+     * Reads bytes from the current tar archive entry. This method simply calls
+     * read( byte[], int, int ).
+     *
+     * @param buffer The buffer into which to place bytes read.
+     * @return The number of bytes read, or -1 at EOF.
+     * @exception IOException when an IO error causes operation to fail
+     */
+    public int read( final byte[] buffer )
+        throws IOException
+    {
+        return read( buffer, 0, buffer.length );
+    }
+
+    /**
+     * Reads bytes from the current tar archive entry. This method is aware of
+     * the boundaries of the current entry in the archive and will deal with
+     * them as if they were this stream's start and EOF.
+     *
+     * @param buffer The buffer into which to place bytes read.
+     * @param offset The offset at which to place bytes read.
+     * @param count The number of bytes to read.
+     * @return The number of bytes read, or -1 at EOF.
+     * @exception IOException when an IO error causes operation to fail
+     */
+    public int read( final byte[] buffer,
+                     final int offset,
+                     final int count )
+        throws IOException
+    {
+        int position = offset;
+        int numToRead = count;
+        int totalRead = 0;
+
+        if( m_entryOffset >= m_entrySize )
+        {
+            return -1;
+        }
+
+        if( ( numToRead + m_entryOffset ) > m_entrySize )
+        {
+            numToRead = ( m_entrySize - m_entryOffset );
+        }
+
+        if( null != m_readBuf )
+        {
+            final int size =
+                ( numToRead > m_readBuf.length ) ? m_readBuf.length : numToRead;
+
+            System.arraycopy( m_readBuf, 0, buffer, position, size );
+
+            if( size >= m_readBuf.length )
+            {
+                m_readBuf = null;
+            }
+            else
+            {
+                final int newLength = m_readBuf.length - size;
+                final byte[] newBuffer = new byte[ newLength ];
+
+                System.arraycopy( m_readBuf, size, newBuffer, 0, newLength );
+
+                m_readBuf = newBuffer;
+            }
+
+            totalRead += size;
+            numToRead -= size;
+            position += size;
+        }
+
+        while( numToRead > 0 )
+        {
+            final byte[] rec = m_buffer.readRecord();
+            if( null == rec )
+            {
+                // Unexpected EOF!
+                final String message =
+                    "unexpected EOF with " + numToRead + " bytes unread";
+                throw new IOException( message );
+            }
+
+            int size = numToRead;
+            final int recordLength = rec.length;
+
+            if( recordLength > size )
+            {
+                System.arraycopy( rec, 0, buffer, position, size );
+
+                m_readBuf = new byte[ recordLength - size ];
+
+                System.arraycopy( rec, size, m_readBuf, 0, recordLength - size );
+            }
+            else
+            {
+                size = recordLength;
+
+                System.arraycopy( rec, 0, buffer, position, recordLength );
+            }
+
+            totalRead += size;
+            numToRead -= size;
+            position += size;
+        }
+
+        m_entryOffset += totalRead;
+
+        return totalRead;
+    }
+
+    /**
+     * Since we do not support marking just yet, we do nothing.
+     */
+    public void reset()
+    {
+    }
+
+    /**
+     * Skip bytes in the input buffer. This skips bytes in the current entry's
+     * data, not the entire archive, and will stop at the end of the current
+     * entry's data if the number to skip extends beyond that point.
+     *
+     * @param numToSkip The number of bytes to skip.
+     * @exception IOException when an IO error causes operation to fail
+     */
+    public void skip( final int numToSkip )
+        throws IOException
+    {
+        // REVIEW
+        // This is horribly inefficient, but it ensures that we
+        // properly skip over bytes via the TarBuffer...
+        //
+        final byte[] skipBuf = new byte[ 8 * 1024 ];
+        int num = numToSkip;
+        while( num > 0 )
+        {
+            final int count = ( num > skipBuf.length ) ? skipBuf.length : num;
+            final int numRead = read( skipBuf, 0, count );
+            if( numRead == -1 )
+            {
+                break;
+            }
+
+            num -= numRead;
+        }
+    }
+
+    /**
+     * Utility method to do debugging.
+     * Capable of being overidden in sub-classes.
+     *
+     * @param message the message to use in debugging
+     */
+    protected void debug( final String message )
+    {
+        if( m_debug )
+        {
+            System.err.println( message );
+        }
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/tar/TarOutputStream.java b/src/main/java/org/apache/commons/compress/archivers/tar/TarOutputStream.java
new file mode 100644
index 0000000..8dbf4ad
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarOutputStream.java
@@ -0,0 +1,427 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.tar;
+
+import java.io.FilterOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+
+/**
+ * The TarOutputStream writes a UNIX tar archive as an OutputStream. Methods are
+ * provided to put entries, and then write their contents by writing to this
+ * stream using write().
+ *
+ * @author Timothy Gerard Endres <a href="mailto:time@ice.com">time@ice.com</a>
+ * @author <a href="mailto:peter@apache.org">Peter Donald</a>
+ * @version $Revision$ $Date$
+ * @see TarInputStream
+ * @see TarArchiveEntry
+ */
+public class TarOutputStream
+    extends FilterOutputStream
+{
+    /**
+     * Flag to indicate that an error should be generated if
+     * an attempt is made to write an entry that exceeds the 100 char
+     * POSIX limit.
+     */
+    public static final int LONGFILE_ERROR = 0;
+
+    /**
+     * Flag to indicate that entry name should be truncated if
+     * an attempt is made to write an entry that exceeds the 100 char
+     * POSIX limit.
+     */
+    public static final int LONGFILE_TRUNCATE = 1;
+
+    /**
+     * Flag to indicate that entry name should be formatted
+     * according to GNU tar extension if an attempt is made
+     * to write an entry that exceeds the 100 char POSIX
+     * limit. Note that this makes the jar unreadable by
+     * non-GNU tar commands.
+     */
+    public static final int LONGFILE_GNU = 2;
+
+    private int m_longFileMode = LONGFILE_ERROR;
+    private byte[] m_assemBuf;
+    private int m_assemLen;
+    private TarBuffer m_buffer;
+    private int m_currBytes;
+    private int m_currSize;
+
+    private byte[] m_oneBuf;
+    private byte[] m_recordBuf;
+
+    /**
+     * Construct a TarOutputStream using specified input
+     * stream and default block and record sizes.
+     *
+     * @param output stream to create TarOutputStream from
+     * @see TarBuffer#DEFAULT_BLOCKSIZE
+     * @see TarBuffer#DEFAULT_RECORDSIZE
+     */
+    public TarOutputStream( final OutputStream output )
+    {
+        this( output, TarBuffer.DEFAULT_BLOCKSIZE, TarBuffer.DEFAULT_RECORDSIZE );
+    }
+
+    /**
+     * Construct a TarOutputStream using specified input
+     * stream, block size and default record sizes.
+     *
+     * @param output stream to create TarOutputStream from
+     * @param blockSize the block size
+     * @see TarBuffer#DEFAULT_RECORDSIZE
+     */
+    public TarOutputStream( final OutputStream output,
+                            final int blockSize )
+    {
+        this( output, blockSize, TarBuffer.DEFAULT_RECORDSIZE );
+    }
+
+    /**
+     * Construct a TarOutputStream using specified input
+     * stream, block size and record sizes.
+     *
+     * @param output stream to create TarOutputStream from
+     * @param blockSize the block size
+     * @param recordSize the record size
+     */
+    public TarOutputStream( final OutputStream output,
+                            final int blockSize,
+                            final int recordSize )
+    {
+        super( output );
+
+        m_buffer = new TarBuffer( output, blockSize, recordSize );
+        m_assemLen = 0;
+        m_assemBuf = new byte[ recordSize ];
+        m_recordBuf = new byte[ recordSize ];
+        m_oneBuf = new byte[ 1 ];
+    }
+
+    /**
+     * Sets the debugging flag in this stream's TarBuffer.
+     *
+     * @param debug The new BufferDebug value
+     */
+    public void setBufferDebug( boolean debug )
+    {
+        m_buffer.setDebug( debug );
+    }
+
+    /**
+     * Set the mode used to work with entrys exceeding
+     * 100 chars (and thus break the POSIX standard).
+     * Must be one of the LONGFILE_* constants.
+     *
+     * @param longFileMode the mode
+     */
+    public void setLongFileMode( final int longFileMode )
+    {
+        if( LONGFILE_ERROR != longFileMode &&
+            LONGFILE_GNU != longFileMode &&
+            LONGFILE_TRUNCATE != longFileMode )
+        {
+            throw new IllegalArgumentException( "longFileMode" );
+        }
+        m_longFileMode = longFileMode;
+    }
+
+    /**
+     * Get the record size being used by this stream's TarBuffer.
+     *
+     * @return The TarBuffer record size.
+     */
+    public int getRecordSize()
+    {
+        return m_buffer.getRecordSize();
+    }
+
+    /**
+     * Ends the TAR archive and closes the underlying OutputStream. This means
+     * that finish() is called followed by calling the TarBuffer's close().
+     *
+     * @exception IOException when an IO error causes operation to fail
+     */
+    public void close()
+        throws IOException
+    {
+        finish();
+        m_buffer.close();
+    }
+
+    /**
+     * Close an entry. This method MUST be called for all file entries that
+     * contain data. The reason is that we must buffer data written to the
+     * stream in order to satisfy the buffer's record based writes. Thus, there
+     * may be data fragments still being assembled that must be written to the
+     * output stream before this entry is closed and the next entry written.
+     *
+     * @exception IOException when an IO error causes operation to fail
+     */
+    public void closeEntry()
+        throws IOException
+    {
+        if( m_assemLen > 0 )
+        {
+            for( int i = m_assemLen; i < m_assemBuf.length; ++i )
+            {
+                m_assemBuf[ i ] = 0;
+            }
+
+            m_buffer.writeRecord( m_assemBuf );
+
+            m_currBytes += m_assemLen;
+            m_assemLen = 0;
+        }
+
+        if( m_currBytes < m_currSize )
+        {
+            final String message = "entry closed at '" + m_currBytes +
+                "' before the '" + m_currSize +
+                "' bytes specified in the header were written";
+            throw new IOException( message );
+        }
+    }
+
+    /**
+     * Ends the TAR archive without closing the underlying OutputStream. The
+     * result is that the EOF record of nulls is written.
+     *
+     * @exception IOException when an IO error causes operation to fail
+     */
+    public void finish()
+        throws IOException
+    {
+        writeEOFRecord();
+    }
+
+    /**
+     * Put an entry on the output stream. This writes the entry's header record
+     * and positions the output stream for writing the contents of the entry.
+     * Once this method is called, the stream is ready for calls to write() to
+     * write the entry's contents. Once the contents are written, closeEntry()
+     * <B>MUST</B> be called to ensure that all buffered data is completely
+     * written to the output stream.
+     *
+     * @param entry The TarArchiveEntry to be written to the archive.
+     * @exception IOException when an IO error causes operation to fail
+     */
+    public void putNextEntry( final TarArchiveEntry entry )
+        throws IOException
+    {
+        if( entry.getName().length() >= TarArchiveEntry.NAMELEN )
+        {
+            if( m_longFileMode == LONGFILE_GNU )
+            {
+                // create a TarArchiveEntry for the LongLink, the contents
+                // of which are the entry's name
+                final TarArchiveEntry longLinkEntry =
+                    new TarArchiveEntry( TarConstants.GNU_LONGLINK,
+                                  TarConstants.LF_GNUTYPE_LONGNAME );
+
+                longLinkEntry.setSize( entry.getName().length() );
+                putNextEntry( longLinkEntry );
+                write( entry.getName().getBytes() );
+                //write( 0 );
+                closeEntry();
+            }
+            else if( m_longFileMode != LONGFILE_TRUNCATE )
+            {
+                final String message = "file name '" + entry.getName() +
+                    "' is too long ( > " + TarArchiveEntry.NAMELEN + " bytes)";
+                throw new IOException( message );
+            }
+        }
+
+        entry.writeEntryHeader( m_recordBuf );
+        m_buffer.writeRecord( m_recordBuf );
+
+        m_currBytes = 0;
+
+        if( entry.isDirectory() )
+        {
+            m_currSize = 0;
+        }
+        else
+        {
+            m_currSize = (int)entry.getSize();
+        }
+    }
+
+    /**
+     * Copies the contents of the specified stream into current tar
+     * archive entry.
+     *
+     * @param input The InputStream from which to read entrys data
+     * @exception IOException when an IO error causes operation to fail
+     */
+    public void copyEntryContents( final InputStream input )
+        throws IOException
+    {
+        final byte[] buffer = new byte[ 32 * 1024 ];
+        while( true )
+        {
+            final int numRead = input.read( buffer, 0, buffer.length );
+            if( numRead == -1 )
+            {
+                break;
+            }
+
+            write( buffer, 0, numRead );
+        }
+    }
+
+    /**
+     * Writes a byte to the current tar archive entry. This method simply calls
+     * read( byte[], int, int ).
+     *
+     * @param data The byte written.
+     * @exception IOException when an IO error causes operation to fail
+     */
+    public void write( final int data )
+        throws IOException
+    {
+        m_oneBuf[ 0 ] = (byte)data;
+
+        write( m_oneBuf, 0, 1 );
+    }
+
+    /**
+     * Writes bytes to the current tar archive entry. This method simply calls
+     * write( byte[], int, int ).
+     *
+     * @param buffer The buffer to write to the archive.
+     * @exception IOException when an IO error causes operation to fail
+     */
+    public void write( final byte[] buffer )
+        throws IOException
+    {
+        write( buffer, 0, buffer.length );
+    }
+
+    /**
+     * Writes bytes to the current tar archive entry. This method is aware of
+     * the current entry and will throw an exception if you attempt to write
+     * bytes past the length specified for the current entry. The method is also
+     * (painfully) aware of the record buffering required by TarBuffer, and
+     * manages buffers that are not a multiple of recordsize in length,
+     * including assembling records from small buffers.
+     *
+     * @param buffer The buffer to write to the archive.
+     * @param offset The offset in the buffer from which to get bytes.
+     * @param count The number of bytes to write.
+     * @exception IOException when an IO error causes operation to fail
+     */
+    public void write( final byte[] buffer,
+                       final int offset,
+                       final int count )
+        throws IOException
+    {
+        int position = offset;
+        int numToWrite = count;
+        if( ( m_currBytes + numToWrite ) > m_currSize )
+        {
+            final String message = "request to write '" + numToWrite +
+                "' bytes exceeds size in header of '" + m_currSize + "' bytes";
+            throw new IOException( message );
+            //
+            // We have to deal with assembly!!!
+            // The programmer can be writing little 32 byte chunks for all
+            // we know, and we must assemble complete records for writing.
+            // REVIEW Maybe this should be in TarBuffer? Could that help to
+            // eliminate some of the buffer copying.
+            //
+        }
+
+        if( m_assemLen > 0 )
+        {
+            if( ( m_assemLen + numToWrite ) >= m_recordBuf.length )
+            {
+                final int length = m_recordBuf.length - m_assemLen;
+
+                System.arraycopy( m_assemBuf, 0, m_recordBuf, 0,
+                                  m_assemLen );
+                System.arraycopy( buffer, position, m_recordBuf,
+                                  m_assemLen, length );
+                m_buffer.writeRecord( m_recordBuf );
+
+                m_currBytes += m_recordBuf.length;
+                position += length;
+                numToWrite -= length;
+                m_assemLen = 0;
+            }
+            else
+            {
+                System.arraycopy( buffer, position, m_assemBuf, m_assemLen,
+                                  numToWrite );
+
+                position += numToWrite;
+                m_assemLen += numToWrite;
+                numToWrite -= numToWrite;
+            }
+        }
+
+        //
+        // When we get here we have EITHER:
+        // o An empty "assemble" buffer.
+        // o No bytes to write (numToWrite == 0)
+        //
+        while( numToWrite > 0 )
+        {
+            if( numToWrite < m_recordBuf.length )
+            {
+                System.arraycopy( buffer, position, m_assemBuf, m_assemLen,
+                                  numToWrite );
+
+                m_assemLen += numToWrite;
+
+                break;
+            }
+
+            m_buffer.writeRecord( buffer, position );
+
+            int num = m_recordBuf.length;
+
+            m_currBytes += num;
+            numToWrite -= num;
+            position += num;
+        }
+    }
+
+    /**
+     * Write an EOF (end of archive) record to the tar archive. An EOF record
+     * consists of a record of all zeros.
+     *
+     * @exception IOException when an IO error causes operation to fail
+     */
+    private void writeEOFRecord()
+        throws IOException
+    {
+        for( int i = 0; i < m_recordBuf.length; ++i )
+        {
+            m_recordBuf[ i ] = 0;
+        }
+
+        m_buffer.writeRecord( m_recordBuf );
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/tar/TarUtils.java b/src/main/java/org/apache/commons/compress/archivers/tar/TarUtils.java
new file mode 100644
index 0000000..fb32d12
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/tar/TarUtils.java
@@ -0,0 +1,236 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.tar;
+
+/**
+ * This class provides static utility methods to work with byte streams.
+ *
+ * @author <a href="mailto:time@ice.com">Timothy Gerard Endres</a>
+ * @author <a href="mailto:stefano@apache.org">Stefano Mazzocchi</a>
+ * @version $Revision$ $Date$
+ */
+class TarUtils
+{
+    /**
+     * Parse the checksum octal integer from a header buffer.
+     *
+     * @param offset The offset into the buffer from which to parse.
+     * @param length The number of header bytes to parse.
+     * @param value Description of Parameter
+     * @param buf Description of Parameter
+     * @return The integer value of the entry's checksum.
+     */
+    public static int getCheckSumOctalBytes( final long value,
+                                             final byte[] buf,
+                                             final int offset,
+                                             final int length )
+    {
+        getOctalBytes( value, buf, offset, length );
+
+        buf[ offset + length - 1 ] = (byte)' ';
+        buf[ offset + length - 2 ] = 0;
+
+        return offset + length;
+    }
+
+    /**
+     * Parse an octal long integer from a header buffer.
+     *
+     * @param offset The offset into the buffer from which to parse.
+     * @param length The number of header bytes to parse.
+     * @param value Description of Parameter
+     * @param buf Description of Parameter
+     * @return The long value of the octal bytes.
+     */
+    public static int getLongOctalBytes( final long value,
+                                         final byte[] buf,
+                                         final int offset,
+                                         final int length )
+    {
+        byte[] temp = new byte[ length + 1 ];
+
+        getOctalBytes( value, temp, 0, length + 1 );
+        System.arraycopy( temp, 0, buf, offset, length );
+
+        return offset + length;
+    }
+
+    /**
+     * Determine the number of bytes in an entry name.
+     *
+     * @param offset The offset into the buffer from which to parse.
+     * @param length The number of header bytes to parse.
+     * @param name Description of Parameter
+     * @param buffer Description of Parameter
+     * @return The number of bytes in a header's entry name.
+     */
+    public static int getNameBytes( final StringBuffer name,
+                                    final byte[] buffer,
+                                    final int offset,
+                                    final int length )
+    {
+        int i;
+
+        for( i = 0; i < length && i < name.length(); ++i )
+        {
+            buffer[ offset + i ] = (byte)name.charAt( i );
+        }
+
+        for( ; i < length; ++i )
+        {
+            buffer[ offset + i ] = 0;
+        }
+
+        return offset + length;
+    }
+
+    /**
+     * Parse an octal integer from a header buffer.
+     *
+     * @param offset The offset into the buffer from which to parse.
+     * @param length The number of header bytes to parse.
+     * @return The integer value of the octal bytes.
+     */
+    public static int getOctalBytes( final long value,
+                                     final byte[] buffer,
+                                     final int offset,
+                                     final int length )
+    {
+        int idx = length - 1;
+
+        buffer[ offset + idx ] = 0;
+        --idx;
+        buffer[ offset + idx ] = (byte)' ';
+        --idx;
+
+        if( value == 0 )
+        {
+            buffer[ offset + idx ] = (byte)'0';
+            --idx;
+        }
+        else
+        {
+            long val = value;
+            while( idx >= 0 && val > 0 )
+            {
+                buffer[ offset + idx ] = (byte)( (byte)'0' + (byte)( val & 7 ) );
+                val = val >> 3;
+                idx--;
+            }
+        }
+
+        while( idx >= 0 )
+        {
+            buffer[ offset + idx ] = (byte)' ';
+            idx--;
+        }
+
+        return offset + length;
+    }
+
+    /**
+     * Compute the checksum of a tar entry header.
+     *
+     * @param buffer The tar entry's header buffer.
+     * @return The computed checksum.
+     */
+    public static long computeCheckSum( final byte[] buffer )
+    {
+        long sum = 0;
+
+        for( int i = 0; i < buffer.length; ++i )
+        {
+            sum += 255 & buffer[ i ];
+        }
+
+        return sum;
+    }
+
+    /**
+     * Parse an entry name from a header buffer.
+     *
+     * @param header The header buffer from which to parse.
+     * @param offset The offset into the buffer from which to parse.
+     * @param length The number of header bytes to parse.
+     * @return The header's entry name.
+     */
+    public static StringBuffer parseName( final byte[] header,
+                                          final int offset,
+                                          final int length )
+    {
+        StringBuffer result = new StringBuffer( length );
+        int end = offset + length;
+
+        for( int i = offset; i < end; ++i )
+        {
+            if( header[ i ] == 0 )
+            {
+                break;
+            }
+
+            result.append( (char)header[ i ] );
+        }
+
+        return result;
+    }
+
+    /**
+     * Parse an octal string from a header buffer. This is used for the file
+     * permission mode value.
+     *
+     * @param header The header buffer from which to parse.
+     * @param offset The offset into the buffer from which to parse.
+     * @param length The number of header bytes to parse.
+     * @return The long value of the octal string.
+     */
+    public static long parseOctal( final byte[] header,
+                                   final int offset,
+                                   final int length )
+    {
+        long result = 0;
+        boolean stillPadding = true;
+        int end = offset + length;
+
+        for( int i = offset; i < end; ++i )
+        {
+            if( header[ i ] == 0 )
+            {
+                break;
+            }
+
+            if( header[ i ] == (byte)' ' || header[ i ] == '0' )
+            {
+                if( stillPadding )
+                {
+                    continue;
+                }
+
+                if( header[ i ] == (byte)' ' )
+                {
+                    break;
+                }
+            }
+
+            stillPadding = false;
+            result = ( result << 3 ) + ( header[ i ] - '0' );
+        }
+
+        return result;
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/zip/AsiExtraField.java b/src/main/java/org/apache/commons/compress/archivers/zip/AsiExtraField.java
new file mode 100644
index 0000000..6d5761e
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/zip/AsiExtraField.java
@@ -0,0 +1,409 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.zip;
+
+import java.util.zip.CRC32;
+import java.util.zip.ZipException;
+
+/**
+ * Adds Unix file permission and UID/GID fields as well as symbolic link
+ * handling. <p>
+ *
+ * This class uses the ASi extra field in the format: <pre>
+ *         Value         Size            Description
+ *         -----         ----            -----------
+ * (Unix3) 0x756e        Short           tag for this extra block type
+ *         TSize         Short           total data size for this block
+ *         CRC           Long            CRC-32 of the remaining data
+ *         Mode          Short           file permissions
+ *         SizDev        Long            symlink'd size OR major/minor dev num
+ *         UID           Short           user ID
+ *         GID           Short           group ID
+ *         (var.)        variable        symbolic link filename
+ * </pre> taken from appnote.iz (Info-ZIP note, 981119) found at <a
+ * href="ftp://ftp.uu.net/pub/archiving/zip/doc/">
+ * ftp://ftp.uu.net/pub/archiving/zip/doc/</a> </p> <p>
+ *
+ * Short is two bytes and Long is four bytes in big endian byte and word order,
+ * device numbers are currently not supported.</p>
+ *
+ * @author <a href="stefan.bodewig@epost.de">Stefan Bodewig</a>
+ * @version $Revision$
+ */
+public class AsiExtraField
+    implements ZipExtraField, UnixStat, Cloneable
+{
+    private static final ZipShort HEADER_ID = new ZipShort( 0x756E );
+
+    /**
+     * Standard Unix stat(2) file mode.
+     *
+     * @since 1.1
+     */
+    private int m_mode;
+
+    /**
+     * User ID.
+     *
+     * @since 1.1
+     */
+    private int m_uid;
+
+    /**
+     * Group ID.
+     *
+     * @since 1.1
+     */
+    private int m_gid;
+
+    /**
+     * File this entry points to, if it is a symbolic link. <p>
+     *
+     * empty string - if entry is not a symbolic link.</p>
+     *
+     * @since 1.1
+     */
+    private String m_link = "";
+
+    /**
+     * Is this an entry for a directory?
+     *
+     * @since 1.1
+     */
+    private boolean m_dirFlag;
+
+    /**
+     * Instance used to calculate checksums.
+     *
+     * @since 1.1
+     */
+    private CRC32 m_crc = new CRC32();
+
+    /**
+     * Indicate whether this entry is a directory.
+     *
+     * @param dirFlag The new Directory value
+     * @since 1.1
+     */
+    public void setDirectory( final boolean dirFlag )
+    {
+        m_dirFlag = dirFlag;
+        m_mode = getMode( m_mode );
+    }
+
+    /**
+     * Set the group id.
+     *
+     * @param gid The new GroupId value
+     * @since 1.1
+     */
+    public void setGroupId( int gid )
+    {
+        m_gid = gid;
+    }
+
+    /**
+     * Indicate that this entry is a symbolic link to the given filename.
+     *
+     * @param name Name of the file this entry links to, empty String if it is
+     *      not a symbolic link.
+     * @since 1.1
+     */
+    public void setLinkedFile( final String name )
+    {
+        m_link = name;
+        m_mode = getMode( m_mode );
+    }
+
+    /**
+     * File mode of this file.
+     *
+     * @param mode The new Mode value
+     * @since 1.1
+     */
+    public void setMode( final int mode )
+    {
+        m_mode = getMode( mode );
+    }
+
+    /**
+     * Set the user id.
+     *
+     * @param uid The new UserId value
+     * @since 1.1
+     * @deprecated Use setUserID(int)
+     * @see #setUserID(int)
+     */
+    public void setUserId( final int uid )
+    {
+        m_uid = uid;
+    }
+
+    /**
+     * Set the user id.
+     *
+     * @param uid The new UserId value
+     */
+    public void setUserID( final int uid )
+    {
+        m_uid = uid;
+    }
+
+    /**
+     * Delegate to local file data.
+     *
+     * @return The CentralDirectoryData value
+     * @since 1.1
+     */
+    public byte[] getCentralDirectoryData()
+    {
+        return getLocalFileDataData();
+    }
+
+    /**
+     * Delegate to local file data.
+     *
+     * @return The CentralDirectoryLength value
+     * @since 1.1
+     */
+    public ZipShort getCentralDirectoryLength()
+    {
+        return getLocalFileDataLength();
+    }
+
+    /**
+     * Get the group id.
+     *
+     * @return The GroupId value
+     * @since 1.1
+     */
+    public int getGroupID()
+    {
+        return m_gid;
+    }
+
+    /**
+     * Get the group id.
+     *
+     * @return The GroupId value
+     * @since 1.1
+     * @deprecated Use getGroupID() instead
+     * @see #getGroupID()
+     */
+    public int getGroupId()
+    {
+        return m_gid;
+    }
+
+    /**
+     * The Header-ID.
+     *
+     * @return The HeaderId value
+     * @since 1.1
+     */
+    public ZipShort getHeaderID()
+    {
+        return HEADER_ID;
+    }
+
+    /**
+     * Name of linked file
+     *
+     * @return name of the file this entry links to if it is a symbolic link,
+     *      the empty string otherwise.
+     * @since 1.1
+     */
+    public String getLinkedFile()
+    {
+        return m_link;
+    }
+
+    /**
+     * The actual data to put into local file data - without Header-ID or length
+     * specifier.
+     *
+     * @return The LocalFileDataData value
+     * @since 1.1
+     */
+    public byte[] getLocalFileDataData()
+    {
+        // CRC will be added later
+        byte[] data = new byte[ getLocalFileDataLength().getValue() - 4 ];
+        System.arraycopy( ( new ZipShort( getMode() ) ).getBytes(), 0, data, 0, 2 );
+
+        byte[] linkArray = getLinkedFile().getBytes();
+        System.arraycopy( ( new ZipLong( linkArray.length ) ).getBytes(),
+                          0, data, 2, 4 );
+
+        System.arraycopy( ( new ZipShort( getUserID() ) ).getBytes(),
+                          0, data, 6, 2 );
+        System.arraycopy( ( new ZipShort( getGroupID() ) ).getBytes(),
+                          0, data, 8, 2 );
+
+        System.arraycopy( linkArray, 0, data, 10, linkArray.length );
+
+        m_crc.reset();
+        m_crc.update( data );
+        long checksum = m_crc.getValue();
+
+        byte[] result = new byte[ data.length + 4 ];
+        System.arraycopy( ( new ZipLong( checksum ) ).getBytes(), 0, result, 0, 4 );
+        System.arraycopy( data, 0, result, 4, data.length );
+        return result;
+    }
+
+    /**
+     * Length of the extra field in the local file data - without Header-ID or
+     * length specifier.
+     *
+     * @return The LocalFileDataLength value
+     * @since 1.1
+     */
+    public ZipShort getLocalFileDataLength()
+    {
+        return new ZipShort( 4 + // CRC
+                             2 + // Mode
+                             4 + // SizDev
+                             2 + // UID
+                             2 + // GID
+                             getLinkedFile().getBytes().length );
+    }
+
+    /**
+     * File mode of this file.
+     *
+     * @return The Mode value
+     * @since 1.1
+     */
+    public int getMode()
+    {
+        return m_mode;
+    }
+
+    /**
+     * Get the user id.
+     *
+     * @return The UserId value
+     * @since 1.1
+     * @deprecated Use getUserID()
+     * @see #getUserID()
+     */
+    public int getUserId()
+    {
+        return m_uid;
+    }
+
+    /**
+     * Get the user id.
+     *
+     * @return The UserID value
+     */
+    public int getUserID()
+    {
+        return m_uid;
+    }
+
+    /**
+     * Is this entry a directory?
+     *
+     * @return The Directory value
+     * @since 1.1
+     */
+    public boolean isDirectory()
+    {
+        return m_dirFlag && !isLink();
+    }
+
+    /**
+     * Is this entry a symbolic link?
+     *
+     * @return The Link value
+     * @since 1.1
+     */
+    public boolean isLink()
+    {
+        return getLinkedFile().length() != 0;
+    }
+
+    /**
+     * Populate data from this array as if it was in local file data.
+     *
+     * @param buffer the buffer
+     * @param offset the offset into buffer
+     * @param length the length of data in buffer
+     * @throws ZipException on error
+     * @since 1.1
+     */
+    public void parseFromLocalFileData( final byte[] buffer,
+                                        final int offset,
+                                        final int length )
+        throws ZipException
+    {
+
+        long givenChecksum = ( new ZipLong( buffer, offset ) ).getValue();
+        byte[] tmp = new byte[ length - 4 ];
+        System.arraycopy( buffer, offset + 4, tmp, 0, length - 4 );
+        m_crc.reset();
+        m_crc.update( tmp );
+        long realChecksum = m_crc.getValue();
+        if( givenChecksum != realChecksum )
+        {
+            throw new ZipException( "bad CRC checksum " + Long.toHexString( givenChecksum ) +
+                                    " instead of " + Long.toHexString( realChecksum ) );
+        }
+
+        int newMode = ( new ZipShort( tmp, 0 ) ).getValue();
+        byte[] linkArray = new byte[ (int)( new ZipLong( tmp, 2 ) ).getValue() ];
+        m_uid = ( new ZipShort( tmp, 6 ) ).getValue();
+        m_gid = ( new ZipShort( tmp, 8 ) ).getValue();
+
+        if( linkArray.length == 0 )
+        {
+            m_link = "";
+        }
+        else
+        {
+            System.arraycopy( tmp, 10, linkArray, 0, linkArray.length );
+            m_link = new String( linkArray );
+        }
+        setDirectory( ( newMode & DIR_FLAG ) != 0 );
+        setMode( newMode );
+    }
+
+    /**
+     * Get the file mode for given permissions with the correct file type.
+     *
+     * @param mode Description of Parameter
+     * @return The Mode value
+     * @since 1.1
+     */
+    protected int getMode( final int mode )
+    {
+        int type = FILE_FLAG;
+        if( isLink() )
+        {
+            type = LINK_FLAG;
+        }
+        else if( isDirectory() )
+        {
+            type = DIR_FLAG;
+        }
+        return type | ( mode & PERM_MASK );
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/zip/ExtraFieldUtils.java b/src/main/java/org/apache/commons/compress/archivers/zip/ExtraFieldUtils.java
new file mode 100644
index 0000000..24f308b
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ExtraFieldUtils.java
@@ -0,0 +1,207 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.zip;
+
+import java.util.ArrayList;
+import java.util.Hashtable;
+import java.util.zip.ZipException;
+
+/**
+ * ZipExtraField related methods
+ *
+ * @author <a href="stefan.bodewig@epost.de">Stefan Bodewig</a>
+ * @version $Revision$
+ */
+public class ExtraFieldUtils
+{
+    /**
+     * Static registry of known extra fields.
+     *
+     * @since 1.1
+     */
+    private static final Hashtable c_implementations;
+
+    static
+    {
+        c_implementations = new Hashtable();
+        register( AsiExtraField.class );
+    }
+
+    /**
+     * Create an instance of the approriate ExtraField, falls back to {@link
+     * UnrecognizedExtraField UnrecognizedExtraField}.
+     *
+     * Throws java.lang.IllegalAccessException if cant create implementation.
+     *
+     * @param headerID the header ID
+     * @return the extra field implementation
+     * @throws InstantiationException if cant create implementation
+     * @throws IllegalAccessException if cant create implementation
+     * @since 1.1
+     */
+    public static ZipExtraField createExtraField( final ZipShort headerID )
+        throws InstantiationException, IllegalAccessException
+    {
+        final Class clazz =
+            (Class)c_implementations.get( headerID );
+        if( clazz != null )
+        {
+            return (ZipExtraField)clazz.newInstance();
+        }
+        final UnrecognizedExtraField unrecognized = new UnrecognizedExtraField();
+        unrecognized.setHeaderID( headerID );
+        return unrecognized;
+    }
+
+    /**
+     * Merges the central directory fields of the given ZipExtraFields.
+     *
+     * @param data the central directory data
+     * @return the merged data
+     * @since 1.1
+     */
+    public static byte[] mergeCentralDirectoryData( final ZipExtraField[] data )
+    {
+        int sum = 4 * data.length;
+        for( int i = 0; i < data.length; i++ )
+        {
+            sum += data[ i ].getCentralDirectoryLength().getValue();
+        }
+        byte[] result = new byte[ sum ];
+        int start = 0;
+        for( int i = 0; i < data.length; i++ )
+        {
+            System.arraycopy( data[ i ].getHeaderID().getBytes(),
+                              0, result, start, 2 );
+            System.arraycopy( data[ i ].getCentralDirectoryLength().getBytes(),
+                              0, result, start + 2, 2 );
+            byte[] local = data[ i ].getCentralDirectoryData();
+            System.arraycopy( local, 0, result, start + 4, local.length );
+            start += ( local.length + 4 );
+        }
+        return result;
+    }
+
+    /**
+     * Merges the local file data fields of the given ZipExtraFields.
+     *
+     * @param data the data
+     * @return the merged data
+     * @since 1.1
+     */
+    public static byte[] mergeLocalFileDataData( final ZipExtraField[] data )
+    {
+        int sum = 4 * data.length;
+        for( int i = 0; i < data.length; i++ )
+        {
+            sum += data[ i ].getLocalFileDataLength().getValue();
+        }
+        byte[] result = new byte[ sum ];
+        int start = 0;
+        for( int i = 0; i < data.length; i++ )
+        {
+            System.arraycopy( data[ i ].getHeaderID().getBytes(),
+                              0, result, start, 2 );
+            System.arraycopy( data[ i ].getLocalFileDataLength().getBytes(),
+                              0, result, start + 2, 2 );
+            byte[] local = data[ i ].getLocalFileDataData();
+            System.arraycopy( local, 0, result, start + 4, local.length );
+            start += ( local.length + 4 );
+        }
+        return result;
+    }
+
+    /**
+     * Split the array into ExtraFields and populate them with the give data.
+     *
+     * @param data the data to parse
+     * @return the parsed fields
+     * @exception ZipException on error
+     * @since 1.1
+     */
+    public static ZipExtraField[] parse( final byte[] data )
+        throws ZipException
+    {
+        ArrayList v = new ArrayList();
+        int start = 0;
+        while( start <= data.length - 4 )
+        {
+            final ZipShort headerID = new ZipShort( data, start );
+            int length = ( new ZipShort( data, start + 2 ) ).getValue();
+            if( start + 4 + length > data.length )
+            {
+                throw new ZipException( "data starting at " + start + " is in unknown format" );
+            }
+            try
+            {
+                ZipExtraField ze = createExtraField( headerID );
+                ze.parseFromLocalFileData( data, start + 4, length );
+                v.add( ze );
+            }
+            catch( InstantiationException ie )
+            {
+                throw new ZipException( ie.getMessage() );
+            }
+            catch( IllegalAccessException iae )
+            {
+                throw new ZipException( iae.getMessage() );
+            }
+            start += ( length + 4 );
+        }
+        if( start != data.length )
+        {// array not exhausted
+            throw new ZipException( "data starting at " + start + " is in unknown format" );
+        }
+
+        final ZipExtraField[] result = new ZipExtraField[ v.size() ];
+        return (ZipExtraField[])v.toArray( result );
+    }
+
+    /**
+     * Register a ZipExtraField implementation. <p>
+     *
+     * The given class must have a no-arg constructor and implement the {@link
+     * ZipExtraField ZipExtraField interface}.</p>
+     *
+     * @param clazz The Class for particular implementation
+     * @since 1.1
+     */
+    public static void register( final Class clazz )
+    {
+        try
+        {
+            ZipExtraField ze = (ZipExtraField)clazz.newInstance();
+            c_implementations.put( ze.getHeaderID(), clazz );
+        }
+        catch( ClassCastException cc )
+        {
+            throw new RuntimeException( clazz +
+                                        " doesn\'t implement ZipExtraField" );
+        }
+        catch( InstantiationException ie )
+        {
+            throw new RuntimeException( clazz + " is not a concrete class" );
+        }
+        catch( IllegalAccessException ie )
+        {
+            throw new RuntimeException( clazz +
+                                        "\'s no-arg constructor is not public" );
+        }
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/zip/UnixStat.java b/src/main/java/org/apache/commons/compress/archivers/zip/UnixStat.java
new file mode 100644
index 0000000..a46365c
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/zip/UnixStat.java
@@ -0,0 +1,79 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.zip;
+
+/**
+ * Constants from stat.h on Unix systems.
+ *
+ * @author <a href="stefan.bodewig@epost.de">Stefan Bodewig</a>
+ * @version $Revision$
+ */
+public interface UnixStat
+{
+    /**
+     * Bits used for permissions (and sticky bit)
+     *
+     * @since 1.1
+     */
+    int PERM_MASK = 07777;
+    /**
+     * Indicates symbolic links.
+     *
+     * @since 1.1
+     */
+    int LINK_FLAG = 0120000;
+    /**
+     * Indicates plain files.
+     *
+     * @since 1.1
+     */
+    int FILE_FLAG = 0100000;
+    /**
+     * Indicates directories.
+     *
+     * @since 1.1
+     */
+    int DIR_FLAG = 040000;
+
+    // ----------------------------------------------------------
+    // somewhat arbitrary choices that are quite common for shared
+    // installations
+    // -----------------------------------------------------------
+
+    /**
+     * Default permissions for symbolic links.
+     *
+     * @since 1.1
+     */
+    int DEFAULT_LINK_PERM = 0777;
+
+    /**
+     * Default permissions for directories.
+     *
+     * @since 1.1
+     */
+    int DEFAULT_DIR_PERM = 0755;
+
+    /**
+     * Default permissions for plain files.
+     *
+     * @since 1.1
+     */
+    int DEFAULT_FILE_PERM = 0644;
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/zip/UnrecognizedExtraField.java b/src/main/java/org/apache/commons/compress/archivers/zip/UnrecognizedExtraField.java
new file mode 100644
index 0000000..816b364
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/zip/UnrecognizedExtraField.java
@@ -0,0 +1,159 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.zip;
+
+/**
+ * Simple placeholder for all those extra fields we don't want to deal with. <p>
+ *
+ * Assumes local file data and central directory entries are identical - unless
+ * told the opposite.</p>
+ *
+ * @author <a href="stefan.bodewig@epost.de">Stefan Bodewig</a>
+ * @version $Revision$
+ */
+public class UnrecognizedExtraField
+    implements ZipExtraField
+{
+    /**
+     * Extra field data in central directory - without Header-ID or length
+     * specifier.
+     *
+     * @since 1.1
+     */
+    private byte[] m_centralData;
+
+    /**
+     * The Header-ID.
+     *
+     * @since 1.1
+     */
+    private ZipShort m_headerID;
+
+    /**
+     * Extra field data in local file data - without Header-ID or length
+     * specifier.
+     *
+     * @since 1.1
+     */
+    private byte[] m_localData;
+
+    /**
+     * Set the central directory data
+     *
+     * @param centralData the central directory data
+     */
+    public void setCentralDirectoryData( final byte[] centralData )
+    {
+        m_centralData = centralData;
+    }
+
+       /**
+     * Set the header ID.
+     *
+     * @param headerID the header ID
+     */
+    public void setHeaderID( final ZipShort headerID )
+    {
+        m_headerID = headerID;
+    }
+
+    /**
+     * Set the local file data.
+     *
+     * @param localData the local file data
+     */
+    public void setLocalFileDataData( final byte[] localData )
+    {
+        m_localData = localData;
+    }
+
+    /**
+     * Get the central directory data.
+     *
+     * @return the central directory data.
+     */
+    public byte[] getCentralDirectoryData()
+    {
+        if( m_centralData != null )
+        {
+            return m_centralData;
+        }
+        return getLocalFileDataData();
+    }
+
+    /**
+     * Get the length of the central directory in bytes.
+     *
+     * @return the length of the central directory in bytes.
+     */
+    public ZipShort getCentralDirectoryLength()
+    {
+        if( m_centralData != null )
+        {
+            return new ZipShort( m_centralData.length );
+        }
+        return getLocalFileDataLength();
+    }
+
+    /**
+     * Get the HeaderID.
+     *
+     * @return the HeaderID
+     */
+    public ZipShort getHeaderID()
+    {
+        return m_headerID;
+    }
+
+    /**
+     * Get the local file data.
+     *
+     * @return the local file data
+     */
+    public byte[] getLocalFileDataData()
+    {
+        return m_localData;
+    }
+
+    /**
+     * Get the length of local file data in bytes.
+     *
+     * @return the length of local file data in bytes
+     */
+    public ZipShort getLocalFileDataLength()
+    {
+        return new ZipShort( m_localData.length );
+    }
+
+    /**
+     * Parse LocalFiledata out of supplied buffer.
+     *
+     * @param buffer the buffer to use
+     * @param offset the offset into buffer
+     * @param length then length of data
+     */
+    public void parseFromLocalFileData( final byte[] buffer,
+                                        final int offset,
+                                        final int length )
+    {
+        final byte[] fileData = new byte[ length ];
+        System.arraycopy( buffer, offset, fileData, 0, length );
+        setLocalFileDataData( fileData );
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveEntry.java b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveEntry.java
new file mode 100644
index 0000000..ef3aea0
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveEntry.java
@@ -0,0 +1,457 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.zip;
+
+import java.lang.reflect.InvocationTargetException;
+import java.lang.reflect.Method;
+import java.util.ArrayList;
+import java.util.zip.ZipException;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+
+/**
+ * Extension that adds better handling of extra fields and provides access to
+ * the internal and external file attributes.
+ *
+ * @author <a href="stefan.bodewig@epost.de">Stefan Bodewig</a>
+ * @version $Revision$
+ */
+public class ZipArchiveEntry
+    extends java.util.zip.ZipEntry
+    implements ArchiveEntry
+{
+    /**
+     * Helper for JDK 1.1
+     *
+     * @since 1.2
+     */
+    private static Method c_setCompressedSizeMethod;
+
+    /**
+     * Helper for JDK 1.1
+     *
+     * @since 1.2
+     */
+    private static final Object c_lockReflection = new Object();
+
+    /**
+     * Helper for JDK 1.1
+     *
+     * @since 1.2
+     */
+    private static boolean c_triedToGetMethod;
+
+    private final ArrayList m_extraFields = new ArrayList();
+
+    private int m_internalAttributes;
+    private long m_externalAttributes;
+
+    /**
+     * Helper for JDK 1.1 <-> 1.2 incompatibility.
+     *
+     * @since 1.2
+     */
+    private Long m_compressedSize;
+
+    /**
+     * Creates a new zip entry with the specified name.
+     *
+     * @param name the name of entry
+     * @since 1.1
+     */
+    public ZipArchiveEntry( final String name )
+    {
+        super( name );
+    }
+
+    /**
+     * Creates a new zip entry with fields taken from the specified zip entry.
+     *
+     * @param entry the JDK ZipEntry to adapt
+     * @exception ZipException if can not create entry
+     * @since 1.1
+     */
+    public ZipArchiveEntry( java.util.zip.ZipEntry entry )
+        throws ZipException
+    {
+        /*
+         * REVISIT: call super(entry) instead of this stuff in Ant2,
+         * "copy constructor" has not been available in JDK 1.1
+         */
+        super( entry.getName() );
+
+        setComment( entry.getComment() );
+        setMethod( entry.getMethod() );
+        setTime( entry.getTime() );
+
+        final long size = entry.getSize();
+        if( size > 0 )
+        {
+            setSize( size );
+        }
+
+        final long cSize = entry.getCompressedSize();
+        if( cSize > 0 )
+        {
+            setComprSize( cSize );
+        }
+
+        final long crc = entry.getCrc();
+        if( crc > 0 )
+        {
+            setCrc( crc );
+        }
+
+        final byte[] extra = entry.getExtra();
+        if( extra != null )
+        {
+            setExtraFields( ExtraFieldUtils.parse( extra ) );
+        }
+        else
+        {
+            // initializes extra data to an empty byte array
+            setExtra();
+        }
+    }
+
+    /**
+     * Creates a new zip entry with fields taken from the specified zip entry.
+     *
+     * @param entry the entry to adapt
+     * @exception ZipException if can not create entry
+     * @since 1.1
+     */
+    public ZipArchiveEntry( final ZipArchiveEntry entry )
+        throws ZipException
+    {
+        this( (java.util.zip.ZipEntry)entry );
+        setInternalAttributes( entry.getInternalAttributes() );
+        setExternalAttributes( entry.getExternalAttributes() );
+        setExtraFields( entry.getExtraFields() );
+    }
+
+    /**
+     * Try to get a handle to the setCompressedSize method.
+     *
+     * @since 1.2
+     */
+    private static void checkSCS()
+    {
+        if( !c_triedToGetMethod )
+        {
+            synchronized( c_lockReflection )
+            {
+                c_triedToGetMethod = true;
+                try
+                {
+                    c_setCompressedSizeMethod =
+                        java.util.zip.ZipEntry.class.getMethod( "setCompressedSize",
+                                                                new Class[]{Long.TYPE} );
+                }
+                catch( NoSuchMethodException nse )
+                {
+                }
+            }
+        }
+    }
+
+    /**
+     * Are we running JDK 1.2 or higher?
+     *
+     * @return Description of the Returned Value
+     * @since 1.2
+     */
+    private static boolean haveSetCompressedSize()
+    {
+        checkSCS();
+        return c_setCompressedSizeMethod != null;
+    }
+
+    /**
+     * Invoke setCompressedSize via reflection.
+     *
+     * @param entry Description of Parameter
+     * @param size Description of Parameter
+     * @since 1.2
+     */
+    private static void performSetCompressedSize( final ZipArchiveEntry entry,
+                                                  final long size )
+    {
+        final Long[] s = {new Long( size )};
+        try
+        {
+            c_setCompressedSizeMethod.invoke( entry, s );
+        }
+        catch( final InvocationTargetException ite )
+        {
+            final Throwable nested = ite.getTargetException();
+            final String message = "Exception setting the compressed size " +
+                "of " + entry + ": " + nested.getMessage();
+            throw new RuntimeException( message );
+        }
+        catch( final Throwable t )
+        {
+            final String message = "Exception setting the compressed size " +
+                "of " + entry + ": " + t.getMessage();
+            throw new RuntimeException( message );
+        }
+    }
+
+    /**
+     * Make this class work in JDK 1.1 like a 1.2 class. <p>
+     *
+     * This either stores the size for later usage or invokes setCompressedSize
+     * via reflection.</p>
+     *
+     * @param size The new ComprSize value
+     * @since 1.2
+     */
+    public void setComprSize( final long size )
+    {
+        if( haveSetCompressedSize() )
+        {
+            performSetCompressedSize( this, size );
+        }
+        else
+        {
+            m_compressedSize = new Long( size );
+        }
+    }
+
+    /**
+     * Sets the external file attributes.
+     *
+     * @param externalAttributes The new ExternalAttributes value
+     * @since 1.1
+     */
+    public void setExternalAttributes( final long externalAttributes )
+    {
+        m_externalAttributes = externalAttributes;
+    }
+
+    /**
+     * Throws an Exception if extra data cannot be parsed into extra fields.
+     *
+     * @param extra The new Extra value
+     * @throws RuntimeException if fail to set extra data
+     * @since 1.1
+     */
+    public void setExtra( final byte[] extra )
+        throws RuntimeException
+    {
+        try
+        {
+            setExtraFields( ExtraFieldUtils.parse( extra ) );
+        }
+        catch( final Exception e )
+        {
+            throw new RuntimeException( e.getMessage() );
+        }
+    }
+
+    /**
+     * Replaces all currently attached extra fields with the new array.
+     *
+     * @param fields The new ExtraFields value
+     * @since 1.1
+     */
+    public void setExtraFields( final ZipExtraField[] fields )
+    {
+        m_extraFields.clear();
+        for( int i = 0; i < fields.length; i++ )
+        {
+            m_extraFields.add( fields[ i ] );
+        }
+        setExtra();
+    }
+
+    /**
+     * Sets the internal file attributes.
+     *
+     * @param value The new InternalAttributes value
+     * @since 1.1
+     */
+    public void setInternalAttributes( final int value )
+    {
+        m_internalAttributes = value;
+    }
+
+    /**
+     * Retrieves the extra data for the central directory.
+     *
+     * @return The CentralDirectoryExtra value
+     * @since 1.1
+     */
+    public byte[] getCentralDirectoryExtra()
+    {
+        return ExtraFieldUtils.mergeCentralDirectoryData( getExtraFields() );
+    }
+
+    /**
+     * Override to make this class work in JDK 1.1 like a 1.2 class.
+     *
+     * @return The CompressedSize value
+     * @since 1.2
+     */
+    public long getCompressedSize()
+    {
+        if( m_compressedSize != null )
+        {
+            // has been set explicitly and we are running in a 1.1 VM
+            return m_compressedSize.longValue();
+        }
+        return super.getCompressedSize();
+    }
+
+    /**
+     * Retrieves the external file attributes.
+     *
+     * @return The ExternalAttributes value
+     * @since 1.1
+     */
+    public long getExternalAttributes()
+    {
+        return m_externalAttributes;
+    }
+
+    /**
+     * Retrieves extra fields.
+     *
+     * @return The ExtraFields value
+     * @since 1.1
+     */
+    public ZipExtraField[] getExtraFields()
+    {
+        final ZipExtraField[] result = new ZipExtraField[ m_extraFields.size() ];
+        return (ZipExtraField[])m_extraFields.toArray( result );
+    }
+
+    /**
+     * Retrieves the internal file attributes.
+     *
+     * @return The InternalAttributes value
+     * @since 1.1
+     */
+    public int getInternalAttributes()
+    {
+        return m_internalAttributes;
+    }
+
+    /**
+     * Retrieves the extra data for the local file data.
+     *
+     * @return The LocalFileDataExtra value
+     * @since 1.1
+     */
+    public byte[] getLocalFileDataExtra()
+    {
+        byte[] extra = getExtra();
+        return extra != null ? extra : new byte[ 0 ];
+    }
+
+    /**
+     * Adds an extra fields - replacing an already present extra field of the
+     * same type.
+     *
+     * @param extraField The feature to be added to the ExtraField attribute
+     * @since 1.1
+     */
+    public void addExtraField( final ZipExtraField extraField )
+    {
+        final ZipShort type = extraField.getHeaderID();
+        boolean done = false;
+        for( int i = 0; !done && i < m_extraFields.size(); i++ )
+        {
+            final ZipExtraField other = (ZipExtraField)m_extraFields.get( i );
+            if( other.getHeaderID().equals( type ) )
+            {
+                m_extraFields.set( i, extraField );
+                done = true;
+            }
+        }
+        if( !done )
+        {
+            m_extraFields.add( extraField );
+        }
+        setExtra();
+    }
+
+    /**
+     * Overwrite clone
+     *
+     * @return Description of the Returned Value
+     * @since 1.1
+     */
+    public Object clone()
+    {
+        ZipArchiveEntry entry = null;
+        try
+        {
+            entry = new ZipArchiveEntry( (java.util.zip.ZipEntry)super.clone() );
+        }
+        catch( final Exception e )
+        {
+            // impossible as extra data is in correct format
+            e.printStackTrace();
+            return null;
+        }
+
+        entry.setInternalAttributes( getInternalAttributes() );
+        entry.setExternalAttributes( getExternalAttributes() );
+        entry.setExtraFields( getExtraFields() );
+        return entry;
+    }
+
+    /**
+     * Remove an extra fields.
+     *
+     * @param type Description of Parameter
+     * @since 1.1
+     */
+    public void removeExtraField( final ZipShort type )
+    {
+        boolean done = false;
+        for( int i = 0; !done && i < m_extraFields.size(); i++ )
+        {
+            if( ( (ZipExtraField)m_extraFields.get( i ) ).getHeaderID().equals( type ) )
+            {
+                m_extraFields.remove( i );
+                done = true;
+            }
+        }
+        if( !done )
+        {
+            throw new java.util.NoSuchElementException();
+        }
+        setExtra();
+    }
+
+    /**
+     * Unfortunately {@link java.util.zip.ZipOutputStream
+     * java.util.zip.ZipOutputStream} seems to access the extra data directly,
+     * so overriding getExtra doesn't help - we need to modify super's data
+     * directly.
+     *
+     * @since 1.1
+     */
+    protected void setExtra()
+    {
+        super.setExtra( ExtraFieldUtils.mergeLocalFileDataData( getExtraFields() ) );
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveInputStream.java b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveInputStream.java
new file mode 100644
index 0000000..1211847
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveInputStream.java
@@ -0,0 +1,83 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.zip;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.zip.ZipInputStream;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.ArchiveInputStream;
+
+public class ZipArchiveInputStream extends ArchiveInputStream {
+
+	private final ZipInputStream input;
+
+	public ZipArchiveInputStream(InputStream inputStream) {
+		input = new ZipInputStream(inputStream);
+	}
+
+    public ArchiveEntry getNextEntry() throws IOException {
+    	java.util.zip.ZipEntry entry = input.getNextEntry();
+    	if(entry == null) {
+    		return null;
+    	}
+        return (ArchiveEntry)new ZipArchiveEntry(entry);
+    }
+
+    public int read(byte[] b, int off, int len) throws IOException {
+        return input.read(b, off, len);
+    }
+    
+    public int read() throws IOException {
+        return input.read();
+    }
+
+    
+    public static boolean matches( byte[] signature ) {
+    	// 4b50 0403 0014 0000
+
+    	if (signature[0] != 0x50) {
+    		return false;
+    	}
+    	if (signature[1] != 0x4b) {
+    		return false;
+    	}
+    	if (signature[2] != 0x03) {
+    		return false;
+    	}
+    	if (signature[3] != 0x04) {
+    		return false;
+    	}
+    	if (signature[4] != 0x14) {
+    		return false;
+    	}
+    	if (signature[5] != 0x00) {
+    		return false;
+    	}
+    	if (signature[6] != 0x00) {
+    		return false;
+    	}
+    	if (signature[7] != 0x00) {
+    		return false;
+    	}
+    	
+    	return true;
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveOutputStream.java b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveOutputStream.java
new file mode 100644
index 0000000..41efb8e
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipArchiveOutputStream.java
@@ -0,0 +1,70 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.zip;
+
+import java.io.IOException;
+import java.io.OutputStream;
+import java.util.zip.ZipOutputStream;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.ArchiveOutputStream;
+
+public class ZipArchiveOutputStream extends ArchiveOutputStream {
+
+    private ZipOutputStream zipOut = null;
+
+    
+    public ZipArchiveOutputStream(OutputStream out) {
+        this.zipOut = new ZipOutputStream(out);
+    }
+    
+    public void putArchiveEntry(ArchiveEntry entry) throws IOException {
+        zipOut.putNextEntry((ZipArchiveEntry) entry);
+    }
+
+    public String getDefaultFileExtension() {
+        return "zip";
+    }
+
+    public byte[] getHeader() {
+        // TODO Auto-generated method stub
+        return null;
+    }
+
+    public String getName() {
+        return "zip";
+    }
+
+    public void close() throws IOException {
+        zipOut.close();
+    }
+
+    public void write(byte[] buffer, int offset, int length) throws IOException {
+        zipOut.write(buffer, offset, length);
+    }
+
+    public void closeArchiveEntry() {
+        // do nothing
+    }
+
+	public void write(int arg0) throws IOException {
+		this.zipOut.write(arg0);
+	}
+ 
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/zip/ZipEntry.java b/src/main/java/org/apache/commons/compress/archivers/zip/ZipEntry.java
new file mode 100644
index 0000000..aadc9af
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipEntry.java
@@ -0,0 +1,458 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.zip;
+
+import java.lang.reflect.InvocationTargetException;
+import java.lang.reflect.Method;
+import java.util.ArrayList;
+import java.util.zip.ZipException;
+
+/**
+ * Extension that adds better handling of extra fields and provides access to
+ * the internal and external file attributes.
+ *
+ * @author <a href="stefan.bodewig@epost.de">Stefan Bodewig</a>
+<<<<<<< HEAD:src/main/java/org/apache/commons/compress/archivers/zip/ZipEntry.java
+ * @version $Revision$
+=======
+ * @version $Revision$
+>>>>>>> 75cb63ff7005344589b57d17338b64783f8f430c:src/main/java/org/apache/commons/compress/archivers/zip/ZipEntry.java
+ */
+public class ZipEntry
+    extends java.util.zip.ZipEntry
+{
+    /**
+     * Helper for JDK 1.1
+     *
+     * @since 1.2
+     */
+    private static Method c_setCompressedSizeMethod;
+
+    /**
+     * Helper for JDK 1.1
+     *
+     * @since 1.2
+     */
+    private static final Object c_lockReflection = new Object();
+
+    /**
+     * Helper for JDK 1.1
+     *
+     * @since 1.2
+     */
+    private static boolean c_triedToGetMethod;
+
+    private final ArrayList m_extraFields = new ArrayList();
+
+    private int m_internalAttributes;
+    private long m_externalAttributes;
+
+    /**
+     * Helper for JDK 1.1 <-> 1.2 incompatibility.
+     *
+     * @since 1.2
+     */
+    private Long m_compressedSize;
+
+    /**
+     * Creates a new zip entry with the specified name.
+     *
+     * @param name the name of entry
+     * @since 1.1
+     */
+    public ZipEntry( final String name )
+    {
+        super( name );
+    }
+
+    /**
+     * Creates a new zip entry with fields taken from the specified zip entry.
+     *
+     * @param entry the JDK ZipEntry to adapt
+     * @exception ZipException if can not create entry
+     * @since 1.1
+     */
+    public ZipEntry( java.util.zip.ZipEntry entry )
+        throws ZipException
+    {
+        /*
+         * REVISIT: call super(entry) instead of this stuff in Ant2,
+         * "copy constructor" has not been available in JDK 1.1
+         */
+        super( entry.getName() );
+
+        setComment( entry.getComment() );
+        setMethod( entry.getMethod() );
+        setTime( entry.getTime() );
+
+        final long size = entry.getSize();
+        if( size > 0 )
+        {
+            setSize( size );
+        }
+
+        final long cSize = entry.getCompressedSize();
+        if( cSize > 0 )
+        {
+            setComprSize( cSize );
+        }
+
+        final long crc = entry.getCrc();
+        if( crc > 0 )
+        {
+            setCrc( crc );
+        }
+
+        final byte[] extra = entry.getExtra();
+        if( extra != null )
+        {
+            setExtraFields( ExtraFieldUtils.parse( extra ) );
+        }
+        else
+        {
+            // initializes extra data to an empty byte array
+            setExtra();
+        }
+    }
+
+    /**
+     * Creates a new zip entry with fields taken from the specified zip entry.
+     *
+     * @param entry the entry to adapt
+     * @exception ZipException if can not create entry
+     * @since 1.1
+     */
+    public ZipEntry( final ZipEntry entry )
+        throws ZipException
+    {
+        this( (java.util.zip.ZipEntry)entry );
+        setInternalAttributes( entry.getInternalAttributes() );
+        setExternalAttributes( entry.getExternalAttributes() );
+        setExtraFields( entry.getExtraFields() );
+    }
+
+    /**
+     * Try to get a handle to the setCompressedSize method.
+     *
+     * @since 1.2
+     */
+    private static void checkSCS()
+    {
+        if( !c_triedToGetMethod )
+        {
+            synchronized( c_lockReflection )
+            {
+                c_triedToGetMethod = true;
+                try
+                {
+                    c_setCompressedSizeMethod =
+                        java.util.zip.ZipEntry.class.getMethod( "setCompressedSize",
+                                                                new Class[]{Long.TYPE} );
+                }
+                catch( NoSuchMethodException nse )
+                {
+                }
+            }
+        }
+    }
+
+    /**
+     * Are we running JDK 1.2 or higher?
+     *
+     * @return Description of the Returned Value
+     * @since 1.2
+     */
+    private static boolean haveSetCompressedSize()
+    {
+        checkSCS();
+        return c_setCompressedSizeMethod != null;
+    }
+
+    /**
+     * Invoke setCompressedSize via reflection.
+     *
+     * @param entry Description of Parameter
+     * @param size Description of Parameter
+     * @since 1.2
+     */
+    private static void performSetCompressedSize( final ZipEntry entry,
+                                                  final long size )
+    {
+        final Long[] s = {new Long( size )};
+        try
+        {
+            c_setCompressedSizeMethod.invoke( entry, s );
+        }
+        catch( final InvocationTargetException ite )
+        {
+            final Throwable nested = ite.getTargetException();
+            final String message = "Exception setting the compressed size " +
+                "of " + entry + ": " + nested.getMessage();
+            throw new RuntimeException( message );
+        }
+        catch( final Throwable t )
+        {
+            final String message = "Exception setting the compressed size " +
+                "of " + entry + ": " + t.getMessage();
+            throw new RuntimeException( message );
+        }
+    }
+
+    /**
+     * Make this class work in JDK 1.1 like a 1.2 class. <p>
+     *
+     * This either stores the size for later usage or invokes setCompressedSize
+     * via reflection.</p>
+     *
+     * @param size The new ComprSize value
+     * @since 1.2
+     */
+    public void setComprSize( final long size )
+    {
+        if( haveSetCompressedSize() )
+        {
+            performSetCompressedSize( this, size );
+        }
+        else
+        {
+            m_compressedSize = new Long( size );
+        }
+    }
+
+    /**
+     * Sets the external file attributes.
+     *
+     * @param externalAttributes The new ExternalAttributes value
+     * @since 1.1
+     */
+    public void setExternalAttributes( final long externalAttributes )
+    {
+        m_externalAttributes = externalAttributes;
+    }
+
+    /**
+     * Throws an Exception if extra data cannot be parsed into extra fields.
+     *
+     * @param extra The new Extra value
+     * @throws RuntimeException if fail to set extra data
+     * @since 1.1
+     */
+    public void setExtra( final byte[] extra )
+        throws RuntimeException
+    {
+        try
+        {
+            setExtraFields( ExtraFieldUtils.parse( extra ) );
+        }
+        catch( final Exception e )
+        {
+            throw new RuntimeException( e.getMessage() );
+        }
+    }
+
+    /**
+     * Replaces all currently attached extra fields with the new array.
+     *
+     * @param fields The new ExtraFields value
+     * @since 1.1
+     */
+    public void setExtraFields( final ZipExtraField[] fields )
+    {
+        m_extraFields.clear();
+        for( int i = 0; i < fields.length; i++ )
+        {
+            m_extraFields.add( fields[ i ] );
+        }
+        setExtra();
+    }
+
+    /**
+     * Sets the internal file attributes.
+     *
+     * @param value The new InternalAttributes value
+     * @since 1.1
+     */
+    public void setInternalAttributes( final int value )
+    {
+        m_internalAttributes = value;
+    }
+
+    /**
+     * Retrieves the extra data for the central directory.
+     *
+     * @return The CentralDirectoryExtra value
+     * @since 1.1
+     */
+    public byte[] getCentralDirectoryExtra()
+    {
+        return ExtraFieldUtils.mergeCentralDirectoryData( getExtraFields() );
+    }
+
+    /**
+     * Override to make this class work in JDK 1.1 like a 1.2 class.
+     *
+     * @return The CompressedSize value
+     * @since 1.2
+     */
+    public long getCompressedSize()
+    {
+        if( m_compressedSize != null )
+        {
+            // has been set explicitly and we are running in a 1.1 VM
+            return m_compressedSize.longValue();
+        }
+        return super.getCompressedSize();
+    }
+
+    /**
+     * Retrieves the external file attributes.
+     *
+     * @return The ExternalAttributes value
+     * @since 1.1
+     */
+    public long getExternalAttributes()
+    {
+        return m_externalAttributes;
+    }
+
+    /**
+     * Retrieves extra fields.
+     *
+     * @return The ExtraFields value
+     * @since 1.1
+     */
+    public ZipExtraField[] getExtraFields()
+    {
+        final ZipExtraField[] result = new ZipExtraField[ m_extraFields.size() ];
+        return (ZipExtraField[])m_extraFields.toArray( result );
+    }
+
+    /**
+     * Retrieves the internal file attributes.
+     *
+     * @return The InternalAttributes value
+     * @since 1.1
+     */
+    public int getInternalAttributes()
+    {
+        return m_internalAttributes;
+    }
+
+    /**
+     * Retrieves the extra data for the local file data.
+     *
+     * @return The LocalFileDataExtra value
+     * @since 1.1
+     */
+    public byte[] getLocalFileDataExtra()
+    {
+        byte[] extra = getExtra();
+        return extra != null ? extra : new byte[ 0 ];
+    }
+
+    /**
+     * Adds an extra fields - replacing an already present extra field of the
+     * same type.
+     *
+     * @param extraField The feature to be added to the ExtraField attribute
+     * @since 1.1
+     */
+    public void addExtraField( final ZipExtraField extraField )
+    {
+        final ZipShort type = extraField.getHeaderID();
+        boolean done = false;
+        for( int i = 0; !done && i < m_extraFields.size(); i++ )
+        {
+            final ZipExtraField other = (ZipExtraField)m_extraFields.get( i );
+            if( other.getHeaderID().equals( type ) )
+            {
+                m_extraFields.set( i, extraField );
+                done = true;
+            }
+        }
+        if( !done )
+        {
+            m_extraFields.add( extraField );
+        }
+        setExtra();
+    }
+
+    /**
+     * Overwrite clone
+     *
+     * @return Description of the Returned Value
+     * @since 1.1
+     */
+    public Object clone()
+    {
+        ZipEntry entry = null;
+        try
+        {
+            entry = new ZipEntry( (java.util.zip.ZipEntry)super.clone() );
+        }
+        catch( final Exception e )
+        {
+            // impossible as extra data is in correct format
+            e.printStackTrace();
+            return null;
+        }
+
+        entry.setInternalAttributes( getInternalAttributes() );
+        entry.setExternalAttributes( getExternalAttributes() );
+        entry.setExtraFields( getExtraFields() );
+        return entry;
+    }
+
+    /**
+     * Remove an extra fields.
+     *
+     * @param type Description of Parameter
+     * @since 1.1
+     */
+    public void removeExtraField( final ZipShort type )
+    {
+        boolean done = false;
+        for( int i = 0; !done && i < m_extraFields.size(); i++ )
+        {
+            if( ( (ZipExtraField)m_extraFields.get( i ) ).getHeaderID().equals( type ) )
+            {
+                m_extraFields.remove( i );
+                done = true;
+            }
+        }
+        if( !done )
+        {
+            throw new java.util.NoSuchElementException();
+        }
+        setExtra();
+    }
+
+    /**
+     * Unfortunately {@link java.util.zip.ZipOutputStream
+     * java.util.zip.ZipOutputStream} seems to access the extra data directly,
+     * so overriding getExtra doesn't help - we need to modify super's data
+     * directly.
+     *
+     * @since 1.1
+     */
+    protected void setExtra()
+    {
+        super.setExtra( ExtraFieldUtils.mergeLocalFileDataData( getExtraFields() ) );
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/zip/ZipExtraField.java b/src/main/java/org/apache/commons/compress/archivers/zip/ZipExtraField.java
new file mode 100644
index 0000000..314686c
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipExtraField.java
@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.zip;
+
+import java.util.zip.ZipException;
+
+/**
+ * General format of extra field data. <p>
+ *
+ * Extra fields usually appear twice per file, once in the local file data and
+ * once in the central directory. Usually they are the same, but they don't have
+ * to be. {@link java.util.zip.ZipOutputStream java.util.zip.ZipOutputStream}
+ * will only use the local file data in both places.</p>
+ *
+ * @author <a href="stefan.bodewig@epost.de">Stefan Bodewig</a>
+ * @version $Revision$
+ */
+public interface ZipExtraField
+{
+    /**
+     * The Header-ID.
+     *
+     * @return The HeaderId value
+     * @since 1.1
+     */
+    ZipShort getHeaderID();
+
+    /**
+     * Length of the extra field in the local file data - without Header-ID or
+     * length specifier.
+     *
+     * @return The LocalFileDataLength value
+     * @since 1.1
+     */
+    ZipShort getLocalFileDataLength();
+
+    /**
+     * Length of the extra field in the central directory - without Header-ID or
+     * length specifier.
+     *
+     * @return The CentralDirectoryLength value
+     * @since 1.1
+     */
+    ZipShort getCentralDirectoryLength();
+
+    /**
+     * The actual data to put into local file data - without Header-ID or length
+     * specifier.
+     *
+     * @return The LocalFileDataData value
+     * @since 1.1
+     */
+    byte[] getLocalFileDataData();
+
+    /**
+     * The actual data to put central directory - without Header-ID or length
+     * specifier.
+     *
+     * @return The CentralDirectoryData value
+     * @since 1.1
+     */
+    byte[] getCentralDirectoryData();
+
+    /**
+     * Populate data from this array as if it was in local file data.
+     *
+     * @param buffer the buffer to read data from
+     * @param offset offset into buffer to read data
+     * @param length the length of data
+     * @exception ZipException on error
+     * @since 1.1
+     */
+    void parseFromLocalFileData( byte[] buffer, int offset, int length )
+        throws ZipException;
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/zip/ZipLong.java b/src/main/java/org/apache/commons/compress/archivers/zip/ZipLong.java
new file mode 100644
index 0000000..f79410e
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipLong.java
@@ -0,0 +1,122 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.zip;
+
+/**
+ * Utility class that represents a four byte integer with conversion rules for
+ * the big endian byte order of ZIP files.
+ *
+ * @author <a href="mailto:stefan.bodewig@epost.de">Stefan Bodewig</a>
+ * @version $Revision$
+ */
+public final class ZipLong implements Cloneable
+{
+    private long m_value;
+
+    /**
+     * Create instance from a number.
+     *
+     * @param value the value
+     * @since 1.1
+     */
+    public ZipLong( final long value )
+    {
+        m_value = value;
+    }
+
+    /**
+     * Create instance from bytes.
+     *
+     * @param buffer the buffer to read data from
+     * @since 1.1
+     */
+    public ZipLong( final byte[] buffer )
+    {
+        this( buffer, 0 );
+    }
+
+    /**
+     * Create instance from the four bytes starting at offset.
+     *
+     * @param buffer buffer to read data from
+     * @param offset offset into buffer
+     * @since 1.1
+     */
+    public ZipLong( final byte[] buffer, final int offset )
+    {
+        m_value = ( buffer[ offset + 3 ] << 24 ) & 0xFF000000l;
+        m_value += ( buffer[ offset + 2 ] << 16 ) & 0xFF0000;
+        m_value += ( buffer[ offset + 1 ] << 8 ) & 0xFF00;
+        m_value += ( buffer[ offset ] & 0xFF );
+    }
+
+    /**
+     * Get value as two bytes in big endian byte order.
+     *
+     * @return The value as bytes
+     * @since 1.1
+     */
+    public byte[] getBytes()
+    {
+        byte[] result = new byte[ 4 ];
+        result[ 0 ] = (byte)( ( m_value & 0xFF ) );
+        result[ 1 ] = (byte)( ( m_value & 0xFF00 ) >> 8 );
+        result[ 2 ] = (byte)( ( m_value & 0xFF0000 ) >> 16 );
+        result[ 3 ] = (byte)( ( m_value & 0xFF000000l ) >> 24 );
+        return result;
+    }
+
+    /**
+     * Get value as Java int.
+     *
+     * @return The value
+     * @since 1.1
+     */
+    public long getValue()
+    {
+        return m_value;
+    }
+
+    /**
+     * Override to make two instances with same value equal.
+     *
+     * @param o the object to compare against
+     * @return true if equyal, false otherwise
+     * @since 1.1
+     */
+    public boolean equals( final Object o )
+    {
+        if( o == null || !( o instanceof ZipLong ) )
+        {
+            return false;
+        }
+        return m_value == ( (ZipLong)o ).getValue();
+    }
+
+    /**
+     * Override to make two instances with same value equal.
+     *
+     * @return the hashcode
+     * @since 1.1
+     */
+    public int hashCode()
+    {
+        return (int)m_value;
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/zip/ZipOutputStream.java b/src/main/java/org/apache/commons/compress/archivers/zip/ZipOutputStream.java
new file mode 100644
index 0000000..a003bee
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipOutputStream.java
@@ -0,0 +1,731 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.zip;
+
+import java.io.IOException;
+import java.io.OutputStream;
+import java.io.UnsupportedEncodingException;
+import java.util.ArrayList;
+import java.util.Calendar;
+import java.util.Date;
+import java.util.Hashtable;
+import java.util.zip.CRC32;
+import java.util.zip.Deflater;
+import java.util.zip.DeflaterOutputStream;
+import java.util.zip.ZipException;
+
+/**
+ * Reimplementation of {@link java.util.zip.ZipOutputStream
+ * java.util.zip.ZipOutputStream} that does handle the extended functionality of
+ * this package, especially internal/external file attributes and extra fields
+ * with different layouts for local file data and central directory entries. <p>
+ *
+ * This implementation will use a Data Descriptor to store size and CRC
+ * information for DEFLATED entries, this means, you don't need to calculate
+ * them yourself. Unfortunately this is not possible for the STORED method, here
+ * setting the CRC and uncompressed size information is required before {@link
+ * #putNextEntry putNextEntry} will be called.</p>
+ *
+ * @author <a href="stefan.bodewig@epost.de">Stefan Bodewig</a>
+ * @version $Revision$
+ */
+public class ZipOutputStream
+    extends DeflaterOutputStream
+{
+    /**
+     * Helper, a 0 as ZipShort.
+     *
+     * @since 1.1
+     */
+    private static final byte[] ZERO = {0, 0};
+
+    /**
+     * Helper, a 0 as ZipLong.
+     *
+     * @since 1.1
+     */
+    private static final byte[] LZERO = {0, 0, 0, 0};
+
+    /**
+     * Compression method for deflated entries.
+     *
+     * @since 1.1
+     */
+    public static final int DEFLATED = ZipEntry.DEFLATED;
+
+    /**
+     * Compression method for deflated entries.
+     *
+     * @since 1.1
+     */
+    public static final int STORED = ZipEntry.STORED;
+
+    /*
+     * Various ZIP constants
+     */
+    /**
+     * local file header signature
+     *
+     * @since 1.1
+     */
+    protected static final ZipLong LFH_SIG = new ZipLong( 0X04034B50L );
+    /**
+     * data descriptor signature
+     *
+     * @since 1.1
+     */
+    protected static final ZipLong DD_SIG = new ZipLong( 0X08074B50L );
+    /**
+     * central file header signature
+     *
+     * @since 1.1
+     */
+    protected static final ZipLong CFH_SIG = new ZipLong( 0X02014B50L );
+    /**
+     * end of central dir signature
+     *
+     * @since 1.1
+     */
+    protected static final ZipLong EOCD_SIG = new ZipLong( 0X06054B50L );
+
+    /**
+     * Smallest date/time ZIP can handle.
+     *
+     * @since 1.1
+     */
+    private static final ZipLong DOS_TIME_MIN = new ZipLong( 0x00002100L );
+
+    /**
+     * The file comment.
+     *
+     * @since 1.1
+     */
+    private String m_comment = "";
+
+    /**
+     * Compression level for next entry.
+     *
+     * @since 1.1
+     */
+    private int m_level = Deflater.DEFAULT_COMPRESSION;
+
+    /**
+     * Default compression method for next entry.
+     *
+     * @since 1.1
+     */
+    private int m_method = DEFLATED;
+
+    /**
+     * List of ZipEntries written so far.
+     *
+     * @since 1.1
+     */
+    private final ArrayList m_entries = new ArrayList();
+
+    /**
+     * CRC instance to avoid parsing DEFLATED data twice.
+     *
+     * @since 1.1
+     */
+    private final CRC32 m_crc = new CRC32();
+
+    /**
+     * Count the bytes written to out.
+     *
+     * @since 1.1
+     */
+    private long m_written;
+
+    /**
+     * Data for current entry started here.
+     *
+     * @since 1.1
+     */
+    private long m_dataStart;
+
+    /**
+     * Start of central directory.
+     *
+     * @since 1.1
+     */
+    private ZipLong m_cdOffset = new ZipLong( 0 );
+
+    /**
+     * Length of central directory.
+     *
+     * @since 1.1
+     */
+    private ZipLong m_cdLength = new ZipLong( 0 );
+
+    /**
+     * Holds the offsets of the LFH starts for each entry
+     *
+     * @since 1.1
+     */
+    private final Hashtable m_offsets = new Hashtable();
+
+    /**
+     * The encoding to use for filenames and the file comment. <p>
+     *
+     * For a list of possible values see <a
+     * href="http://java.sun.com/products/jdk/1.2/docs/guide/internat/encoding.doc.html">
+     * http://java.sun.com/products/jdk/1.2/docs/guide/internat/encoding.doc.html
+     * </a>. Defaults to the platform's default character encoding.</p>
+     *
+     * @since 1.3
+     */
+    private String m_encoding;
+
+    /**
+     * Current entry.
+     *
+     * @since 1.1
+     */
+    private ZipArchiveEntry m_entry;
+
+    /**
+     * Creates a new ZIP OutputStream filtering the underlying stream.
+     *
+     * @param output the output stream to write to
+     * @since 1.1
+     */
+    public ZipOutputStream( final OutputStream output )
+    {
+        super( output, new Deflater( Deflater.DEFAULT_COMPRESSION, true ) );
+    }
+
+    /**
+     * Convert a Date object to a DOS date/time field. <p>
+     *
+     * Stolen from InfoZip's <code>fileio.c</code></p>
+     *
+     * @param time Description of Parameter
+     * @return Description of the Returned Value
+     * @since 1.1
+     */
+    protected static ZipLong toDosTime( Date time )
+    {
+        Calendar cal = Calendar.getInstance();
+        cal.setTime( time );
+        int year = cal.get(Calendar.YEAR);
+        int month = cal.get(Calendar.MONTH) + 1;
+        if( year < 1980 )
+        {
+            return DOS_TIME_MIN;
+        }
+        long value = ( ( year - 1980 ) << 25 )
+            | ( month << 21 )
+            | ( cal.get(Calendar.DAY_OF_MONTH) << 16 )
+            | ( cal.get(Calendar.HOUR_OF_DAY) << 11 )
+            | ( cal.get(Calendar.MINUTE) << 5 )
+            | ( cal.get(Calendar.SECOND) >> 1 );
+
+        byte[] result = new byte[ 4 ];
+        result[ 0 ] = (byte)( ( value & 0xFF ) );
+        result[ 1 ] = (byte)( ( value & 0xFF00 ) >> 8 );
+        result[ 2 ] = (byte)( ( value & 0xFF0000 ) >> 16 );
+        result[ 3 ] = (byte)( ( value & 0xFF000000l ) >> 24 );
+        return new ZipLong( result );
+    }
+
+    /**
+     * Set the file comment.
+     *
+     * @param comment The new Comment value
+     * @since 1.1
+     */
+    public void setComment( String comment )
+    {
+        m_comment = comment;
+    }
+
+    /**
+     * The encoding to use for filenames and the file comment. <p>
+     *
+     * For a list of possible values see <a
+     * href="http://java.sun.com/products/jdk/1.2/docs/guide/internat/encoding.doc.html">
+     * http://java.sun.com/products/jdk/1.2/docs/guide/internat/encoding.doc.html
+     * </a>. Defaults to the platform's default character encoding.</p>
+     *
+     * @param encoding The new Encoding value
+     * @since 1.3
+     */
+    public void setEncoding( String encoding )
+    {
+        m_encoding = encoding;
+    }
+
+    /**
+     * Sets the compression level for subsequent entries. <p>
+     *
+     * Default is Deflater.DEFAULT_COMPRESSION.</p>
+     *
+     * @param level The new Level value
+     * @since 1.1
+     */
+    public void setLevel( int level )
+    {
+        m_level = level;
+    }
+
+    /**
+     * Sets the default compression method for subsequent entries. <p>
+     *
+     * Default is DEFLATED.</p>
+     *
+     * @param method The new Method value
+     * @since 1.1
+     */
+    public void setMethod( final int method )
+    {
+        m_method = method;
+    }
+
+    /**
+     * The encoding to use for filenames and the file comment.
+     *
+     * @return null if using the platform's default character encoding.
+     * @since 1.3
+     */
+    public String getEncoding()
+    {
+        return m_encoding;
+    }
+
+    /**
+     * Writes all necessary data for this entry.
+     *
+     * @throws IOException if an IO failure causes operation to fail
+     * @since 1.1
+     */
+    public void closeEntry()
+        throws IOException
+    {
+        if( m_entry == null )
+        {
+            return;
+        }
+
+        long realCrc = m_crc.getValue();
+        m_crc.reset();
+
+        if( m_entry.getMethod() == DEFLATED )
+        {
+            def.finish();
+            while( !def.finished() )
+            {
+                deflate();
+            }
+
+            m_entry.setSize( def.getTotalIn() );
+            m_entry.setComprSize( def.getTotalOut() );
+            m_entry.setCrc( realCrc );
+
+            def.reset();
+
+            m_written += m_entry.getCompressedSize();
+        }
+        else
+        {
+            if( m_entry.getCrc() != realCrc )
+            {
+                throw new ZipException( "bad CRC checksum for entry "
+                                        + m_entry.getName() + ": "
+                                        + Long.toHexString( m_entry.getCrc() )
+                                        + " instead of "
+                                        + Long.toHexString( realCrc ) );
+            }
+
+            if( m_entry.getSize() != m_written - m_dataStart )
+            {
+                throw new ZipException( "bad size for entry "
+                                        + m_entry.getName() + ": "
+                                        + m_entry.getSize()
+                                        + " instead of "
+                                        + ( m_written - m_dataStart ) );
+            }
+
+        }
+
+        writeDataDescriptor( m_entry );
+        m_entry = null;
+    }
+
+    /*
+     * Found out by experiment, that DeflaterOutputStream.close()
+     * will call finish() - so we don't need to override close
+     * ourselves.
+     */
+    /**
+     * Finishs writing the contents and closes this as well as the underlying
+     * stream.
+     *
+     * @throws IOException if an IO failure causes operation to fail
+     * @since 1.1
+     */
+    public void finish()
+        throws IOException
+    {
+        closeEntry();
+        m_cdOffset = new ZipLong( m_written );
+        final int size = m_entries.size();
+        for( int i = 0; i < size; i++ )
+        {
+            final ZipArchiveEntry entry = (ZipArchiveEntry)m_entries.get( i );
+            writeCentralFileHeader( entry );
+        }
+        m_cdLength = new ZipLong( m_written - m_cdOffset.getValue() );
+        writeCentralDirectoryEnd();
+        m_offsets.clear();
+        m_entries.clear();
+    }
+
+    /**
+     * Begin writing next entry.
+     *
+     * @param entry the entry
+     * @throws IOException if an IO failure causes operation to fail
+     * @since 1.1
+     */
+    public void putNextEntry( final ZipArchiveEntry entry )
+        throws IOException
+    {
+        closeEntry();
+
+        m_entry = entry;
+        m_entries.add( m_entry );
+
+        if( m_entry.getMethod() == -1 )
+        {// not specified
+            m_entry.setMethod( m_method );
+        }
+
+        if( m_entry.getTime() == -1 )
+        {// not specified
+            m_entry.setTime( System.currentTimeMillis() );
+        }
+
+        if( m_entry.getMethod() == STORED )
+        {
+            if( m_entry.getSize() == -1 )
+            {
+                throw new ZipException( "uncompressed size is required for STORED method" );
+            }
+            if( m_entry.getCrc() == -1 )
+            {
+                throw new ZipException( "crc checksum is required for STORED method" );
+            }
+            m_entry.setComprSize( m_entry.getSize() );
+        }
+        else
+        {
+            def.setLevel( m_level );
+        }
+        writeLocalFileHeader( m_entry );
+    }
+
+    /**
+     * Writes bytes to ZIP entry. <p>
+     *
+     * Override is necessary to support STORED entries, as well as calculationg
+     * CRC automatically for DEFLATED entries.</p>
+     *
+     * @param buffer the buffer to write to
+     * @param offset the offset to write to
+     * @param length the length of data to write
+     * @exception IOException if an IO error causes operation to fail
+     */
+    public void write( final byte[] buffer,
+                       final int offset,
+                       final int length )
+        throws IOException
+    {
+        if( m_entry.getMethod() == DEFLATED )
+        {
+            super.write( buffer, offset, length );
+        }
+        else
+        {
+            out.write( buffer, offset, length );
+            m_written += length;
+        }
+        m_crc.update( buffer, offset, length );
+    }
+
+    /**
+     * Retrieve the bytes for the given String in the encoding set for this
+     * Stream.
+     *
+     * @param name the name to decode
+     * @return the bytes for string
+     * @exception ZipException if fail to retrieve bytes for specified string
+     * @since 1.3
+     */
+    protected byte[] getBytes( String name )
+        throws ZipException
+    {
+        if( m_encoding == null )
+        {
+            return name.getBytes();
+        }
+        else
+        {
+            try
+            {
+                return name.getBytes( m_encoding );
+            }
+            catch( UnsupportedEncodingException uee )
+            {
+                throw new ZipException( uee.getMessage() );
+            }
+        }
+    }
+
+    /**
+     * Writes the &quot;End of central dir record&quot;
+     *
+     * @exception IOException when an IO erro causes operation to fail
+     * @since 1.1
+     */
+    protected void writeCentralDirectoryEnd()
+        throws IOException
+    {
+        out.write( EOCD_SIG.getBytes() );
+
+        // disk numbers
+        out.write( ZERO );
+        out.write( ZERO );
+
+        // number of entries
+        byte[] num = ( new ZipShort( m_entries.size() ) ).getBytes();
+        out.write( num );
+        out.write( num );
+
+        // length and location of CD
+        out.write( m_cdLength.getBytes() );
+        out.write( m_cdOffset.getBytes() );
+
+        // ZIP file comment
+        byte[] data = getBytes( m_comment );
+        out.write( ( new ZipShort( data.length ) ).getBytes() );
+        out.write( data );
+    }
+
+    /**
+     * Writes the central file header entry
+     *
+     * @param entry the zip entry
+     * @throws IOException when an IO error causes operation to fail
+     * @since 1.1
+     */
+    protected void writeCentralFileHeader( final ZipArchiveEntry entry )
+        throws IOException
+    {
+        out.write( CFH_SIG.getBytes() );
+        m_written += 4;
+
+        // version made by
+        out.write( ( new ZipShort( 20 ) ).getBytes() );
+        m_written += 2;
+
+        // version needed to extract
+        // general purpose bit flag
+        if( entry.getMethod() == DEFLATED )
+        {
+            // requires version 2 as we are going to store length info
+            // in the data descriptor
+            out.write( ( new ZipShort( 20 ) ).getBytes() );
+
+            // bit3 set to signal, we use a data descriptor
+            out.write( ( new ZipShort( 8 ) ).getBytes() );
+        }
+        else
+        {
+            out.write( ( new ZipShort( 10 ) ).getBytes() );
+            out.write( ZERO );
+        }
+        m_written += 4;
+
+        // compression method
+        out.write( ( new ZipShort( entry.getMethod() ) ).getBytes() );
+        m_written += 2;
+
+        // last mod. time and date
+        out.write( toDosTime( new Date( entry.getTime() ) ).getBytes() );
+        m_written += 4;
+
+        // CRC
+        // compressed length
+        // uncompressed length
+        out.write( ( new ZipLong( entry.getCrc() ) ).getBytes() );
+        out.write( ( new ZipLong( entry.getCompressedSize() ) ).getBytes() );
+        out.write( ( new ZipLong( entry.getSize() ) ).getBytes() );
+        m_written += 12;
+
+        // file name length
+        byte[] name = getBytes( entry.getName() );
+        out.write( ( new ZipShort( name.length ) ).getBytes() );
+        m_written += 2;
+
+        // extra field length
+        byte[] extra = entry.getCentralDirectoryExtra();
+        out.write( ( new ZipShort( extra.length ) ).getBytes() );
+        m_written += 2;
+
+        // file comment length
+        String comm = entry.getComment();
+        if( comm == null )
+        {
+            comm = "";
+        }
+        byte[] comment = getBytes( comm );
+        out.write( ( new ZipShort( comment.length ) ).getBytes() );
+        m_written += 2;
+
+        // disk number start
+        out.write( ZERO );
+        m_written += 2;
+
+        // internal file attributes
+        out.write( ( new ZipShort( entry.getInternalAttributes() ) ).getBytes() );
+        m_written += 2;
+
+        // external file attributes
+        out.write( ( new ZipLong( entry.getExternalAttributes() ) ).getBytes() );
+        m_written += 4;
+
+        // relative offset of LFH
+        out.write( ( (ZipLong)m_offsets.get( entry ) ).getBytes() );
+        m_written += 4;
+
+        // file name
+        out.write( name );
+        m_written += name.length;
+
+        // extra field
+        out.write( extra );
+        m_written += extra.length;
+
+        // file comment
+        out.write( comment );
+        m_written += comment.length;
+    }
+
+    /**
+     * Writes the data descriptor entry
+     *
+     * @param ze Description of Parameter
+     * @throws IOException if an IO failure causes operation to fail
+     * @since 1.1
+     */
+    protected void writeDataDescriptor( ZipArchiveEntry ze )
+        throws IOException
+    {
+        if( ze.getMethod() != DEFLATED )
+        {
+            return;
+        }
+        out.write( DD_SIG.getBytes() );
+        out.write( ( new ZipLong( m_entry.getCrc() ) ).getBytes() );
+        out.write( ( new ZipLong( m_entry.getCompressedSize() ) ).getBytes() );
+        out.write( ( new ZipLong( m_entry.getSize() ) ).getBytes() );
+        m_written += 16;
+    }
+
+    /**
+     * Writes the local file header entry
+     *
+     * @param entry the zip entry
+     * @exception IOException when an IO error causes operation to fail
+     * @since 1.1
+     */
+    protected void writeLocalFileHeader( final ZipArchiveEntry entry )
+        throws IOException
+    {
+        m_offsets.put( entry, new ZipLong( m_written ) );
+
+        out.write( LFH_SIG.getBytes() );
+        m_written += 4;
+
+        // version needed to extract
+        // general purpose bit flag
+        if( entry.getMethod() == DEFLATED )
+        {
+            // requires version 2 as we are going to store length info
+            // in the data descriptor
+            out.write( ( new ZipShort( 20 ) ).getBytes() );
+
+            // bit3 set to signal, we use a data descriptor
+            out.write( ( new ZipShort( 8 ) ).getBytes() );
+        }
+        else
+        {
+            out.write( ( new ZipShort( 10 ) ).getBytes() );
+            out.write( ZERO );
+        }
+        m_written += 4;
+
+        // compression method
+        out.write( ( new ZipShort( entry.getMethod() ) ).getBytes() );
+        m_written += 2;
+
+        // last mod. time and date
+        out.write( toDosTime( new Date( entry.getTime() ) ).getBytes() );
+        m_written += 4;
+
+        // CRC
+        // compressed length
+        // uncompressed length
+        if( entry.getMethod() == DEFLATED )
+        {
+            out.write( LZERO );
+            out.write( LZERO );
+            out.write( LZERO );
+        }
+        else
+        {
+            out.write( ( new ZipLong( entry.getCrc() ) ).getBytes() );
+            out.write( ( new ZipLong( entry.getSize() ) ).getBytes() );
+            out.write( ( new ZipLong( entry.getSize() ) ).getBytes() );
+        }
+        m_written += 12;
+
+        // file name length
+        byte[] name = getBytes( entry.getName() );
+        out.write( ( new ZipShort( name.length ) ).getBytes() );
+        m_written += 2;
+
+        // extra field length
+        byte[] extra = entry.getLocalFileDataExtra();
+        out.write( ( new ZipShort( extra.length ) ).getBytes() );
+        m_written += 2;
+
+        // file name
+        out.write( name );
+        m_written += name.length;
+
+        // extra field
+        out.write( extra );
+        m_written += extra.length;
+
+        m_dataStart = m_written;
+    }
+
+}
diff --git a/src/main/java/org/apache/commons/compress/archivers/zip/ZipShort.java b/src/main/java/org/apache/commons/compress/archivers/zip/ZipShort.java
new file mode 100644
index 0000000..06213a4
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/archivers/zip/ZipShort.java
@@ -0,0 +1,118 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.zip;
+
+/**
+ * Utility class that represents a two byte integer with conversion rules for
+ * the big endian byte order of ZIP files.
+ *
+ * @author <a href="mailto:stefan.bodewig@epost.de">Stefan Bodewig</a>
+ * @version $Revision$
+ */
+public final class ZipShort implements Cloneable
+{
+    private int m_value;
+
+    /**
+     * Create instance from a number.
+     *
+     * @param value Description of Parameter
+     * @since 1.1
+     */
+    public ZipShort( int value )
+    {
+        this.m_value = value;
+    }
+
+    /**
+     * Create instance from bytes.
+     *
+     * @param bytes Description of Parameter
+     * @since 1.1
+     */
+    public ZipShort( byte[] bytes )
+    {
+        this( bytes, 0 );
+    }
+
+    /**
+     * Create instance from the two bytes starting at offset.
+     *
+     * @param bytes Description of Parameter
+     * @param offset Description of Parameter
+     * @since 1.1
+     */
+    public ZipShort( byte[] bytes, int offset )
+    {
+        m_value = ( bytes[ offset + 1 ] << 8 ) & 0xFF00;
+        m_value += ( bytes[ offset ] & 0xFF );
+    }
+
+    /**
+     * Get value as two bytes in big endian byte order.
+     *
+     * @return The Bytes value
+     * @since 1.1
+     */
+    public byte[] getBytes()
+    {
+        byte[] result = new byte[ 2 ];
+        result[ 0 ] = (byte)( m_value & 0xFF );
+        result[ 1 ] = (byte)( ( m_value & 0xFF00 ) >> 8 );
+        return result;
+    }
+
+    /**
+     * Get value as Java int.
+     *
+     * @return The Value value
+     * @since 1.1
+     */
+    public int getValue()
+    {
+        return m_value;
+    }
+
+    /**
+     * Override to make two instances with same value equal.
+     *
+     * @param o Description of Parameter
+     * @return Description of the Returned Value
+     * @since 1.1
+     */
+    public boolean equals( Object o )
+    {
+        if( o == null || !( o instanceof ZipShort ) )
+        {
+            return false;
+        }
+        return m_value == ( (ZipShort)o ).getValue();
+    }
+
+    /**
+     * Override to make two instances with same value equal.
+     *
+     * @return Description of the Returned Value
+     * @since 1.1
+     */
+    public int hashCode()
+    {
+        return m_value;
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/changes/Change.java b/src/main/java/org/apache/commons/compress/changes/Change.java
new file mode 100644
index 0000000..0ca960f
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/changes/Change.java
@@ -0,0 +1,15 @@
+/**
+ * 
+ */
+package org.apache.commons.compress.changes;
+
+import org.apache.commons.compress.archivers.ArchiveInputStream;
+
+/**
+ * @author Cy
+ *
+ */
+interface Change {
+	// public void perform(ArchiveInputStream input);
+	public int type();
+}
diff --git a/src/main/java/org/apache/commons/compress/changes/ChangeSet.java b/src/main/java/org/apache/commons/compress/changes/ChangeSet.java
new file mode 100644
index 0000000..0b4c7b4
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/changes/ChangeSet.java
@@ -0,0 +1,49 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.changes;
+
+import java.io.InputStream;
+import java.util.LinkedHashSet;
+import java.util.Set;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+
+
+public final class ChangeSet {
+
+	private final Set changes = new LinkedHashSet();
+	
+	public static final int CHANGE_TYPE_DELETE = 1;
+	public static final int CHANGE_TYPE_ADD = 2;
+	
+
+	public void delete( final String pFilename ) {
+		changes.add(new DeleteChange(pFilename));
+	}
+
+	public void move( final String pFrom, final String pTo ) {
+	}
+	
+	public void add( final ArchiveEntry pEntry, final InputStream pInput) {
+	}
+	
+	public Set asSet() {
+		return changes;
+	}
+}
diff --git a/src/main/java/org/apache/commons/compress/changes/ChangeWorker.java b/src/main/java/org/apache/commons/compress/changes/ChangeWorker.java
new file mode 100644
index 0000000..23edefd
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/changes/ChangeWorker.java
@@ -0,0 +1,79 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.changes;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.Iterator;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.ArchiveInputStream;
+import org.apache.commons.compress.archivers.ArchiveOutputStream;
+import org.apache.commons.compress.utils.IOUtils;
+
+/**
+ * Performs the operations of a change set
+ */
+public class ChangeWorker {
+	private ChangeWorker() {
+		// nothing to do
+	}
+	
+	/**
+	 * TODO
+	 * @param changes
+	 * @param in
+	 * @param out
+	 * @throws IOException 
+	 */
+	public static void perform(ChangeSet changes, ArchiveInputStream in, ArchiveOutputStream out) throws IOException {
+		ArchiveEntry entry = null;	
+		while((entry = in.getNextEntry()) != null) {
+			System.out.println(entry.getName());
+			boolean copy = true; 
+			
+			for (Iterator it = changes.asSet().iterator(); it.hasNext();) {
+				Change change = (Change)it.next();
+				
+				if(change.type() == ChangeSet.CHANGE_TYPE_DELETE) {
+					DeleteChange delete = ((DeleteChange)change);
+					if(entry.getName() != null &&
+					   entry.getName().equals(delete.targetFile())) {
+						copy = false;
+					}
+				}
+			}
+			
+			if(copy) {
+				// copy archive
+				// TODO: unsafe long to int 
+				System.out.println("Copy: " + entry.getName());
+				long size = entry.getSize();
+				out.putArchiveEntry(entry);
+				IOUtils.copy((InputStream)in, out, (int)size);
+				out.closeArchiveEntry();
+			}
+			
+			
+			System.out.println("---");
+		}
+		// add operation stuff
+		out.close();
+	}
+}
diff --git a/src/main/java/org/apache/commons/compress/changes/DeleteChange.java b/src/main/java/org/apache/commons/compress/changes/DeleteChange.java
new file mode 100644
index 0000000..f75c4e4
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/changes/DeleteChange.java
@@ -0,0 +1,37 @@
+/**
+ * 
+ */
+package org.apache.commons.compress.changes;
+
+import org.apache.commons.compress.archivers.ArchiveInputStream;
+
+/**
+ * Implementation for a delete operation
+ */
+class DeleteChange implements Change {
+	private String filename = null;
+	
+	/**
+	 * Constructor. Takes the filename of the file to be deleted
+	 * from the stream as argument.
+	 * @param pFilename the filename of the file to delete
+	 */
+	public DeleteChange(final String pFilename) {
+		if(pFilename == null) {
+			throw new NullPointerException();
+		}
+		filename = pFilename;
+	}
+	
+	public void perform(ArchiveInputStream input) {
+		System.out.println("PERFORMING DELETE");
+	}
+
+	public String targetFile() {
+		return filename;
+	}
+	
+	public int type() {
+		return ChangeSet.CHANGE_TYPE_DELETE;
+	}
+}
diff --git a/src/main/java/org/apache/commons/compress/compressors/CompressorException.java b/src/main/java/org/apache/commons/compress/compressors/CompressorException.java
new file mode 100644
index 0000000..01fe07d
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/compressors/CompressorException.java
@@ -0,0 +1,28 @@
+/**
+ * 
+ */
+package org.apache.commons.compress.compressors;
+
+/**
+ *
+ */
+public class CompressorException extends Exception {
+	/* Serial */
+	private static final long serialVersionUID = -2770299103090672278L;
+
+	public CompressorException() {
+		super();
+	}
+
+	public CompressorException(String arg0, Throwable arg1) {
+		super(arg0, arg1);
+	}
+
+	public CompressorException(String arg0) {
+		super(arg0);
+	}
+
+	public CompressorException(Throwable arg0) {
+		super(arg0);
+	}
+}
diff --git a/src/main/java/org/apache/commons/compress/compressors/CompressorInputStream.java b/src/main/java/org/apache/commons/compress/compressors/CompressorInputStream.java
new file mode 100644
index 0000000..6553faa
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/compressors/CompressorInputStream.java
@@ -0,0 +1,25 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.compressors;
+
+import java.io.InputStream;
+
+public abstract class CompressorInputStream extends InputStream {
+	// TODO 
+}
diff --git a/src/main/java/org/apache/commons/compress/compressors/CompressorOutputStream.java b/src/main/java/org/apache/commons/compress/compressors/CompressorOutputStream.java
new file mode 100644
index 0000000..759e7e5
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/compressors/CompressorOutputStream.java
@@ -0,0 +1,26 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.compressors;
+
+import java.io.OutputStream;
+
+
+public abstract class CompressorOutputStream extends OutputStream {
+	// TODO
+}
diff --git a/src/main/java/org/apache/commons/compress/compressors/CompressorStreamFactory.java b/src/main/java/org/apache/commons/compress/compressors/CompressorStreamFactory.java
new file mode 100644
index 0000000..e50e999
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/compressors/CompressorStreamFactory.java
@@ -0,0 +1,97 @@
+package org.apache.commons.compress.compressors;
+
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.lang.reflect.Constructor;
+import java.lang.reflect.InvocationTargetException;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.commons.compress.archivers.ArchiveException;
+import org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;
+import org.apache.commons.compress.compressors.bzip2.BZip2CompressorOutputStream;
+import org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream;
+import org.apache.commons.compress.compressors.gzip.GzipCompressorOutputStream;
+
+public class CompressorStreamFactory {
+	final Map inputStreamClasses = new HashMap();
+	final Map outputStreamClasses = new HashMap();
+	
+	public CompressorStreamFactory() throws CompressorException {
+		registerInputStream("gz", GzipCompressorInputStream.class);
+		registerOutputStream("gz", GzipCompressorOutputStream.class);
+		registerInputStream("bzip2", BZip2CompressorInputStream.class);
+		registerOutputStream("bzip2", BZip2CompressorOutputStream.class);
+		
+	}
+	
+	public void registerInputStream( final String name, final Class stream ) throws CompressorException {
+		if (CompressorInputStream.class.isAssignableFrom(stream) && !(stream.isInterface())) {
+			inputStreamClasses.put(name, stream);
+        } else {
+            throw new CompressorException("Compressor does not implement the CompressorInputStream interface.");
+        }	
+	}
+
+	public void registerOutputStream( final String name, final Class stream ) throws CompressorException {
+		if (CompressorOutputStream.class.isAssignableFrom(stream) && !(stream.isInterface())) {
+			outputStreamClasses.put(name, stream);
+        } else {
+            throw new CompressorException("Compressor does not implement the CompressorOutputStream interface.");
+        }
+	}
+	
+	public CompressorInputStream createCompressorInputStream( final String name, final InputStream out ) throws CompressorException {
+        try {
+            final Class clazz = (Class) inputStreamClasses.get(name);
+
+            if (clazz == null) {
+            	throw new CompressorException("CompressorFactory could not create instance");
+            }
+
+            final Class[] params = { InputStream.class };
+            final Constructor constructor = clazz.getConstructor(params);
+            final Object[] initargs = { out };
+            return (CompressorInputStream) constructor.newInstance(initargs);
+        } catch (InstantiationException e) {
+            throw new CompressorException("CompressorFactory could not create instance", e);
+        } catch (IllegalAccessException e) {
+            throw new CompressorException("CompressorFactory could not create instance", e);
+        } catch (SecurityException e) {
+            throw new CompressorException("CompressorFactory could not create instance", e);
+        } catch (NoSuchMethodException e) {
+            throw new CompressorException("CompressorFactory could not create instance", e);
+        } catch (IllegalArgumentException e) {
+            throw new CompressorException("CompressorFactory could not create instance", e);
+        } catch (InvocationTargetException e) {
+            throw new CompressorException("CompressorFactory could not create instance", e);
+        }
+    }
+
+    public CompressorOutputStream createCompressorOutputStream( final String name, final OutputStream out ) throws ArchiveException {
+        try {
+            final Class clazz = (Class) outputStreamClasses.get(name);
+            
+            if (clazz == null) {
+            	throw new ArchiveException("CompressorFactory could not create instance");
+            }
+            
+            final Class[] params = { OutputStream.class };
+            final Constructor constructor = clazz.getConstructor(params);
+            final Object[] initargs = { out };
+            return (CompressorOutputStream) constructor.newInstance(initargs);
+        } catch (InstantiationException e) {
+            throw new ArchiveException("CompressorFactory could not create instance", e);
+        } catch (IllegalAccessException e) {
+            throw new ArchiveException("CompressorFactory could not create instance", e);
+        } catch (SecurityException e) {
+            throw new ArchiveException("CompressorFactory could not create instance", e);
+        } catch (NoSuchMethodException e) {
+            throw new ArchiveException("CompressorFactory could not create instance", e);
+        } catch (IllegalArgumentException e) {
+            throw new ArchiveException("CompressorFactory could not create instance", e);
+        } catch (InvocationTargetException e) {
+            throw new ArchiveException("CompressorFactory could not create instance", e);
+        }
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2CompressorInputStream.java b/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2CompressorInputStream.java
new file mode 100644
index 0000000..cbca548
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2CompressorInputStream.java
@@ -0,0 +1,841 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.compressors.bzip2;
+
+import java.io.IOException;
+import java.io.InputStream;
+
+import org.apache.commons.compress.compressors.CompressorInputStream;
+
+/*
+ * This package is based on the work done by Keiron Liddle, Aftex Software
+ * <keiron@aftexsw.com> to whom the Ant project is very grateful for his great
+ * code. 
+ */
+
+/**
+ * An input stream that decompresses from the BZip2 format (without the file
+ * header chars) to be read as any other stream.
+ * 
+ * @author <a href="mailto:keiron@aftexsw.com">Keiron Liddle</a>
+ */
+public class BZip2CompressorInputStream extends CompressorInputStream implements BZip2Constants {
+
+    private static void cadvise() {
+        System.out.println("CRC Error");
+        //throw new CCoruptionError();
+    }
+
+    private static void badBGLengths() {
+        cadvise();
+    }
+
+    private static void bitStreamEOF() {
+        cadvise();
+    }
+
+    private static void compressedStreamEOF() {
+        cadvise();
+    }
+
+    private void makeMaps() {
+        int i;
+        nInUse = 0;
+        for (i = 0; i < 256; i++) {
+            if (inUse[i]) {
+                seqToUnseq[nInUse] = (char) i;
+                unseqToSeq[i] = (char) nInUse;
+                nInUse++;
+            }
+        }
+    }
+
+    /*
+      index of the last char in the block, so
+      the block size == last + 1.
+    */
+    private int  last;
+
+    /*
+      index in zptr[] of original string after sorting.
+    */
+    private int  origPtr;
+
+    /*
+      always: in the range 0 .. 9.
+      The current block size is 100000 * this number.
+    */
+    private int blockSize100k;
+
+    private boolean blockRandomised;
+
+    private int bsBuff;
+    private int bsLive;
+    private CRC mCrc = new CRC();
+
+    private boolean[] inUse = new boolean[256];
+    private int nInUse;
+
+    private char[] seqToUnseq = new char[256];
+    private char[] unseqToSeq = new char[256];
+
+    private char[] selector = new char[MAX_SELECTORS];
+    private char[] selectorMtf = new char[MAX_SELECTORS];
+
+    private int[] tt;
+    private char[] ll8;
+
+    /*
+      freq table collected to save a pass over the data
+      during decompression.
+    */
+    private int[] unzftab = new int[256];
+
+    private int[][] limit = new int[N_GROUPS][MAX_ALPHA_SIZE];
+    private int[][] base = new int[N_GROUPS][MAX_ALPHA_SIZE];
+    private int[][] perm = new int[N_GROUPS][MAX_ALPHA_SIZE];
+    private int[] minLens = new int[N_GROUPS];
+
+    private InputStream bsStream;
+
+    private boolean streamEnd = false;
+
+    private int currentChar = -1;
+
+    private static final int START_BLOCK_STATE = 1;
+    private static final int RAND_PART_A_STATE = 2;
+    private static final int RAND_PART_B_STATE = 3;
+    private static final int RAND_PART_C_STATE = 4;
+    private static final int NO_RAND_PART_A_STATE = 5;
+    private static final int NO_RAND_PART_B_STATE = 6;
+    private static final int NO_RAND_PART_C_STATE = 7;
+
+    private int currentState = START_BLOCK_STATE;
+
+    private int storedBlockCRC, storedCombinedCRC;
+    private int computedBlockCRC, computedCombinedCRC;
+
+    int i2, count, chPrev, ch2;
+    int i, tPos;
+    int rNToGo = 0;
+    int rTPos  = 0;
+    int j2;
+    char z;
+
+    public BZip2CompressorInputStream(InputStream zStream) {
+        ll8 = null;
+        tt = null;
+        bsSetStream(zStream);
+        initialize();
+        initBlock();
+        setupBlock();
+    }
+
+    public int read() {
+        if (streamEnd) {
+            return -1;
+        } else {
+            int retChar = currentChar;
+            switch(currentState) {
+            case START_BLOCK_STATE:
+                break;
+            case RAND_PART_A_STATE:
+                break;
+            case RAND_PART_B_STATE:
+                setupRandPartB();
+                break;
+            case RAND_PART_C_STATE:
+                setupRandPartC();
+                break;
+            case NO_RAND_PART_A_STATE:
+                break;
+            case NO_RAND_PART_B_STATE:
+                setupNoRandPartB();
+                break;
+            case NO_RAND_PART_C_STATE:
+                setupNoRandPartC();
+                break;
+            default:
+                break;
+            }
+            return retChar;
+        }
+    }
+
+    private void initialize() {
+        char magic3, magic4;
+        magic3 = bsGetUChar();
+        magic4 = bsGetUChar();
+        if (magic3 != 'h' || magic4 < '1' || magic4 > '9') {
+            bsFinishedWithStream();
+            streamEnd = true;
+            return;
+        }
+
+        setDecompressStructureSizes(magic4 - '0');
+        computedCombinedCRC = 0;
+    }
+
+    private void initBlock() {
+        char magic1, magic2, magic3, magic4;
+        char magic5, magic6;
+        magic1 = bsGetUChar();
+        magic2 = bsGetUChar();
+        magic3 = bsGetUChar();
+        magic4 = bsGetUChar();
+        magic5 = bsGetUChar();
+        magic6 = bsGetUChar();
+        if (magic1 == 0x17 && magic2 == 0x72 && magic3 == 0x45
+            && magic4 == 0x38 && magic5 == 0x50 && magic6 == 0x90) {
+            complete();
+            return;
+        }
+
+        if (magic1 != 0x31 || magic2 != 0x41 || magic3 != 0x59
+            || magic4 != 0x26 || magic5 != 0x53 || magic6 != 0x59) {
+            badBlockHeader();
+            streamEnd = true;
+            return;
+        }
+
+        storedBlockCRC = bsGetInt32();
+
+        if (bsR(1) == 1) {
+            blockRandomised = true;
+        } else {
+            blockRandomised = false;
+        }
+
+        //        currBlockNo++;
+        getAndMoveToFrontDecode();
+
+        mCrc.initialiseCRC();
+        currentState = START_BLOCK_STATE;
+    }
+
+    private void endBlock() {
+        computedBlockCRC = mCrc.getFinalCRC();
+        /* A bad CRC is considered a fatal error. */
+        if (storedBlockCRC != computedBlockCRC) {
+            crcError();
+        }
+
+        computedCombinedCRC = (computedCombinedCRC << 1)
+            | (computedCombinedCRC >>> 31);
+        computedCombinedCRC ^= computedBlockCRC;
+    }
+
+    private void complete() {
+        storedCombinedCRC = bsGetInt32();
+        if (storedCombinedCRC != computedCombinedCRC) {
+            crcError();
+        }
+
+        bsFinishedWithStream();
+        streamEnd = true;
+    }
+
+    private static void blockOverrun() {
+        cadvise();
+    }
+
+    private static void badBlockHeader() {
+        cadvise();
+    }
+
+    private static void crcError() {
+        cadvise();
+    }
+
+    private void bsFinishedWithStream() {
+        try {
+            if (this.bsStream != null) {
+                if (this.bsStream != System.in) {
+                    this.bsStream.close();
+                    this.bsStream = null;
+                }
+            }
+        } catch (IOException ioe) {
+            //ignore
+        }
+    }
+
+    private void bsSetStream(InputStream f) {
+        bsStream = f;
+        bsLive = 0;
+        bsBuff = 0;
+    }
+
+    private int bsR(int n) {
+        int v;
+        while (bsLive < n) {
+            int zzi;
+            char thech = 0;
+            try {
+                thech = (char) bsStream.read();
+            } catch (IOException e) {
+                compressedStreamEOF();
+            }
+            if (thech == -1) {
+                compressedStreamEOF();
+            }
+            zzi = thech;
+            bsBuff = (bsBuff << 8) | (zzi & 0xff);
+            bsLive += 8;
+        }
+
+        v = (bsBuff >> (bsLive - n)) & ((1 << n) - 1);
+        bsLive -= n;
+        return v;
+    }
+
+    private char bsGetUChar() {
+        return (char) bsR(8);
+    }
+
+    private int bsGetint() {
+        int u = 0;
+        u = (u << 8) | bsR(8);
+        u = (u << 8) | bsR(8);
+        u = (u << 8) | bsR(8);
+        u = (u << 8) | bsR(8);
+        return u;
+    }
+
+    private int bsGetIntVS(int numBits) {
+        return (int) bsR(numBits);
+    }
+
+    private int bsGetInt32() {
+        return (int) bsGetint();
+    }
+
+    private void hbCreateDecodeTables(int[] limit, int[] base,
+                                      int[] perm, char[] length,
+                                      int minLen, int maxLen, int alphaSize) {
+        int pp, i, j, vec;
+
+        pp = 0;
+        for (i = minLen; i <= maxLen; i++) {
+            for (j = 0; j < alphaSize; j++) {
+                if (length[j] == i) {
+                    perm[pp] = j;
+                    pp++;
+                }
+            }
+        }
+
+        for (i = 0; i < MAX_CODE_LEN; i++) {
+            base[i] = 0;
+        }
+        for (i = 0; i < alphaSize; i++) {
+            base[length[i] + 1]++;
+        }
+
+        for (i = 1; i < MAX_CODE_LEN; i++) {
+            base[i] += base[i - 1];
+        }
+
+        for (i = 0; i < MAX_CODE_LEN; i++) {
+            limit[i] = 0;
+        }
+        vec = 0;
+
+        for (i = minLen; i <= maxLen; i++) {
+            vec += (base[i + 1] - base[i]);
+            limit[i] = vec - 1;
+            vec <<= 1;
+        }
+        for (i = minLen + 1; i <= maxLen; i++) {
+            base[i] = ((limit[i - 1] + 1) << 1) - base[i];
+        }
+    }
+
+    private void recvDecodingTables() {
+        char len[][] = new char[N_GROUPS][MAX_ALPHA_SIZE];
+        int i, j, t, nGroups, nSelectors, alphaSize;
+        int minLen, maxLen;
+        boolean[] inUse16 = new boolean[16];
+
+        /* Receive the mapping table */
+        for (i = 0; i < 16; i++) {
+            if (bsR(1) == 1) {
+                inUse16[i] = true;
+            } else {
+                inUse16[i] = false;
+            }
+        }
+
+        for (i = 0; i < 256; i++) {
+            inUse[i] = false;
+        }
+
+        for (i = 0; i < 16; i++) {
+            if (inUse16[i]) {
+                for (j = 0; j < 16; j++) {
+                    if (bsR(1) == 1) {
+                        inUse[i * 16 + j] = true;
+                    }
+                }
+            }
+        }
+
+        makeMaps();
+        alphaSize = nInUse + 2;
+
+        /* Now the selectors */
+        nGroups = bsR(3);
+        nSelectors = bsR(15);
+        for (i = 0; i < nSelectors; i++) {
+            j = 0;
+            while (bsR(1) == 1) {
+                j++;
+            }
+            selectorMtf[i] = (char) j;
+        }
+
+        /* Undo the MTF values for the selectors. */
+        {
+            char[] pos = new char[N_GROUPS];
+            char tmp, v;
+            for (v = 0; v < nGroups; v++) {
+                pos[v] = v;
+            }
+
+            for (i = 0; i < nSelectors; i++) {
+                v = selectorMtf[i];
+                tmp = pos[v];
+                while (v > 0) {
+                    pos[v] = pos[v - 1];
+                    v--;
+                }
+                pos[0] = tmp;
+                selector[i] = tmp;
+            }
+        }
+
+        /* Now the coding tables */
+        for (t = 0; t < nGroups; t++) {
+            int curr = bsR(5);
+            for (i = 0; i < alphaSize; i++) {
+                while (bsR(1) == 1) {
+                    if (bsR(1) == 0) {
+                        curr++;
+                    } else {
+                        curr--;
+                    }
+                }
+                len[t][i] = (char) curr;
+            }
+        }
+
+        /* Create the Huffman decoding tables */
+        for (t = 0; t < nGroups; t++) {
+            minLen = 32;
+            maxLen = 0;
+            for (i = 0; i < alphaSize; i++) {
+                if (len[t][i] > maxLen) {
+                    maxLen = len[t][i];
+                }
+                if (len[t][i] < minLen) {
+                    minLen = len[t][i];
+                }
+            }
+            hbCreateDecodeTables(limit[t], base[t], perm[t], len[t], minLen,
+                                 maxLen, alphaSize);
+            minLens[t] = minLen;
+        }
+    }
+
+    private void getAndMoveToFrontDecode() {
+        char[] yy = new char[256];
+        int i, j, nextSym, limitLast;
+        int EOB, groupNo, groupPos;
+
+        limitLast = baseBlockSize * blockSize100k;
+        origPtr = bsGetIntVS(24);
+
+        recvDecodingTables();
+        EOB = nInUse + 1;
+        groupNo = -1;
+        groupPos = 0;
+
+        /*
+          Setting up the unzftab entries here is not strictly
+          necessary, but it does save having to do it later
+          in a separate pass, and so saves a block's worth of
+          cache misses.
+        */
+        for (i = 0; i <= 255; i++) {
+            unzftab[i] = 0;
+        }
+
+        for (i = 0; i <= 255; i++) {
+            yy[i] = (char) i;
+        }
+
+        last = -1;
+
+        {
+            int zt, zn, zvec, zj;
+            if (groupPos == 0) {
+                groupNo++;
+                groupPos = G_SIZE;
+            }
+            groupPos--;
+            zt = selector[groupNo];
+            zn = minLens[zt];
+            zvec = bsR(zn);
+            while (zvec > limit[zt][zn]) {
+                zn++;
+                {
+                    {
+                        while (bsLive < 1) {
+                            int zzi;
+                            char thech = 0;
+                            try {
+                                thech = (char) bsStream.read();
+                            } catch (IOException e) {
+                                compressedStreamEOF();
+                            }
+                            if (thech == -1) {
+                                compressedStreamEOF();
+                            }
+                            zzi = thech;
+                            bsBuff = (bsBuff << 8) | (zzi & 0xff);
+                            bsLive += 8;
+                        }
+                    }
+                    zj = (bsBuff >> (bsLive - 1)) & 1;
+                    bsLive--;
+                }
+                zvec = (zvec << 1) | zj;
+            }
+            nextSym = perm[zt][zvec - base[zt][zn]];
+        }
+
+        while (true) {
+
+            if (nextSym == EOB) {
+                break;
+            }
+
+            if (nextSym == RUNA || nextSym == RUNB) {
+                char ch;
+                int s = -1;
+                int N = 1;
+                do {
+                    if (nextSym == RUNA) {
+                        s = s + (0 + 1) * N;
+                    } else if (nextSym == RUNB) {
+                        s = s + (1 + 1) * N;
+                           }
+                    N = N * 2;
+                    {
+                        int zt, zn, zvec, zj;
+                        if (groupPos == 0) {
+                            groupNo++;
+                            groupPos = G_SIZE;
+                        }
+                        groupPos--;
+                        zt = selector[groupNo];
+                        zn = minLens[zt];
+                        zvec = bsR(zn);
+                        while (zvec > limit[zt][zn]) {
+                            zn++;
+                            {
+                                {
+                                    while (bsLive < 1) {
+                                        int zzi;
+                                        char thech = 0;
+                                        try {
+                                            thech = (char) bsStream.read();
+                                        } catch (IOException e) {
+                                            compressedStreamEOF();
+                                        }
+                                        if (thech == -1) {
+                                            compressedStreamEOF();
+                                        }
+                                        zzi = thech;
+                                        bsBuff = (bsBuff << 8) | (zzi & 0xff);
+                                        bsLive += 8;
+                                    }
+                                }
+                                zj = (bsBuff >> (bsLive - 1)) & 1;
+                                bsLive--;
+                            }
+                            zvec = (zvec << 1) | zj;
+                        }
+                        nextSym = perm[zt][zvec - base[zt][zn]];
+                    }
+                } while (nextSym == RUNA || nextSym == RUNB);
+
+                s++;
+                ch = seqToUnseq[yy[0]];
+                unzftab[ch] += s;
+
+                while (s > 0) {
+                    last++;
+                    ll8[last] = ch;
+                    s--;
+                }
+
+                if (last >= limitLast) {
+                    blockOverrun();
+                }
+                continue;
+            } else {
+                char tmp;
+                last++;
+                if (last >= limitLast) {
+                    blockOverrun();
+                }
+
+                tmp = yy[nextSym - 1];
+                unzftab[seqToUnseq[tmp]]++;
+                ll8[last] = seqToUnseq[tmp];
+
+                /*
+                  This loop is hammered during decompression,
+                  hence the unrolling.
+
+                  for (j = nextSym-1; j > 0; j--) yy[j] = yy[j-1];
+                */
+
+                j = nextSym - 1;
+                for (; j > 3; j -= 4) {
+                    yy[j]     = yy[j - 1];
+                    yy[j - 1] = yy[j - 2];
+                    yy[j - 2] = yy[j - 3];
+                    yy[j - 3] = yy[j - 4];
+                }
+                for (; j > 0; j--) {
+                    yy[j] = yy[j - 1];
+                }
+
+                yy[0] = tmp;
+                {
+                    int zt, zn, zvec, zj;
+                    if (groupPos == 0) {
+                        groupNo++;
+                        groupPos = G_SIZE;
+                    }
+                    groupPos--;
+                    zt = selector[groupNo];
+                    zn = minLens[zt];
+                    zvec = bsR(zn);
+                    while (zvec > limit[zt][zn]) {
+                        zn++;
+                        {
+                            {
+                                while (bsLive < 1) {
+                                    int zzi;
+                                    char thech = 0;
+                                    try {
+                                        thech = (char) bsStream.read();
+                                    } catch (IOException e) {
+                                        compressedStreamEOF();
+                                    }
+                                    zzi = thech;
+                                    bsBuff = (bsBuff << 8) | (zzi & 0xff);
+                                    bsLive += 8;
+                                }
+                            }
+                            zj = (bsBuff >> (bsLive - 1)) & 1;
+                            bsLive--;
+                        }
+                        zvec = (zvec << 1) | zj;
+                    }
+                    nextSym = perm[zt][zvec - base[zt][zn]];
+                }
+                continue;
+            }
+        }
+    }
+
+    private void setupBlock() {
+        int[] cftab = new int[257];
+        char ch;
+
+        cftab[0] = 0;
+        for (i = 1; i <= 256; i++) {
+            cftab[i] = unzftab[i - 1];
+        }
+        for (i = 1; i <= 256; i++) {
+            cftab[i] += cftab[i - 1];
+        }
+
+        for (i = 0; i <= last; i++) {
+            ch = (char) ll8[i];
+            tt[cftab[ch]] = i;
+            cftab[ch]++;
+        }
+        cftab = null;
+
+        tPos = tt[origPtr];
+
+        count = 0;
+        i2 = 0;
+        ch2 = 256;   /* not a char and not EOF */
+
+        if (blockRandomised) {
+            rNToGo = 0;
+            rTPos = 0;
+            setupRandPartA();
+        } else {
+            setupNoRandPartA();
+        }
+    }
+
+    private void setupRandPartA() {
+        if (i2 <= last) {
+            chPrev = ch2;
+            ch2 = ll8[tPos];
+            tPos = tt[tPos];
+            if (rNToGo == 0) {
+                rNToGo = rNums[rTPos];
+                rTPos++;
+                if (rTPos == 512) {
+                    rTPos = 0;
+                }
+            }
+            rNToGo--;
+            ch2 ^= (int) ((rNToGo == 1) ? 1 : 0);
+            i2++;
+
+            currentChar = ch2;
+            currentState = RAND_PART_B_STATE;
+            mCrc.updateCRC(ch2);
+        } else {
+            endBlock();
+            initBlock();
+            setupBlock();
+        }
+    }
+
+    private void setupNoRandPartA() {
+        if (i2 <= last) {
+            chPrev = ch2;
+            ch2 = ll8[tPos];
+            tPos = tt[tPos];
+            i2++;
+
+            currentChar = ch2;
+            currentState = NO_RAND_PART_B_STATE;
+            mCrc.updateCRC(ch2);
+        } else {
+            endBlock();
+            initBlock();
+            setupBlock();
+        }
+    }
+
+    private void setupRandPartB() {
+        if (ch2 != chPrev) {
+            currentState = RAND_PART_A_STATE;
+            count = 1;
+            setupRandPartA();
+        } else {
+            count++;
+            if (count >= 4) {
+                z = ll8[tPos];
+                tPos = tt[tPos];
+                if (rNToGo == 0) {
+                    rNToGo = rNums[rTPos];
+                    rTPos++;
+                    if (rTPos == 512) {
+                        rTPos = 0;
+                    }
+                }
+                rNToGo--;
+                z ^= ((rNToGo == 1) ? 1 : 0);
+                j2 = 0;
+                currentState = RAND_PART_C_STATE;
+                setupRandPartC();
+            } else {
+                currentState = RAND_PART_A_STATE;
+                setupRandPartA();
+            }
+        }
+    }
+
+    private void setupRandPartC() {
+        if (j2 < (int) z) {
+            currentChar = ch2;
+            mCrc.updateCRC(ch2);
+            j2++;
+        } else {
+            currentState = RAND_PART_A_STATE;
+            i2++;
+            count = 0;
+            setupRandPartA();
+        }
+    }
+
+    private void setupNoRandPartB() {
+        if (ch2 != chPrev) {
+            currentState = NO_RAND_PART_A_STATE;
+            count = 1;
+            setupNoRandPartA();
+        } else {
+            count++;
+            if (count >= 4) {
+                z = ll8[tPos];
+                tPos = tt[tPos];
+                currentState = NO_RAND_PART_C_STATE;
+                j2 = 0;
+                setupNoRandPartC();
+            } else {
+                currentState = NO_RAND_PART_A_STATE;
+                setupNoRandPartA();
+            }
+        }
+    }
+
+    private void setupNoRandPartC() {
+        if (j2 < (int) z) {
+            currentChar = ch2;
+            mCrc.updateCRC(ch2);
+            j2++;
+        } else {
+            currentState = NO_RAND_PART_A_STATE;
+            i2++;
+            count = 0;
+            setupNoRandPartA();
+        }
+    }
+
+    private void setDecompressStructureSizes(int newSize100k) {
+        if (!(0 <= newSize100k && newSize100k <= 9 && 0 <= blockSize100k
+               && blockSize100k <= 9)) {
+            // throw new IOException("Invalid block size");
+        }
+
+        blockSize100k = newSize100k;
+
+        if (newSize100k == 0) {
+            return;
+        }
+
+        int n = baseBlockSize * newSize100k;
+        ll8 = new char[n];
+        tt = new int[n];
+    }
+}
+
diff --git a/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2CompressorOutputStream.java b/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2CompressorOutputStream.java
new file mode 100644
index 0000000..7885860
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2CompressorOutputStream.java
@@ -0,0 +1,1631 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.compressors.bzip2;
+
+import java.io.IOException;
+import java.io.OutputStream;
+
+import org.apache.commons.compress.compressors.CompressorOutputStream;
+
+/*
+ * This package is based on the work done by Keiron Liddle, Aftex Software
+ * <keiron@aftexsw.com> to whom the Ant project is very grateful for his great
+ * code. 
+ */
+/**
+ * An output stream that compresses into the BZip2 format (without the file
+ * header chars) into another stream. TODO: Update to BZip2 1.0.1
+ * 
+ * @author <a href="mailto:keiron@aftexsw.com">Keiron Liddle</a>
+ */
+public class BZip2CompressorOutputStream extends CompressorOutputStream implements BZip2Constants {
+	protected static final int SETMASK = (1 << 21);
+    protected static final int CLEARMASK = (~SETMASK);
+    protected static final int GREATER_ICOST = 15;
+    protected static final int LESSER_ICOST = 0;
+    protected static final int SMALL_THRESH = 20;
+    protected static final int DEPTH_THRESH = 10;
+
+    /*
+      If you are ever unlucky/improbable enough
+      to get a stack overflow whilst sorting,
+      increase the following constant and try
+      again.  In practice I have never seen the
+      stack go above 27 elems, so the following
+      limit seems very generous.
+    */
+    protected static final int QSORT_STACK_SIZE = 1000;
+
+    private static void panic() {
+        System.out.println("panic");
+        //throw new CError();
+    }
+
+    private void makeMaps() {
+        int i;
+        nInUse = 0;
+        for (i = 0; i < 256; i++) {
+            if (inUse[i]) {
+                seqToUnseq[nInUse] = (char) i;
+                unseqToSeq[i] = (char) nInUse;
+                nInUse++;
+            }
+        }
+    }
+
+    protected static void hbMakeCodeLengths(char[] len, int[] freq,
+                                            int alphaSize, int maxLen) {
+        /*
+          Nodes and heap entries run from 1.  Entry 0
+          for both the heap and nodes is a sentinel.
+        */
+        int nNodes, nHeap, n1, n2, i, j, k;
+        boolean  tooLong;
+
+        int[] heap = new int[MAX_ALPHA_SIZE + 2];
+        int[] weight = new int[MAX_ALPHA_SIZE * 2];
+        int[] parent = new int[MAX_ALPHA_SIZE * 2];
+
+        for (i = 0; i < alphaSize; i++) {
+            weight[i + 1] = (freq[i] == 0 ? 1 : freq[i]) << 8;
+        }
+
+        while (true) {
+            nNodes = alphaSize;
+            nHeap = 0;
+
+            heap[0] = 0;
+            weight[0] = 0;
+            parent[0] = -2;
+
+            for (i = 1; i <= alphaSize; i++) {
+                parent[i] = -1;
+                nHeap++;
+                heap[nHeap] = i;
+                {
+                    int zz, tmp;
+                    zz = nHeap;
+                    tmp = heap[zz];
+                    while (weight[tmp] < weight[heap[zz >> 1]]) {
+                        heap[zz] = heap[zz >> 1];
+                        zz >>= 1;
+                    }
+                    heap[zz] = tmp;
+                }
+            }
+            if (!(nHeap < (MAX_ALPHA_SIZE + 2))) {
+                panic();
+            }
+
+            while (nHeap > 1) {
+                n1 = heap[1];
+                heap[1] = heap[nHeap];
+                nHeap--;
+                {
+                    int zz = 0, yy = 0, tmp = 0;
+                    zz = 1;
+                    tmp = heap[zz];
+                    while (true) {
+                        yy = zz << 1;
+                        if (yy > nHeap) {
+                            break;
+                        }
+                        if (yy < nHeap
+                            && weight[heap[yy + 1]] < weight[heap[yy]]) {
+                            yy++;
+                        }
+                        if (weight[tmp] < weight[heap[yy]]) {
+                            break;
+                        }
+                        heap[zz] = heap[yy];
+                        zz = yy;
+                    }
+                    heap[zz] = tmp;
+                }
+                n2 = heap[1];
+                heap[1] = heap[nHeap];
+                nHeap--;
+                {
+                    int zz = 0, yy = 0, tmp = 0;
+                    zz = 1;
+                    tmp = heap[zz];
+                    while (true) {
+                        yy = zz << 1;
+                        if (yy > nHeap) {
+                            break;
+                        }
+                        if (yy < nHeap
+                            && weight[heap[yy + 1]] < weight[heap[yy]]) {
+                            yy++;
+                        }
+                        if (weight[tmp] < weight[heap[yy]]) {
+                            break;
+                        }
+                        heap[zz] = heap[yy];
+                        zz = yy;
+                    }
+                    heap[zz] = tmp;
+                }
+                nNodes++;
+                parent[n1] = parent[n2] = nNodes;
+
+                weight[nNodes] = ((weight[n1] & 0xffffff00)
+                                  + (weight[n2] & 0xffffff00))
+                    | (1 + (((weight[n1] & 0x000000ff) >
+                             (weight[n2] & 0x000000ff)) ?
+                            (weight[n1] & 0x000000ff) :
+                            (weight[n2] & 0x000000ff)));
+
+                parent[nNodes] = -1;
+                nHeap++;
+                heap[nHeap] = nNodes;
+                {
+                    int zz = 0, tmp = 0;
+                    zz = nHeap;
+                    tmp = heap[zz];
+                    while (weight[tmp] < weight[heap[zz >> 1]]) {
+                        heap[zz] = heap[zz >> 1];
+                        zz >>= 1;
+                    }
+                    heap[zz] = tmp;
+                }
+            }
+            if (!(nNodes < (MAX_ALPHA_SIZE * 2))) {
+                panic();
+            }
+
+            tooLong = false;
+            for (i = 1; i <= alphaSize; i++) {
+                j = 0;
+                k = i;
+                while (parent[k] >= 0) {
+                    k = parent[k];
+                    j++;
+                }
+                len[i - 1] = (char) j;
+                if (j > maxLen) {
+                    tooLong = true;
+                }
+            }
+
+            if (!tooLong) {
+                break;
+            }
+
+            for (i = 1; i < alphaSize; i++) {
+                j = weight[i] >> 8;
+                j = 1 + (j / 2);
+                weight[i] = j << 8;
+            }
+        }
+    }
+
+    /*
+      index of the last char in the block, so
+      the block size == last + 1.
+    */
+    int last;
+
+    /*
+      index in zptr[] of original string after sorting.
+    */
+    int origPtr;
+
+    /*
+      always: in the range 0 .. 9.
+      The current block size is 100000 * this number.
+    */
+    int blockSize100k;
+
+    boolean blockRandomised;
+
+    int bytesOut;
+    int bsBuff;
+    int bsLive;
+    CRC mCrc = new CRC();
+
+    private boolean[] inUse = new boolean[256];
+    private int nInUse;
+
+    private char[] seqToUnseq = new char[256];
+    private char[] unseqToSeq = new char[256];
+
+    private char[] selector = new char[MAX_SELECTORS];
+    private char[] selectorMtf = new char[MAX_SELECTORS];
+
+    private char[] block;
+    private int[] quadrant;
+    private int[] zptr;
+    private short[] szptr;
+    private int[] ftab;
+
+    private int nMTF;
+
+    private int[] mtfFreq = new int[MAX_ALPHA_SIZE];
+
+    /*
+     * Used when sorting.  If too many long comparisons
+     * happen, we stop sorting, randomise the block
+     * slightly, and try again.
+     */
+    private int workFactor;
+    private int workDone;
+    private int workLimit;
+    private boolean firstAttempt;
+    private int nBlocksRandomised;
+
+    private int currentChar = -1;
+    private int runLength = 0;
+
+    public BZip2CompressorOutputStream(OutputStream inStream) throws IOException {
+        this(inStream, 9);
+    }
+
+    public BZip2CompressorOutputStream(OutputStream inStream, int inBlockSize)
+        throws IOException {
+        block = null;
+        quadrant = null;
+        zptr = null;
+        ftab = null;
+
+        bsSetStream(inStream);
+
+        workFactor = 50;
+        if (inBlockSize > 9) {
+            inBlockSize = 9;
+        }
+        if (inBlockSize < 1) {
+            inBlockSize = 1;
+        }
+        blockSize100k = inBlockSize;
+        allocateCompressStructures();
+        initialize();
+        initBlock();
+    }
+
+    /**
+     *
+     * modified by Oliver Merkel, 010128
+     *
+     */
+    public void write(int bv) throws IOException {
+        int b = (256 + bv) % 256;
+        if (currentChar != -1) {
+            if (currentChar == b) {
+                runLength++;
+                if (runLength > 254) {
+                    writeRun();
+                    currentChar = -1;
+                    runLength = 0;
+                }
+            } else {
+                writeRun();
+                runLength = 1;
+                currentChar = b;
+            }
+        } else {
+            currentChar = b;
+            runLength++;
+        }
+    }
+
+    private void writeRun() throws IOException {
+        if (last < allowableBlockSize) {
+            inUse[currentChar] = true;
+            for (int i = 0; i < runLength; i++) {
+                mCrc.updateCRC((char) currentChar);
+            }
+            switch (runLength) {
+            case 1:
+                last++;
+                block[last + 1] = (char) currentChar;
+                break;
+            case 2:
+                last++;
+                block[last + 1] = (char) currentChar;
+                last++;
+                block[last + 1] = (char) currentChar;
+                break;
+            case 3:
+                last++;
+                block[last + 1] = (char) currentChar;
+                last++;
+                block[last + 1] = (char) currentChar;
+                last++;
+                block[last + 1] = (char) currentChar;
+                break;
+            default:
+                inUse[runLength - 4] = true;
+                last++;
+                block[last + 1] = (char) currentChar;
+                last++;
+                block[last + 1] = (char) currentChar;
+                last++;
+                block[last + 1] = (char) currentChar;
+                last++;
+                block[last + 1] = (char) currentChar;
+                last++;
+                block[last + 1] = (char) (runLength - 4);
+                break;
+            }
+        } else {
+            endBlock();
+            initBlock();
+            writeRun();
+        }
+    }
+
+    boolean closed = false;
+
+    protected void finalize() throws Throwable {
+        close();
+        super.finalize();
+    }
+
+    public void close() throws IOException {
+        if (closed) {
+            return;
+        }
+
+        if (runLength > 0) {
+            writeRun();
+        }
+        currentChar = -1;
+        endBlock();
+        endCompression();
+        closed = true;
+        super.close();
+        bsStream.close();
+    }
+
+    public void flush() throws IOException {
+        super.flush();
+        bsStream.flush();
+    }
+
+    private int blockCRC, combinedCRC;
+
+    private void initialize() throws IOException {
+        bytesOut = 0;
+        nBlocksRandomised = 0;
+
+        /* Write `magic' bytes h indicating file-format == huffmanised,
+           followed by a digit indicating blockSize100k.
+        */
+        bsPutUChar('h');
+        bsPutUChar('0' + blockSize100k);
+
+        combinedCRC = 0;
+    }
+
+    private int allowableBlockSize;
+
+    private void initBlock() {
+        //        blockNo++;
+        mCrc.initialiseCRC();
+        last = -1;
+        //        ch = 0;
+
+        for (int i = 0; i < 256; i++) {
+            inUse[i] = false;
+        }
+
+        /* 20 is just a paranoia constant */
+        allowableBlockSize = baseBlockSize * blockSize100k - 20;
+    }
+
+    private void endBlock() throws IOException {
+        blockCRC = mCrc.getFinalCRC();
+        combinedCRC = (combinedCRC << 1) | (combinedCRC >>> 31);
+        combinedCRC ^= blockCRC;
+
+        /* sort the block and establish posn of original string */
+        doReversibleTransformation();
+
+        /*
+          A 6-byte block header, the value chosen arbitrarily
+          as 0x314159265359 :-).  A 32 bit value does not really
+          give a strong enough guarantee that the value will not
+          appear by chance in the compressed datastream.  Worst-case
+          probability of this event, for a 900k block, is about
+          2.0e-3 for 32 bits, 1.0e-5 for 40 bits and 4.0e-8 for 48 bits.
+          For a compressed file of size 100Gb -- about 100000 blocks --
+          only a 48-bit marker will do.  NB: normal compression/
+          decompression do *not* rely on these statistical properties.
+          They are only important when trying to recover blocks from
+          damaged files.
+        */
+        bsPutUChar(0x31);
+        bsPutUChar(0x41);
+        bsPutUChar(0x59);
+        bsPutUChar(0x26);
+        bsPutUChar(0x53);
+        bsPutUChar(0x59);
+
+        /* Now the block's CRC, so it is in a known place. */
+        bsPutint(blockCRC);
+
+        /* Now a single bit indicating randomisation. */
+        if (blockRandomised) {
+            bsW(1, 1);
+            nBlocksRandomised++;
+        } else {
+            bsW(1, 0);
+        }
+
+        /* Finally, block's contents proper. */
+        moveToFrontCodeAndSend();
+    }
+
+    private void endCompression() throws IOException {
+        /*
+          Now another magic 48-bit number, 0x177245385090, to
+          indicate the end of the last block.  (sqrt(pi), if
+          you want to know.  I did want to use e, but it contains
+          too much repetition -- 27 18 28 18 28 46 -- for me
+          to feel statistically comfortable.  Call me paranoid.)
+        */
+        bsPutUChar(0x17);
+        bsPutUChar(0x72);
+        bsPutUChar(0x45);
+        bsPutUChar(0x38);
+        bsPutUChar(0x50);
+        bsPutUChar(0x90);
+
+        bsPutint(combinedCRC);
+
+        bsFinishedWithStream();
+    }
+
+    private void hbAssignCodes (int[] code, char[] length, int minLen,
+                                int maxLen, int alphaSize) {
+        int n, vec, i;
+
+        vec = 0;
+        for (n = minLen; n <= maxLen; n++) {
+            for (i = 0; i < alphaSize; i++) {
+                if (length[i] == n) {
+                    code[i] = vec;
+                    vec++;
+                }
+            };
+            vec <<= 1;
+        }
+    }
+
+    private void bsSetStream(OutputStream f) {
+        bsStream = f;
+        bsLive = 0;
+        bsBuff = 0;
+        bytesOut = 0;
+    }
+
+    private void bsFinishedWithStream() throws IOException {
+        while (bsLive > 0) {
+            int ch = (bsBuff >> 24);
+            try {
+                bsStream.write(ch); // write 8-bit
+            } catch (IOException e) {
+                throw  e;
+            }
+            bsBuff <<= 8;
+            bsLive -= 8;
+            bytesOut++;
+        }
+    }
+
+    private void bsW(int n, int v) throws IOException {
+        while (bsLive >= 8) {
+            int ch = (bsBuff >> 24);
+            try {
+                bsStream.write(ch); // write 8-bit
+            } catch (IOException e) {
+                throw e;
+            }
+            bsBuff <<= 8;
+            bsLive -= 8;
+            bytesOut++;
+        }
+        bsBuff |= (v << (32 - bsLive - n));
+        bsLive += n;
+    }
+
+    private void bsPutUChar(int c) throws IOException {
+        bsW(8, c);
+    }
+
+    private void bsPutint(int u) throws IOException {
+        bsW(8, (u >> 24) & 0xff);
+        bsW(8, (u >> 16) & 0xff);
+        bsW(8, (u >>  8) & 0xff);
+        bsW(8,  u        & 0xff);
+    }
+
+    private void bsPutIntVS(int numBits, int c) throws IOException {
+        bsW(numBits, c);
+    }
+
+    private void sendMTFValues() throws IOException {
+        char len[][] = new char[N_GROUPS][MAX_ALPHA_SIZE];
+
+        int v, t, i, j, gs, ge, totc, bt, bc, iter;
+        int nSelectors = 0, alphaSize, minLen, maxLen, selCtr;
+        int nGroups, nBytes;
+
+        alphaSize = nInUse + 2;
+        for (t = 0; t < N_GROUPS; t++) {
+            for (v = 0; v < alphaSize; v++) {
+                len[t][v] = (char) GREATER_ICOST;
+            }
+        }
+
+        /* Decide how many coding tables to use */
+        if (nMTF <= 0) {
+            panic();
+        }
+
+        if (nMTF < 200) {
+            nGroups = 2;
+        } else if (nMTF < 600) {
+            nGroups = 3;
+        } else if (nMTF < 1200) {
+            nGroups = 4;
+        } else if (nMTF < 2400) {
+            nGroups = 5;
+        } else {
+            nGroups = 6;
+        }
+
+        /* Generate an initial set of coding tables */ {
+            int nPart, remF, tFreq, aFreq;
+
+            nPart = nGroups;
+            remF  = nMTF;
+            gs = 0;
+            while (nPart > 0) {
+                tFreq = remF / nPart;
+                ge = gs - 1;
+                aFreq = 0;
+                while (aFreq < tFreq && ge < alphaSize - 1) {
+                    ge++;
+                    aFreq += mtfFreq[ge];
+                }
+
+                if (ge > gs && nPart != nGroups && nPart != 1
+                    && ((nGroups - nPart) % 2 == 1)) {
+                    aFreq -= mtfFreq[ge];
+                    ge--;
+                }
+
+                for (v = 0; v < alphaSize; v++) {
+                    if (v >= gs && v <= ge) {
+                        len[nPart - 1][v] = (char) LESSER_ICOST;
+                    } else {
+                        len[nPart - 1][v] = (char) GREATER_ICOST;
+                    }
+                }
+
+                nPart--;
+                gs = ge + 1;
+                remF -= aFreq;
+            }
+        }
+
+        int[][] rfreq = new int[N_GROUPS][MAX_ALPHA_SIZE];
+        int[] fave = new int[N_GROUPS];
+        short[] cost = new short[N_GROUPS];
+        /*
+          Iterate up to N_ITERS times to improve the tables.
+        */
+        for (iter = 0; iter < N_ITERS; iter++) {
+            for (t = 0; t < nGroups; t++) {
+                fave[t] = 0;
+            }
+
+            for (t = 0; t < nGroups; t++) {
+                for (v = 0; v < alphaSize; v++) {
+                    rfreq[t][v] = 0;
+                }
+            }
+
+            nSelectors = 0;
+            totc = 0;
+            gs = 0;
+            while (true) {
+
+                /* Set group start & end marks. */
+                if (gs >= nMTF) {
+                    break;
+                }
+                ge = gs + G_SIZE - 1;
+                if (ge >= nMTF) {
+                    ge = nMTF - 1;
+                }
+
+                /*
+                  Calculate the cost of this group as coded
+                  by each of the coding tables.
+                */
+                for (t = 0; t < nGroups; t++) {
+                    cost[t] = 0;
+                }
+
+                if (nGroups == 6) {
+                    short cost0, cost1, cost2, cost3, cost4, cost5;
+                    cost0 = cost1 = cost2 = cost3 = cost4 = cost5 = 0;
+                    for (i = gs; i <= ge; i++) {
+                        short icv = szptr[i];
+                        cost0 += len[0][icv];
+                        cost1 += len[1][icv];
+                        cost2 += len[2][icv];
+                        cost3 += len[3][icv];
+                        cost4 += len[4][icv];
+                        cost5 += len[5][icv];
+                    }
+                    cost[0] = cost0;
+                    cost[1] = cost1;
+                    cost[2] = cost2;
+                    cost[3] = cost3;
+                    cost[4] = cost4;
+                    cost[5] = cost5;
+                } else {
+                    for (i = gs; i <= ge; i++) {
+                        short icv = szptr[i];
+                        for (t = 0; t < nGroups; t++) {
+                            cost[t] += len[t][icv];
+                        }
+                    }
+                }
+
+                /*
+                  Find the coding table which is best for this group,
+                  and record its identity in the selector table.
+                */
+                bc = 999999999;
+                bt = -1;
+                for (t = 0; t < nGroups; t++) {
+                    if (cost[t] < bc) {
+                        bc = cost[t];
+                        bt = t;
+                    }
+                };
+                totc += bc;
+                fave[bt]++;
+                selector[nSelectors] = (char) bt;
+                nSelectors++;
+
+                /*
+                  Increment the symbol frequencies for the selected table.
+                */
+                for (i = gs; i <= ge; i++) {
+                    rfreq[bt][szptr[i]]++;
+                }
+
+                gs = ge + 1;
+            }
+
+            /*
+              Recompute the tables based on the accumulated frequencies.
+            */
+            for (t = 0; t < nGroups; t++) {
+                hbMakeCodeLengths(len[t], rfreq[t], alphaSize, 20);
+            }
+        }
+
+        rfreq = null;
+        fave = null;
+        cost = null;
+
+        if (!(nGroups < 8)) {
+            panic();
+        }
+        if (!(nSelectors < 32768 && nSelectors <= (2 + (900000 / G_SIZE)))) {
+            panic();
+        }
+
+
+        /* Compute MTF values for the selectors. */
+        {
+            char[] pos = new char[N_GROUPS];
+            char ll_i, tmp2, tmp;
+            for (i = 0; i < nGroups; i++) {
+                pos[i] = (char) i;
+            }
+            for (i = 0; i < nSelectors; i++) {
+                ll_i = selector[i];
+                j = 0;
+                tmp = pos[j];
+                while (ll_i != tmp) {
+                    j++;
+                    tmp2 = tmp;
+                    tmp = pos[j];
+                    pos[j] = tmp2;
+                }
+                pos[0] = tmp;
+                selectorMtf[i] = (char) j;
+            }
+        }
+
+        int[][] code = new int[N_GROUPS][MAX_ALPHA_SIZE];
+
+        /* Assign actual codes for the tables. */
+        for (t = 0; t < nGroups; t++) {
+            minLen = 32;
+            maxLen = 0;
+            for (i = 0; i < alphaSize; i++) {
+                if (len[t][i] > maxLen) {
+                    maxLen = len[t][i];
+                }
+                if (len[t][i] < minLen) {
+                    minLen = len[t][i];
+                }
+            }
+            if (maxLen > 20) {
+                panic();
+            }
+            if (minLen < 1) {
+                panic();
+            }
+            hbAssignCodes(code[t], len[t], minLen, maxLen, alphaSize);
+        }
+
+        /* Transmit the mapping table. */
+        {
+            boolean[] inUse16 = new boolean[16];
+            for (i = 0; i < 16; i++) {
+                inUse16[i] = false;
+                for (j = 0; j < 16; j++) {
+                    if (inUse[i * 16 + j]) {
+                        inUse16[i] = true;
+                    }
+                }
+            }
+
+            nBytes = bytesOut;
+            for (i = 0; i < 16; i++) {
+                if (inUse16[i]) {
+                    bsW(1, 1);
+                } else {
+                    bsW(1, 0);
+                }
+            }
+
+            for (i = 0; i < 16; i++) {
+                if (inUse16[i]) {
+                    for (j = 0; j < 16; j++) {
+                        if (inUse[i * 16 + j]) {
+                            bsW(1, 1);
+                        } else {
+                            bsW(1, 0);
+                        }
+                    }
+                }
+            }
+
+        }
+
+        /* Now the selectors. */
+        nBytes = bytesOut;
+        bsW (3, nGroups);
+        bsW (15, nSelectors);
+        for (i = 0; i < nSelectors; i++) {
+            for (j = 0; j < selectorMtf[i]; j++) {
+                bsW(1, 1);
+            }
+            bsW(1, 0);
+        }
+
+        /* Now the coding tables. */
+        nBytes = bytesOut;
+
+        for (t = 0; t < nGroups; t++) {
+            int curr = len[t][0];
+            bsW(5, curr);
+            for (i = 0; i < alphaSize; i++) {
+                while (curr < len[t][i]) {
+                    bsW(2, 2);
+                    curr++; /* 10 */
+                }
+                while (curr > len[t][i]) {
+                    bsW(2, 3);
+                    curr--; /* 11 */
+                }
+                bsW (1, 0);
+            }
+        }
+
+        /* And finally, the block data proper */
+        nBytes = bytesOut;
+        selCtr = 0;
+        gs = 0;
+        while (true) {
+            if (gs >= nMTF) {
+                break;
+            }
+            ge = gs + G_SIZE - 1;
+            if (ge >= nMTF) {
+                ge = nMTF - 1;
+            }
+            for (i = gs; i <= ge; i++) {
+                bsW(len[selector[selCtr]][szptr[i]],
+                    code[selector[selCtr]][szptr[i]]);
+            }
+
+            gs = ge + 1;
+            selCtr++;
+        }
+        if (!(selCtr == nSelectors)) {
+            panic();
+        }
+    }
+
+    private void moveToFrontCodeAndSend () throws IOException {
+        bsPutIntVS(24, origPtr);
+        generateMTFValues();
+        sendMTFValues();
+    }
+
+    private OutputStream bsStream;
+
+    private void simpleSort(int lo, int hi, int d) {
+        int i, j, h, bigN, hp;
+        int v;
+
+        bigN = hi - lo + 1;
+        if (bigN < 2) {
+            return;
+        }
+
+        hp = 0;
+        while (incs[hp] < bigN) {
+            hp++;
+        }
+        hp--;
+
+        for (; hp >= 0; hp--) {
+            h = incs[hp];
+
+            i = lo + h;
+            while (true) {
+                /* copy 1 */
+                if (i > hi) {
+                    break;
+                }
+                v = zptr[i];
+                j = i;
+                while (fullGtU(zptr[j - h] + d, v + d)) {
+                    zptr[j] = zptr[j - h];
+                    j = j - h;
+                    if (j <= (lo + h - 1)) {
+                        break;
+                    }
+                }
+                zptr[j] = v;
+                i++;
+
+                /* copy 2 */
+                if (i > hi) {
+                    break;
+                }
+                v = zptr[i];
+                j = i;
+                while (fullGtU(zptr[j - h] + d, v + d)) {
+                    zptr[j] = zptr[j - h];
+                    j = j - h;
+                    if (j <= (lo + h - 1)) {
+                        break;
+                    }
+                }
+                zptr[j] = v;
+                i++;
+
+                /* copy 3 */
+                if (i > hi) {
+                    break;
+                }
+                v = zptr[i];
+                j = i;
+                while (fullGtU(zptr[j - h] + d, v + d)) {
+                    zptr[j] = zptr[j - h];
+                    j = j - h;
+                    if (j <= (lo + h - 1)) {
+                        break;
+                    }
+                }
+                zptr[j] = v;
+                i++;
+
+                if (workDone > workLimit && firstAttempt) {
+                    return;
+                }
+            }
+        }
+    }
+
+    private void vswap(int p1, int p2, int n) {
+        int temp = 0;
+        while (n > 0) {
+            temp = zptr[p1];
+            zptr[p1] = zptr[p2];
+            zptr[p2] = temp;
+            p1++;
+            p2++;
+            n--;
+        }
+    }
+
+    private char med3(char a, char b, char c) {
+        char t;
+        if (a > b) {
+            t = a;
+            a = b;
+            b = t;
+        }
+        if (b > c) {
+            t = b;
+            b = c;
+            c = t;
+        }
+        if (a > b) {
+            b = a;
+        }
+        return b;
+    }
+
+    private static class StackElem {
+        int ll;
+        int hh;
+        int dd;
+    }
+
+    private void qSort3(int loSt, int hiSt, int dSt) {
+        int unLo, unHi, ltLo, gtHi, med, n, m;
+        int sp, lo, hi, d;
+        StackElem[] stack = new StackElem[QSORT_STACK_SIZE];
+        for (int count = 0; count < QSORT_STACK_SIZE; count++) {
+            stack[count] = new StackElem();
+        }
+
+        sp = 0;
+
+        stack[sp].ll = loSt;
+        stack[sp].hh = hiSt;
+        stack[sp].dd = dSt;
+        sp++;
+
+        while (sp > 0) {
+            if (sp >= QSORT_STACK_SIZE) {
+                panic();
+            }
+
+            sp--;
+            lo = stack[sp].ll;
+            hi = stack[sp].hh;
+            d = stack[sp].dd;
+
+            if (hi - lo < SMALL_THRESH || d > DEPTH_THRESH) {
+                simpleSort(lo, hi, d);
+                if (workDone > workLimit && firstAttempt) {
+                    return;
+                }
+                continue;
+            }
+
+            med = med3(block[zptr[lo] + d + 1],
+                       block[zptr[hi            ] + d  + 1],
+                       block[zptr[(lo + hi) >> 1] + d + 1]);
+
+            unLo = ltLo = lo;
+            unHi = gtHi = hi;
+
+            while (true) {
+                while (true) {
+                    if (unLo > unHi) {
+                        break;
+                    }
+                    n = ((int) block[zptr[unLo] + d + 1]) - med;
+                    if (n == 0) {
+                        int temp = 0;
+                        temp = zptr[unLo];
+                        zptr[unLo] = zptr[ltLo];
+                        zptr[ltLo] = temp;
+                        ltLo++;
+                        unLo++;
+                        continue;
+                    };
+                    if (n >  0) {
+                        break;
+                    }
+                    unLo++;
+                }
+                while (true) {
+                    if (unLo > unHi) {
+                        break;
+                    }
+                    n = ((int) block[zptr[unHi] + d + 1]) - med;
+                    if (n == 0) {
+                        int temp = 0;
+                        temp = zptr[unHi];
+                        zptr[unHi] = zptr[gtHi];
+                        zptr[gtHi] = temp;
+                        gtHi--;
+                        unHi--;
+                        continue;
+                    };
+                    if (n <  0) {
+                        break;
+                    }
+                    unHi--;
+                }
+                if (unLo > unHi) {
+                    break;
+                }
+                int temp = 0;
+                temp = zptr[unLo];
+                zptr[unLo] = zptr[unHi];
+                zptr[unHi] = temp;
+                unLo++;
+                unHi--;
+            }
+
+            if (gtHi < ltLo) {
+                stack[sp].ll = lo;
+                stack[sp].hh = hi;
+                stack[sp].dd = d + 1;
+                sp++;
+                continue;
+            }
+
+            n = ((ltLo - lo) < (unLo - ltLo)) ? (ltLo - lo) : (unLo - ltLo);
+            vswap(lo, unLo - n, n);
+            m = ((hi - gtHi) < (gtHi - unHi)) ? (hi - gtHi) : (gtHi - unHi);
+            vswap(unLo, hi - m + 1, m);
+
+            n = lo + unLo - ltLo - 1;
+            m = hi - (gtHi - unHi) + 1;
+
+            stack[sp].ll = lo;
+            stack[sp].hh = n;
+            stack[sp].dd = d;
+            sp++;
+
+            stack[sp].ll = n + 1;
+            stack[sp].hh = m - 1;
+            stack[sp].dd = d + 1;
+            sp++;
+
+            stack[sp].ll = m;
+            stack[sp].hh = hi;
+            stack[sp].dd = d;
+            sp++;
+        }
+    }
+
+    private void mainSort() {
+        int i, j, ss, sb;
+        int[] runningOrder = new int[256];
+        int[] copy = new int[256];
+        boolean[] bigDone = new boolean[256];
+        int c1, c2;
+        int numQSorted;
+
+        /*
+          In the various block-sized structures, live data runs
+          from 0 to last+NUM_OVERSHOOT_BYTES inclusive.  First,
+          set up the overshoot area for block.
+        */
+
+        //   if (verbosity >= 4) fprintf ( stderr, "   sort initialise ...\n" );
+        for (i = 0; i < NUM_OVERSHOOT_BYTES; i++) {
+            block[last + i + 2] = block[(i % (last + 1)) + 1];
+        }
+        for (i = 0; i <= last + NUM_OVERSHOOT_BYTES; i++) {
+            quadrant[i] = 0;
+        }
+
+        block[0] = (char) (block[last + 1]);
+
+        if (last < 4000) {
+            /*
+              Use simpleSort(), since the full sorting mechanism
+              has quite a large constant overhead.
+            */
+            for (i = 0; i <= last; i++) {
+                zptr[i] = i;
+            }
+            firstAttempt = false;
+            workDone = workLimit = 0;
+            simpleSort(0, last, 0);
+        } else {
+            numQSorted = 0;
+            for (i = 0; i <= 255; i++) {
+                bigDone[i] = false;
+            }
+
+            for (i = 0; i <= 65536; i++) {
+                ftab[i] = 0;
+            }
+
+            c1 = block[0];
+            for (i = 0; i <= last; i++) {
+                c2 = block[i + 1];
+                ftab[(c1 << 8) + c2]++;
+                c1 = c2;
+            }
+
+            for (i = 1; i <= 65536; i++) {
+                ftab[i] += ftab[i - 1];
+            }
+
+            c1 = block[1];
+            for (i = 0; i < last; i++) {
+                c2 = block[i + 2];
+                j = (c1 << 8) + c2;
+                c1 = c2;
+                ftab[j]--;
+                zptr[ftab[j]] = i;
+            }
+
+            j = ((block[last + 1]) << 8) + (block[1]);
+            ftab[j]--;
+            zptr[ftab[j]] = last;
+
+            /*
+              Now ftab contains the first loc of every small bucket.
+              Calculate the running order, from smallest to largest
+              big bucket.
+            */
+
+            for (i = 0; i <= 255; i++) {
+                runningOrder[i] = i;
+            }
+
+            {
+                int vv;
+                int h = 1;
+                do {
+                    h = 3 * h + 1;
+                }
+                while (h <= 256);
+                do {
+                    h = h / 3;
+                    for (i = h; i <= 255; i++) {
+                        vv = runningOrder[i];
+                        j = i;
+                        while ((ftab[((runningOrder[j - h]) + 1) << 8]
+                                - ftab[(runningOrder[j - h]) << 8]) >
+                               (ftab[((vv) + 1) << 8] - ftab[(vv) << 8])) {
+                            runningOrder[j] = runningOrder[j - h];
+                            j = j - h;
+                            if (j <= (h - 1)) {
+                                break;
+                            }
+                        }
+                        runningOrder[j] = vv;
+                    }
+                } while (h != 1);
+            }
+
+            /*
+              The main sorting loop.
+            */
+            for (i = 0; i <= 255; i++) {
+
+                /*
+                  Process big buckets, starting with the least full.
+                */
+                ss = runningOrder[i];
+
+                /*
+                  Complete the big bucket [ss] by quicksorting
+                  any unsorted small buckets [ss, j].  Hopefully
+                  previous pointer-scanning phases have already
+                  completed many of the small buckets [ss, j], so
+                  we don't have to sort them at all.
+                */
+                for (j = 0; j <= 255; j++) {
+                    sb = (ss << 8) + j;
+                    if (!((ftab[sb] & SETMASK) == SETMASK)) {
+                        int lo = ftab[sb] & CLEARMASK;
+                        int hi = (ftab[sb + 1] & CLEARMASK) - 1;
+                        if (hi > lo) {
+                            qSort3(lo, hi, 2);
+                            numQSorted += (hi - lo + 1);
+                            if (workDone > workLimit && firstAttempt) {
+                                return;
+                            }
+                        }
+                        ftab[sb] |= SETMASK;
+                    }
+                }
+
+                /*
+                  The ss big bucket is now done.  Record this fact,
+                  and update the quadrant descriptors.  Remember to
+                  update quadrants in the overshoot area too, if
+                  necessary.  The "if (i < 255)" test merely skips
+                  this updating for the last bucket processed, since
+                  updating for the last bucket is pointless.
+                */
+                bigDone[ss] = true;
+
+                if (i < 255) {
+                    int bbStart  = ftab[ss << 8] & CLEARMASK;
+                    int bbSize   = (ftab[(ss + 1) << 8] & CLEARMASK) - bbStart;
+                    int shifts   = 0;
+
+                    while ((bbSize >> shifts) > 65534) {
+                        shifts++;
+                    }
+
+                    for (j = 0; j < bbSize; j++) {
+                        int a2update = zptr[bbStart + j];
+                        int qVal = (j >> shifts);
+                        quadrant[a2update] = qVal;
+                        if (a2update < NUM_OVERSHOOT_BYTES) {
+                            quadrant[a2update + last + 1] = qVal;
+                        }
+                    }
+
+                    if (!(((bbSize - 1) >> shifts) <= 65535)) {
+                        panic();
+                    }
+                }
+
+                /*
+                  Now scan this big bucket so as to synthesise the
+                  sorted order for small buckets [t, ss] for all t != ss.
+                */
+                for (j = 0; j <= 255; j++) {
+                    copy[j] = ftab[(j << 8) + ss] & CLEARMASK;
+                }
+
+                for (j = ftab[ss << 8] & CLEARMASK;
+                     j < (ftab[(ss + 1) << 8] & CLEARMASK); j++) {
+                    c1 = block[zptr[j]];
+                    if (!bigDone[c1]) {
+                        zptr[copy[c1]] = zptr[j] == 0 ? last : zptr[j] - 1;
+                        copy[c1]++;
+                    }
+                }
+
+                for (j = 0; j <= 255; j++) {
+                    ftab[(j << 8) + ss] |= SETMASK;
+                }
+            }
+        }
+    }
+
+    private void randomiseBlock() {
+        int i;
+        int rNToGo = 0;
+        int rTPos  = 0;
+        for (i = 0; i < 256; i++) {
+            inUse[i] = false;
+        }
+
+        for (i = 0; i <= last; i++) {
+            if (rNToGo == 0) {
+                rNToGo = (char) rNums[rTPos];
+                rTPos++;
+                if (rTPos == 512) {
+                    rTPos = 0;
+                }
+            }
+            rNToGo--;
+            block[i + 1] ^= ((rNToGo == 1) ? 1 : 0);
+            // handle 16 bit signed numbers
+            block[i + 1] &= 0xFF;
+
+            inUse[block[i + 1]] = true;
+        }
+    }
+
+    private void doReversibleTransformation() {
+        int i;
+
+        workLimit = workFactor * last;
+        workDone = 0;
+        blockRandomised = false;
+        firstAttempt = true;
+
+        mainSort();
+
+        if (workDone > workLimit && firstAttempt) {
+            randomiseBlock();
+            workLimit = workDone = 0;
+            blockRandomised = true;
+            firstAttempt = false;
+            mainSort();
+        }
+
+        origPtr = -1;
+        for (i = 0; i <= last; i++) {
+            if (zptr[i] == 0) {
+                origPtr = i;
+                break;
+            }
+        };
+
+        if (origPtr == -1) {
+            panic();
+        }
+    }
+
+    private boolean fullGtU(int i1, int i2) {
+        int k;
+        char c1, c2;
+        int s1, s2;
+
+        c1 = block[i1 + 1];
+        c2 = block[i2 + 1];
+        if (c1 != c2) {
+            return (c1 > c2);
+        }
+        i1++;
+        i2++;
+
+        c1 = block[i1 + 1];
+        c2 = block[i2 + 1];
+        if (c1 != c2) {
+            return (c1 > c2);
+        }
+        i1++;
+        i2++;
+
+        c1 = block[i1 + 1];
+        c2 = block[i2 + 1];
+        if (c1 != c2) {
+            return (c1 > c2);
+        }
+        i1++;
+        i2++;
+
+        c1 = block[i1 + 1];
+        c2 = block[i2 + 1];
+        if (c1 != c2) {
+            return (c1 > c2);
+        }
+        i1++;
+        i2++;
+
+        c1 = block[i1 + 1];
+        c2 = block[i2 + 1];
+        if (c1 != c2) {
+            return (c1 > c2);
+        }
+        i1++;
+        i2++;
+
+        c1 = block[i1 + 1];
+        c2 = block[i2 + 1];
+        if (c1 != c2) {
+            return (c1 > c2);
+        }
+        i1++;
+        i2++;
+
+        k = last + 1;
+
+        do {
+            c1 = block[i1 + 1];
+            c2 = block[i2 + 1];
+            if (c1 != c2) {
+                return (c1 > c2);
+            }
+            s1 = quadrant[i1];
+            s2 = quadrant[i2];
+            if (s1 != s2) {
+                return (s1 > s2);
+            }
+            i1++;
+            i2++;
+
+            c1 = block[i1 + 1];
+            c2 = block[i2 + 1];
+            if (c1 != c2) {
+                return (c1 > c2);
+            }
+            s1 = quadrant[i1];
+            s2 = quadrant[i2];
+            if (s1 != s2) {
+                return (s1 > s2);
+            }
+            i1++;
+            i2++;
+
+            c1 = block[i1 + 1];
+            c2 = block[i2 + 1];
+            if (c1 != c2) {
+                return (c1 > c2);
+            }
+            s1 = quadrant[i1];
+            s2 = quadrant[i2];
+            if (s1 != s2) {
+                return (s1 > s2);
+            }
+            i1++;
+            i2++;
+
+            c1 = block[i1 + 1];
+            c2 = block[i2 + 1];
+            if (c1 != c2) {
+                return (c1 > c2);
+            }
+            s1 = quadrant[i1];
+            s2 = quadrant[i2];
+            if (s1 != s2) {
+                return (s1 > s2);
+            }
+            i1++;
+            i2++;
+
+            if (i1 > last) {
+                i1 -= last;
+                i1--;
+            };
+            if (i2 > last) {
+                i2 -= last;
+                i2--;
+            };
+
+            k -= 4;
+            workDone++;
+        } while (k >= 0);
+
+        return false;
+    }
+
+    /*
+      Knuth's increments seem to work better
+      than Incerpi-Sedgewick here.  Possibly
+      because the number of elems to sort is
+      usually small, typically <= 20.
+    */
+    private int[] incs = { 1, 4, 13, 40, 121, 364, 1093, 3280,
+                           9841, 29524, 88573, 265720,
+                           797161, 2391484 };
+
+    private void allocateCompressStructures () {
+        int n = baseBlockSize * blockSize100k;
+        block = new char[(n + 1 + NUM_OVERSHOOT_BYTES)];
+        quadrant = new int[(n + NUM_OVERSHOOT_BYTES)];
+        zptr = new int[n];
+        ftab = new int[65537];
+
+        if (block == null || quadrant == null || zptr == null
+            || ftab == null) {
+            //int totalDraw = (n + 1 + NUM_OVERSHOOT_BYTES) + (n + NUM_OVERSHOOT_BYTES) + n + 65537;
+            //compressOutOfMemory ( totalDraw, n );
+        }
+
+        /*
+          The back end needs a place to store the MTF values
+          whilst it calculates the coding tables.  We could
+          put them in the zptr array.  However, these values
+          will fit in a short, so we overlay szptr at the
+          start of zptr, in the hope of reducing the number
+          of cache misses induced by the multiple traversals
+          of the MTF values when calculating coding tables.
+          Seems to improve compression speed by about 1%.
+        */
+        //    szptr = zptr;
+
+
+        szptr = new short[2 * n];
+    }
+
+    private void generateMTFValues() {
+        char[] yy = new char[256];
+        int  i, j;
+        char tmp;
+        char tmp2;
+        int zPend;
+        int wr;
+        int EOB;
+
+        makeMaps();
+        EOB = nInUse + 1;
+
+        for (i = 0; i <= EOB; i++) {
+            mtfFreq[i] = 0;
+        }
+
+        wr = 0;
+        zPend = 0;
+        for (i = 0; i < nInUse; i++) {
+            yy[i] = (char) i;
+        }
+
+
+        for (i = 0; i <= last; i++) {
+            char ll_i;
+
+            ll_i = unseqToSeq[block[zptr[i]]];
+
+            j = 0;
+            tmp = yy[j];
+            while (ll_i != tmp) {
+                j++;
+                tmp2 = tmp;
+                tmp = yy[j];
+                yy[j] = tmp2;
+            };
+            yy[0] = tmp;
+
+            if (j == 0) {
+                zPend++;
+            } else {
+                if (zPend > 0) {
+                    zPend--;
+                    while (true) {
+                        switch (zPend % 2) {
+                        case 0:
+                            szptr[wr] = (short) RUNA;
+                            wr++;
+                            mtfFreq[RUNA]++;
+                            break;
+                        case 1:
+                            szptr[wr] = (short) RUNB;
+                            wr++;
+                            mtfFreq[RUNB]++;
+                            break;
+                        };
+                        if (zPend < 2) {
+                            break;
+                        }
+                        zPend = (zPend - 2) / 2;
+                    };
+                    zPend = 0;
+                }
+                szptr[wr] = (short) (j + 1);
+                wr++;
+                mtfFreq[j + 1]++;
+            }
+        }
+
+        if (zPend > 0) {
+            zPend--;
+            while (true) {
+                switch (zPend % 2) {
+                case 0:
+                    szptr[wr] = (short) RUNA;
+                    wr++;
+                    mtfFreq[RUNA]++;
+                    break;
+                case 1:
+                    szptr[wr] = (short) RUNB;
+                    wr++;
+                    mtfFreq[RUNB]++;
+                    break;
+                }
+                if (zPend < 2) {
+                    break;
+                }
+                zPend = (zPend - 2) / 2;
+            }
+        }
+
+        szptr[wr] = (short) EOB;
+        wr++;
+        mtfFreq[EOB]++;
+
+        nMTF = wr;
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2Constants.java b/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2Constants.java
new file mode 100644
index 0000000..a8b609d
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/compressors/bzip2/BZip2Constants.java
@@ -0,0 +1,101 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.apache.commons.compress.compressors.bzip2;
+
+/*
+ * This package is based on the work done by Keiron Liddle, Aftex Software
+ * <keiron@aftexsw.com> to whom the Ant project is very grateful for his great
+ * code.
+ */
+
+/**
+ * Base class for both the compress and decompress classes. Holds common arrays,
+ * and static data.
+ * 
+ * @author <a href="mailto:keiron@aftexsw.com">Keiron Liddle</a>
+ */
+interface BZip2Constants {
+
+    int baseBlockSize = 100000;
+    int MAX_ALPHA_SIZE = 258;
+    int MAX_CODE_LEN = 23;
+    int RUNA = 0;
+    int RUNB = 1;
+    int N_GROUPS = 6;
+    int G_SIZE = 50;
+    int N_ITERS = 4;
+    int MAX_SELECTORS = (2 + (900000 / G_SIZE));
+    int NUM_OVERSHOOT_BYTES = 20;
+
+    int[] rNums = {
+        619, 720, 127, 481, 931, 816, 813, 233, 566, 247,
+        985, 724, 205, 454, 863, 491, 741, 242, 949, 214,
+        733, 859, 335, 708, 621, 574, 73, 654, 730, 472,
+        419, 436, 278, 496, 867, 210, 399, 680, 480, 51,
+        878, 465, 811, 169, 869, 675, 611, 697, 867, 561,
+        862, 687, 507, 283, 482, 129, 807, 591, 733, 623,
+        150, 238, 59, 379, 684, 877, 625, 169, 643, 105,
+        170, 607, 520, 932, 727, 476, 693, 425, 174, 647,
+        73, 122, 335, 530, 442, 853, 695, 249, 445, 515,
+        909, 545, 703, 919, 874, 474, 882, 500, 594, 612,
+        641, 801, 220, 162, 819, 984, 589, 513, 495, 799,
+        161, 604, 958, 533, 221, 400, 386, 867, 600, 782,
+        382, 596, 414, 171, 516, 375, 682, 485, 911, 276,
+        98, 553, 163, 354, 666, 933, 424, 341, 533, 870,
+        227, 730, 475, 186, 263, 647, 537, 686, 600, 224,
+        469, 68, 770, 919, 190, 373, 294, 822, 808, 206,
+        184, 943, 795, 384, 383, 461, 404, 758, 839, 887,
+        715, 67, 618, 276, 204, 918, 873, 777, 604, 560,
+        951, 160, 578, 722, 79, 804, 96, 409, 713, 940,
+        652, 934, 970, 447, 318, 353, 859, 672, 112, 785,
+        645, 863, 803, 350, 139, 93, 354, 99, 820, 908,
+        609, 772, 154, 274, 580, 184, 79, 626, 630, 742,
+        653, 282, 762, 623, 680, 81, 927, 626, 789, 125,
+        411, 521, 938, 300, 821, 78, 343, 175, 128, 250,
+        170, 774, 972, 275, 999, 639, 495, 78, 352, 126,
+        857, 956, 358, 619, 580, 124, 737, 594, 701, 612,
+        669, 112, 134, 694, 363, 992, 809, 743, 168, 974,
+        944, 375, 748, 52, 600, 747, 642, 182, 862, 81,
+        344, 805, 988, 739, 511, 655, 814, 334, 249, 515,
+        897, 955, 664, 981, 649, 113, 974, 459, 893, 228,
+        433, 837, 553, 268, 926, 240, 102, 654, 459, 51,
+        686, 754, 806, 760, 493, 403, 415, 394, 687, 700,
+        946, 670, 656, 610, 738, 392, 760, 799, 887, 653,
+        978, 321, 576, 617, 626, 502, 894, 679, 243, 440,
+        680, 879, 194, 572, 640, 724, 926, 56, 204, 700,
+        707, 151, 457, 449, 797, 195, 791, 558, 945, 679,
+        297, 59, 87, 824, 713, 663, 412, 693, 342, 606,
+        134, 108, 571, 364, 631, 212, 174, 643, 304, 329,
+        343, 97, 430, 751, 497, 314, 983, 374, 822, 928,
+        140, 206, 73, 263, 980, 736, 876, 478, 430, 305,
+        170, 514, 364, 692, 829, 82, 855, 953, 676, 246,
+        369, 970, 294, 750, 807, 827, 150, 790, 288, 923,
+        804, 378, 215, 828, 592, 281, 565, 555, 710, 82,
+        896, 831, 547, 261, 524, 462, 293, 465, 502, 56,
+        661, 821, 976, 991, 658, 869, 905, 758, 745, 193,
+        768, 550, 608, 933, 378, 286, 215, 979, 792, 961,
+        61, 688, 793, 644, 986, 403, 106, 366, 905, 644,
+        372, 567, 466, 434, 645, 210, 389, 550, 919, 135,
+        780, 773, 635, 389, 707, 100, 626, 958, 165, 504,
+        920, 176, 193, 713, 857, 265, 203, 50, 668, 108,
+        645, 990, 626, 197, 510, 357, 358, 850, 858, 364,
+        936, 638
+    };
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/commons/compress/compressors/bzip2/CRC.java b/src/main/java/org/apache/commons/compress/compressors/bzip2/CRC.java
new file mode 100644
index 0000000..c4cf7f1
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/compressors/bzip2/CRC.java
@@ -0,0 +1,108 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.compressors.bzip2;
+
+/*
+ * This package is based on the work done by Keiron Liddle, Aftex Software
+ * <keiron@aftexsw.com> to whom the Ant project is very grateful for his great
+ * code.
+ */
+
+/**
+ * A simple class the hold and calculate the CRC for sanity checking of the
+ * data.
+ * 
+ * @author <a href="mailto:keiron@aftexsw.com">Keiron Liddle</a>
+ */
+class CRC {
+	private static int[] CRC32_TABLE = new int[] { 0x00000000, 0x04c11db7,
+			0x09823b6e, 0x0d4326d9, 0x130476dc, 0x17c56b6b, 0x1a864db2,
+			0x1e475005, 0x2608edb8, 0x22c9f00f, 0x2f8ad6d6, 0x2b4bcb61,
+			0x350c9b64, 0x31cd86d3, 0x3c8ea00a, 0x384fbdbd, 0x4c11db70,
+			0x48d0c6c7, 0x4593e01e, 0x4152fda9, 0x5f15adac, 0x5bd4b01b,
+			0x569796c2, 0x52568b75, 0x6a1936c8, 0x6ed82b7f, 0x639b0da6,
+			0x675a1011, 0x791d4014, 0x7ddc5da3, 0x709f7b7a, 0x745e66cd,
+			0x9823b6e0, 0x9ce2ab57, 0x91a18d8e, 0x95609039, 0x8b27c03c,
+			0x8fe6dd8b, 0x82a5fb52, 0x8664e6e5, 0xbe2b5b58, 0xbaea46ef,
+			0xb7a96036, 0xb3687d81, 0xad2f2d84, 0xa9ee3033, 0xa4ad16ea,
+			0xa06c0b5d, 0xd4326d90, 0xd0f37027, 0xddb056fe, 0xd9714b49,
+			0xc7361b4c, 0xc3f706fb, 0xceb42022, 0xca753d95, 0xf23a8028,
+			0xf6fb9d9f, 0xfbb8bb46, 0xff79a6f1, 0xe13ef6f4, 0xe5ffeb43,
+			0xe8bccd9a, 0xec7dd02d, 0x34867077, 0x30476dc0, 0x3d044b19,
+			0x39c556ae, 0x278206ab, 0x23431b1c, 0x2e003dc5, 0x2ac12072,
+			0x128e9dcf, 0x164f8078, 0x1b0ca6a1, 0x1fcdbb16, 0x018aeb13,
+			0x054bf6a4, 0x0808d07d, 0x0cc9cdca, 0x7897ab07, 0x7c56b6b0,
+			0x71159069, 0x75d48dde, 0x6b93dddb, 0x6f52c06c, 0x6211e6b5,
+			0x66d0fb02, 0x5e9f46bf, 0x5a5e5b08, 0x571d7dd1, 0x53dc6066,
+			0x4d9b3063, 0x495a2dd4, 0x44190b0d, 0x40d816ba, 0xaca5c697,
+			0xa864db20, 0xa527fdf9, 0xa1e6e04e, 0xbfa1b04b, 0xbb60adfc,
+			0xb6238b25, 0xb2e29692, 0x8aad2b2f, 0x8e6c3698, 0x832f1041,
+			0x87ee0df6, 0x99a95df3, 0x9d684044, 0x902b669d, 0x94ea7b2a,
+			0xe0b41de7, 0xe4750050, 0xe9362689, 0xedf73b3e, 0xf3b06b3b,
+			0xf771768c, 0xfa325055, 0xfef34de2, 0xc6bcf05f, 0xc27dede8,
+			0xcf3ecb31, 0xcbffd686, 0xd5b88683, 0xd1799b34, 0xdc3abded,
+			0xd8fba05a, 0x690ce0ee, 0x6dcdfd59, 0x608edb80, 0x644fc637,
+			0x7a089632, 0x7ec98b85, 0x738aad5c, 0x774bb0eb, 0x4f040d56,
+			0x4bc510e1, 0x46863638, 0x42472b8f, 0x5c007b8a, 0x58c1663d,
+			0x558240e4, 0x51435d53, 0x251d3b9e, 0x21dc2629, 0x2c9f00f0,
+			0x285e1d47, 0x36194d42, 0x32d850f5, 0x3f9b762c, 0x3b5a6b9b,
+			0x0315d626, 0x07d4cb91, 0x0a97ed48, 0x0e56f0ff, 0x1011a0fa,
+			0x14d0bd4d, 0x19939b94, 0x1d528623, 0xf12f560e, 0xf5ee4bb9,
+			0xf8ad6d60, 0xfc6c70d7, 0xe22b20d2, 0xe6ea3d65, 0xeba91bbc,
+			0xef68060b, 0xd727bbb6, 0xd3e6a601, 0xdea580d8, 0xda649d6f,
+			0xc423cd6a, 0xc0e2d0dd, 0xcda1f604, 0xc960ebb3, 0xbd3e8d7e,
+			0xb9ff90c9, 0xb4bcb610, 0xb07daba7, 0xae3afba2, 0xaafbe615,
+			0xa7b8c0cc, 0xa379dd7b, 0x9b3660c6, 0x9ff77d71, 0x92b45ba8,
+			0x9675461f, 0x8832161a, 0x8cf30bad, 0x81b02d74, 0x857130c3,
+			0x5d8a9099, 0x594b8d2e, 0x5408abf7, 0x50c9b640, 0x4e8ee645,
+			0x4a4ffbf2, 0x470cdd2b, 0x43cdc09c, 0x7b827d21, 0x7f436096,
+			0x7200464f, 0x76c15bf8, 0x68860bfd, 0x6c47164a, 0x61043093,
+			0x65c52d24, 0x119b4be9, 0x155a565e, 0x18197087, 0x1cd86d30,
+			0x029f3d35, 0x065e2082, 0x0b1d065b, 0x0fdc1bec, 0x3793a651,
+			0x3352bbe6, 0x3e119d3f, 0x3ad08088, 0x2497d08d, 0x2056cd3a,
+			0x2d15ebe3, 0x29d4f654, 0xc5a92679, 0xc1683bce, 0xcc2b1d17,
+			0xc8ea00a0, 0xd6ad50a5, 0xd26c4d12, 0xdf2f6bcb, 0xdbee767c,
+			0xe3a1cbc1, 0xe760d676, 0xea23f0af, 0xeee2ed18, 0xf0a5bd1d,
+			0xf464a0aa, 0xf9278673, 0xfde69bc4, 0x89b8fd09, 0x8d79e0be,
+			0x803ac667, 0x84fbdbd0, 0x9abc8bd5, 0x9e7d9662, 0x933eb0bb,
+			0x97ffad0c, 0xafb010b1, 0xab710d06, 0xa6322bdf, 0xa2f33668,
+			0xbcb4666d, 0xb8757bda, 0xb5365d03, 0xb1f740b4 };
+
+	private int m_globalCrc;
+
+	protected CRC() {
+		initialiseCRC();
+	}
+
+	int getFinalCRC() {
+		return ~m_globalCrc;
+	}
+
+	void initialiseCRC() {
+		m_globalCrc = 0xffffffff;
+	}
+
+	void updateCRC(final int inCh) {
+		int temp = (m_globalCrc >> 24) ^ inCh;
+		if (temp < 0) {
+			temp = 256 + temp;
+		}
+		m_globalCrc = (m_globalCrc << 8) ^ CRC32_TABLE[temp];
+	}
+}
\ No newline at end of file
diff --git a/src/main/java/org/apache/commons/compress/compressors/gzip/GzipCompressorInputStream.java b/src/main/java/org/apache/commons/compress/compressors/gzip/GzipCompressorInputStream.java
new file mode 100644
index 0000000..36d09b1
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/compressors/gzip/GzipCompressorInputStream.java
@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.compressors.gzip;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.zip.GZIPInputStream;
+
+import org.apache.commons.compress.compressors.CompressorInputStream;
+
+public class GzipCompressorInputStream extends CompressorInputStream {
+
+	private final GZIPInputStream in;
+	
+	public GzipCompressorInputStream(InputStream inputStream) throws IOException {
+		in = new GZIPInputStream(inputStream);
+	}
+
+	public int read() throws IOException {
+		return in.read();
+	}
+
+}
diff --git a/src/main/java/org/apache/commons/compress/compressors/gzip/GzipCompressorOutputStream.java b/src/main/java/org/apache/commons/compress/compressors/gzip/GzipCompressorOutputStream.java
new file mode 100644
index 0000000..0d0348a
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/compressors/gzip/GzipCompressorOutputStream.java
@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.compressors.gzip;
+
+import java.io.IOException;
+import java.io.OutputStream;
+import java.util.zip.GZIPOutputStream;
+
+import org.apache.commons.compress.compressors.CompressorOutputStream;
+
+public class GzipCompressorOutputStream extends CompressorOutputStream {
+	
+	private final GZIPOutputStream out;
+	
+	public GzipCompressorOutputStream( final OutputStream outputStream ) throws IOException {
+		out = new GZIPOutputStream(outputStream);
+	}
+
+	public void write(int b) throws IOException {
+		out.write(b);
+	}
+
+	public void close() throws IOException {
+		out.close();
+	}
+
+}
diff --git a/src/main/java/org/apache/commons/compress/utils/CompressUtils.java b/src/main/java/org/apache/commons/compress/utils/CompressUtils.java
new file mode 100644
index 0000000..bbb5b09
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/utils/CompressUtils.java
@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.utils;
+
+
+public final class CompressUtils {
+
+    /**
+     * Compares one byte array to another
+     * @param source- the array to compare to 
+     * @param headerBytes - the bytearray match
+     */
+    public static boolean compareByteArrays(byte[] source, byte[] match) {
+        int i = 0;
+        while(source.length < i || i < match.length ) {
+            if(source[i] != match[i]) {
+                return false;
+            }
+            i++;
+        }
+        return true;
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/utils/IOUtils.java b/src/main/java/org/apache/commons/compress/utils/IOUtils.java
new file mode 100644
index 0000000..9dc94ab
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/utils/IOUtils.java
@@ -0,0 +1,52 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.utils;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+
+public final class IOUtils {
+
+	/**
+     * Copies the content of a InputStream into an OutputStream
+     * 
+     * @param input
+     *            the InputStream to copy
+     * @param output
+     *            the target Stream
+     * @throws IOException
+     *             if the streams are interrupted
+     */
+    public static void copy(final InputStream input, final OutputStream output) throws IOException {
+        final byte[] buffer = new byte[8024];
+        int n = 0;
+        while (-1 != (n = input.read(buffer))) {
+            output.write(buffer, 0, n);
+        }
+    }
+    
+    public static void copy(final InputStream input, final OutputStream output, int buffersize) throws IOException {
+        final byte[] buffer = new byte[buffersize];
+        int n = 0;
+        while (-1 != (n = input.read(buffer))) {
+            output.write(buffer, 0, n);
+        }
+    }
+}
diff --git a/src/main/java/org/apache/commons/compress/utils/ReflectionUtils.java b/src/main/java/org/apache/commons/compress/utils/ReflectionUtils.java
new file mode 100644
index 0000000..41cb93d
--- /dev/null
+++ b/src/main/java/org/apache/commons/compress/utils/ReflectionUtils.java
@@ -0,0 +1,34 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.utils;
+
+import java.util.Map;
+
+import org.apache.commons.compress.archivers.ArchiveException;
+
+public final class ReflectionUtils {
+
+	public static void registerClazz(Map map, String name, Class type, Class clazz) throws ArchiveException {
+        if (type.isAssignableFrom(clazz) && !(clazz.isInterface())) {
+            map.put(name, clazz);
+        } else {
+            throw new ArchiveException("Archive does not implement the " + type + " interface.");
+        }
+    }
+}
diff --git a/src/main/resources/bla.jar b/src/main/resources/bla.jar
new file mode 100644
index 0000000..ad3ed82
--- /dev/null
+++ b/src/main/resources/bla.jar
Binary files differ
diff --git a/src/main/resources/bla.tar b/src/main/resources/bla.tar
new file mode 100644
index 0000000..c7af537
--- /dev/null
+++ b/src/main/resources/bla.tar
Binary files differ
diff --git a/src/main/resources/bla.tgz b/src/main/resources/bla.tgz
new file mode 100644
index 0000000..d741f1e
--- /dev/null
+++ b/src/main/resources/bla.tgz
Binary files differ
diff --git a/src/main/resources/bla.zip b/src/main/resources/bla.zip
new file mode 100644
index 0000000..160eedc
--- /dev/null
+++ b/src/main/resources/bla.zip
Binary files differ
diff --git a/src/main/resources/test1.xml b/src/main/resources/test1.xml
new file mode 100644
index 0000000..9e1a188
--- /dev/null
+++ b/src/main/resources/test1.xml
@@ -0,0 +1,19 @@
+<?xml version = '1.0'?>
+<!DOCTYPE connections>
+<connections>
+<<<<<<< HEAD:testdata/test.xml
+=======
+    as
+>>>>>>> 75cb63ff7005344589b57d17338b64783f8f430c:testdata/test.xml
+   <connection>
+      <JDBC_PORT>1521</JDBC_PORT>
+      <HOSTNAME>10.248.40.111</HOSTNAME>
+      <ConnectionType>JDBC</ConnectionType>
+      <DeployPassword>false</DeployPassword>
+      <user>appsrv</user>
+      <ConnectionName>Dev-DB</ConnectionName>
+      <SID>O10gIN1</SID>
+      <JdbcDriver>oracle.jdbc.driver.OracleDriver</JdbcDriver>
+      <ORACLE_JDBC_TYPE>thin</ORACLE_JDBC_TYPE>
+   </connection>
+</connections>
diff --git a/src/main/resources/test2.xml b/src/main/resources/test2.xml
new file mode 100644
index 0000000..486b2c2
--- /dev/null
+++ b/src/main/resources/test2.xml
@@ -0,0 +1,5 @@
+<?xml version = '1.0'?>
+<!DOCTYPE connections>
+<meinxml>
+	<leer />
+</meinxml>
diff --git a/src/site/resources/images/compress-logo-white.png b/src/site/resources/images/compress-logo-white.png
new file mode 100644
index 0000000..2b073e4
--- /dev/null
+++ b/src/site/resources/images/compress-logo-white.png
Binary files differ
diff --git a/src/site/resources/images/compress-logo-white.xcf b/src/site/resources/images/compress-logo-white.xcf
new file mode 100644
index 0000000..fe46ecc
--- /dev/null
+++ b/src/site/resources/images/compress-logo-white.xcf
Binary files differ
diff --git a/src/site/site.xml b/src/site/site.xml
new file mode 100644
index 0000000..068a690
--- /dev/null
+++ b/src/site/site.xml
@@ -0,0 +1,27 @@
+<?xml version="1.0" encoding="ISO-8859-1"?>
+<project name="Commons Compress">
+
+  <bannerRight>
+    <name>Commons Compress</name>
+    <src>/images/compress-logo-white.png</src>
+    <href>/index.html</href>
+  </bannerRight>
+
+  <body>
+
+    <menu name="Compress">
+      <item name="Overview"    href="/index.html"/>
+      <item name="Download"    href="/downloads.html"/>
+      <item name="Wiki"        href="http://wiki.apache.org/commons/Compress"/>
+    </menu>
+    
+    <menu name="Development">
+      <item name="Mailing Lists"           href="/mail-lists.html"/>
+      <item name="Issue Tracking"          href="/issue-tracking.html"/>
+      <item name="Team"                    href="/team-list.html"/>
+      <item name="Source Repository"       href="/source-repository.html"/>
+      <item name="Javadoc (latest)"        href="/apidocs/index.html"/>
+    </menu>
+
+  </body>
+</project>
diff --git a/src/site/xdoc/cvs-usage.xml b/src/site/xdoc/cvs-usage.xml
new file mode 100644
index 0000000..31c8b68
--- /dev/null
+++ b/src/site/xdoc/cvs-usage.xml
@@ -0,0 +1,52 @@
+<?xml version="1.0" encoding="ISO-8859-1" ?>
+<!-- 
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ * 
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+ -->
+
+<document>
+ <properties>
+  <title>Source repository</title>
+  <author email="dev@commons.apache.org">Commons Documentation Team</author>
+ </properties>
+ <body>
+<!-- ================================================== -->
+<section name="Source repository">
+<p>
+  Apache Commons Compress is hosted on the Apache
+  <a href="http://subversion.tigris.org/">subversion</a> repository.
+</p>
+<p>
+  The project URL is:<br />
+  <code>http://svn.apache.org/repos/asf/commons/sandbox/compress/trunk</code>
+</p>
+<p>
+  The best way to view the repository is via the
+  <a href="http://svn.apache.org/viewvc/commons/sandbox/compress/trunk/">subversion viewer</a>.
+</p>
+<p>
+  The alternative is to use the
+  <a href="http://svn.apache.org/repos/asf/commons/sandbox/compress/trunk/">native subversion</a> display.
+</p>
+<p>
+  For more information on subversion and creating patches see the
+  <a href="http://www.apache.org/dev/contributors.html">Apache Contributors Guide</a>.
+</p>
+</section>
+<!-- ================================================== -->
+</body>
+</document>
\ No newline at end of file
diff --git a/src/site/xdoc/downloads.xml b/src/site/xdoc/downloads.xml
new file mode 100644
index 0000000..91a3a5c
--- /dev/null
+++ b/src/site/xdoc/downloads.xml
@@ -0,0 +1,57 @@
+<?xml version="1.0"?>
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one or more
+   contributor license agreements.  See the NOTICE file distributed with
+   this work for additional information regarding copyright ownership.
+   The ASF licenses this file to You under the Apache License, Version 2.0
+   (the "License"); you may not use this file except in compliance with
+   the License.  You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+-->
+<document>
+   <properties>
+      <title>Downloads</title>
+   </properties>
+
+   <body>
+      <section name="Download Compress">
+         
+         <subsection name="Releases">
+            <p>
+               There are currently no official downloads, and will not be until Compress moves out of the Sandbox.
+<!--
+               Download the <a href="http://jakarta.apache.org/site/downloads/downloads_commons-compress.cgi">Latest Release</a>
+               of Commons Compress.
+-->
+            </p>
+
+         </subsection>
+
+         <subsection name="Nightly Builds">
+            <p>
+               <a href="http://people.apache.org/builds/jakarta-commons/nightly/commons-compress/">Nightly Builds</a>
+               are built once a day from the current SVN HEAD. This is (nearly) the latest code and so should
+               be treated with caution.
+            </p>
+         </subsection>
+<!--
+         <subsection name="Archived Releases">
+            <p>
+               Older releases are retained by the Apache Software Foundation but are
+               moved into a
+               <a href="http://archive.apache.org/dist/jakarta/commons/compress/">
+             special archive area</a>.
+            </p>
+         </subsection>
+-->
+      </section>
+
+   </body>
+</document>
diff --git a/src/site/xdoc/images/compress-logo-white.png b/src/site/xdoc/images/compress-logo-white.png
new file mode 100644
index 0000000..2b073e4
--- /dev/null
+++ b/src/site/xdoc/images/compress-logo-white.png
Binary files differ
diff --git a/src/site/xdoc/images/compress-logo-white.xcf b/src/site/xdoc/images/compress-logo-white.xcf
new file mode 100644
index 0000000..fe46ecc
--- /dev/null
+++ b/src/site/xdoc/images/compress-logo-white.xcf
Binary files differ
diff --git a/src/site/xdoc/index.xml b/src/site/xdoc/index.xml
new file mode 100644
index 0000000..828e02c
--- /dev/null
+++ b/src/site/xdoc/index.xml
@@ -0,0 +1,55 @@
+<?xml version="1.0"?>
+
+<document>
+
+ <properties>
+  <title>Overview</title>
+  <author email="dev@commons.apache.org">Commons Documentation Team</author>
+ </properties>
+
+ <body>
+
+<section name="Commons Compress">
+
+<p>
+Commons Compress defines an API for working with tar, zip and bzip2 files.
+</p>
+<p>
+The code in this component came from Avalon's Excalibur, but originally from Ant,
+as far as life in Apache goes. The tar package is originally Tim Endres' public
+domain package. The bzip2 package is based on the work done by Keiron Liddle.
+It has migrated via:<br />
+Ant -> Avalon-Excalibur -> Commons-IO -> Commons-Compress.
+</p>
+<subsection name="Status">
+<ul>
+  <li>This code is in the commons <i>sandbox</i></li>
+  <li>The code is unreleased</li>
+  <li>Methods and classes can and will appear and disappear without warning</li>
+  <li>If you like the code and want to push it towards a release, join the mailing list!</li>
+</ul>
+</subsection>
+</section>
+
+<section name="Documentation">
+<ul>
+  <li>The <a href="apidocs/index.html">Javadoc</a> of the latest SVN</li>
+  <li>The <a href="http://svn.apache.org/viewvc/commons/sandbox/compress/">SVN repository</a> can be browsed.</li>
+</ul>
+<p>
+There are also 2 example for the bzip2 API:
+</p>
+<ul>
+  <li><a href="xref-test/org/apache/commons/compress/bzip2/example/Bzip2Compress.html">Bzip2Compress</a></li>
+  <li><a href="xref-test/org/apache/commons/compress/bzip2/example/Bzip2Uncompress.html">Bzip2UnCompress</a></li>
+</ul>
+</section>
+
+<section name="Releases">
+<p>
+None. This is a <i>sandbox</i> component.
+</p>
+</section>
+
+</body>
+</document>
diff --git a/src/site/xdoc/issue-tracking.xml b/src/site/xdoc/issue-tracking.xml
new file mode 100644
index 0000000..346cbab
--- /dev/null
+++ b/src/site/xdoc/issue-tracking.xml
@@ -0,0 +1,100 @@
+<?xml version="1.0"?>
+<!--
+Licensed to the Apache Software Foundation (ASF) under one or more
+contributor license agreements.  See the NOTICE file distributed with
+this work for additional information regarding copyright ownership.
+The ASF licenses this file to You under the Apache License, Version 2.0
+(the "License"); you may not use this file except in compliance with
+the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+-->
+<!--
+ +======================================================================+
+ |****                                                              ****|
+ |****      THIS FILE IS GENERATED BY THE COMMONS BUILD PLUGIN      ****|
+ |****                    DO NOT EDIT DIRECTLY                      ****|
+ |****                                                              ****|
+ +======================================================================+
+ | TEMPLATE FILE: sandbox-issue-tracking-template.xml                   |
+ | commons-build-plugin/trunk/src/main/resources/commons-xdoc-templates |
+ +======================================================================+
+ |                                                                      |
+ | 1) Re-generate using: mvn commons:jira-page                          |
+ |                                                                      |
+ | 2) Set the following properties in the component's pom:              |
+ |    - commons.jira.componentid (required, numeric)                    |
+ |                                                                      |
+ | 3) Example Properties                                                |
+ |                                                                      |
+ |  <properties>                                                        |
+ |    <commons.jira.componentid>12311182</commons.jira.componentid>     |
+ |  </properties>                                                       |
+ |                                                                      |
+ +======================================================================+
+-->
+<document>
+  <properties>
+    <title>Commons Compress (Sandbox) Issue tracking</title>
+    <author email="dev@commons.apache.org">Commons Documentation Team</author>
+  </properties>
+  <body>
+
+    <section name="Commons Compress (Sandbox) Issue tracking">
+      <p>
+      Commons Compress (Sandbox) uses <a href="http://issues.apache.org/jira/">ASF JIRA</a> for tracking issues.
+      See the <a href="http://issues.apache.org/jira/browse/SANDBOX">Sandbox JIRA project page</a>.
+      </p>
+
+      <p>
+      To use JIRA you may need to <a href="http://issues.apache.org/jira/secure/Signup!default.jspa">create an account</a>
+      (if you have previously created/updated Commons issues using Bugzilla an account will have been automatically
+      created and you can use the <a href="http://issues.apache.org/jira/secure/ForgotPassword!default.jspa">Forgot Password</a>
+      page to get a new password).
+      </p>
+
+      <p>
+      If you would like to report a bug, or raise an enhancement request with
+      Commons Compress (Sandbox) please do the following:
+      <ol>
+        <li><a href="http://issues.apache.org/jira/secure/IssueNavigator.jspa?reset=true&amp;pid=12310491&amp;component=12311183&amp;sorter/field=issuekey&amp;sorter/order=DESC&amp;status=1&amp;status=3&amp;status=4">Search existing open bugs</a>.
+            If you find your issue listed then please add a comment with your details.</li>
+        <li><a href="mail-lists.html">Search the mailing list archive(s)</a>.
+            You may find your issue or idea has already been discussed.</li>
+        <li>Decide if your issue is a bug or an enhancement.</li>
+        <li>Submit either a <a href="http://issues.apache.org/jira/secure/CreateIssueDetails!init.jspa?pid=12310491&amp;components=12311183&amp;issuetype=1&amp;priority=4&amp;assignee=-1">bug report</a>
+            or <a href="http://issues.apache.org/jira/secure/CreateIssueDetails!init.jspa?pid=12310491&amp;components=12311183&amp;issuetype=4&amp;priority=4&amp;assignee=-1">enhancement request</a>.</li>
+      </ol>
+      </p>
+
+      <p>
+      Please also remember these points:
+      <ul>
+        <li>the more information you provide, the better we can help you</li>
+        <li>test cases are vital, particularly for any proposed enhancements</li>
+        <li>the developers of Commons Compress (Sandbox) are all unpaid volunteers</li>
+      </ul>
+      </p>
+
+      <p>
+      For more information on subversion and creating patches see the
+      <a href="http://www.apache.org/dev/contributors.html">Apache Contributors Guide</a>.
+      </p>
+
+      <p>
+      You may also find these links useful:
+      <ul>
+        <li><a href="http://issues.apache.org/jira/secure/IssueNavigator.jspa?reset=true&amp;pid=12310491&amp;component=12311183&amp;sorter/field=issuekey&amp;sorter/order=DESC&amp;status=1&amp;status=3&amp;status=4">All Open Commons Compress (Sandbox) bugs</a></li>
+        <li><a href="http://issues.apache.org/jira/secure/IssueNavigator.jspa?reset=true&amp;pid=12310491&amp;component=12311183&amp;sorter/field=issuekey&amp;sorter/order=DESC&amp;status=5&amp;status=6">All Resolved Commons Compress (Sandbox) bugs</a></li>
+        <li><a href="http://issues.apache.org/jira/secure/IssueNavigator.jspa?reset=true&amp;pid=12310491&amp;component=12311183&amp;sorter/field=issuekey&amp;sorter/order=DESC">All Commons Compress (Sandbox) bugs</a></li>
+      </ul>
+      </p>
+    </section>
+  </body>
+</document>
diff --git a/src/site/xdoc/style/project.css b/src/site/xdoc/style/project.css
new file mode 100644
index 0000000..0130204
--- /dev/null
+++ b/src/site/xdoc/style/project.css
@@ -0,0 +1 @@
+@import url("http://jakarta.apache.org/style/jakarta-maven.css");
diff --git a/src/test/java/org/apache/commons/compress/archivers/CompressTestCase.java b/src/test/java/org/apache/commons/compress/archivers/CompressTestCase.java
new file mode 100644
index 0000000..e0d9e19
--- /dev/null
+++ b/src/test/java/org/apache/commons/compress/archivers/CompressTestCase.java
@@ -0,0 +1,338 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers;
+
+import java.io.BufferedInputStream;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.InputStream;
+import java.io.OutputStream;
+
+import junit.framework.TestCase;
+
+import org.apache.commons.compress.archivers.ar.ArArchiveEntry;
+import org.apache.commons.compress.archivers.ar.ArArchiveInputStream;
+import org.apache.commons.compress.archivers.jar.JarArchiveInputStream;
+import org.apache.commons.compress.archivers.tar.TarArchiveEntry;
+import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;
+import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;
+import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;
+import org.apache.commons.compress.compressors.CompressorInputStream;
+import org.apache.commons.compress.compressors.CompressorOutputStream;
+import org.apache.commons.compress.compressors.CompressorStreamFactory;
+import org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;
+import org.apache.commons.compress.utils.IOUtils;
+
+public final class CompressTestCase extends TestCase {
+
+	private File dir;
+	
+	protected void setUp() throws Exception {
+		dir = File.createTempFile("dir", "");
+		dir.delete();
+		dir.mkdir();
+	}
+
+	protected void tearDown() throws Exception {
+		dir.delete();
+		dir = null;
+	}
+
+
+	public void testGzipCreation()  throws Exception {
+		final File output = new File(dir, "bla.gz");
+		final File file1 = new File(getClass().getClassLoader().getResource("test1.xml").getFile());
+		final OutputStream out = new FileOutputStream(output);
+		CompressorOutputStream cos = new CompressorStreamFactory().createCompressorOutputStream("gz", out);
+		IOUtils.copy(new FileInputStream(file1), cos);
+		cos.close();
+	}
+	
+	public void testGzipUnarchive() throws Exception {
+		final File output = new File(dir, "bla-entpackt.tar");
+		final File input = new File(getClass().getClassLoader().getResource("bla.tgz").getFile());
+        final InputStream is = new FileInputStream(input);
+        final CompressorInputStream in = new CompressorStreamFactory().createCompressorInputStream("gz", is);
+        IOUtils.copy(in, new FileOutputStream(output));
+		in.close();
+    }
+	
+	public void testBzipCreation()  throws Exception {
+		final File output = new File(dir, "bla.txt.bz2");
+		System.out.println(dir);
+		final File file1 = new File(getClass().getClassLoader().getResource("test.txt").getFile());
+		final OutputStream out = new FileOutputStream(output);
+		CompressorOutputStream cos = new CompressorStreamFactory().createCompressorOutputStream("bzip2", out);
+		IOUtils.copy(new FileInputStream(file1), cos);
+		cos.close();
+	}
+	
+	public void testBzip2Unarchive() throws Exception {
+		final File output = new File(dir, "test-entpackt.txt");
+		System.out.println(dir);
+		final File input = new File(getClass().getClassLoader().getResource("bla.txt.bz2").getFile());
+        final InputStream is = new FileInputStream(input);
+        //final CompressorInputStream in = new CompressorStreamFactory().createCompressorInputStream("bzip2", is);
+        final CompressorInputStream in = new BZip2CompressorInputStream(is);
+        IOUtils.copy(in, new FileOutputStream(output));
+		in.close();
+    }
+	
+	public void testJarArchiveCreation() throws Exception {
+		final File output = new File(dir, "bla.jar");
+
+		final File file1 = new File(getClass().getClassLoader().getResource("test1.xml").getFile());
+		final File file2 = new File(getClass().getClassLoader().getResource("test2.xml").getFile());
+		
+        final OutputStream out = new FileOutputStream(output);
+        
+        final ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream("jar", out);
+
+        os.putArchiveEntry(new ZipArchiveEntry("testdata/test1.xml"));
+        IOUtils.copy(new FileInputStream(file1), os);
+        os.closeArchiveEntry();
+        
+        os.putArchiveEntry(new ZipArchiveEntry("testdata/test2.xml"));
+        IOUtils.copy(new FileInputStream(file2), os);
+        os.closeArchiveEntry();
+
+        os.close();
+    }
+	
+	public void testJarUnarchive() throws Exception {
+		final File input = new File(getClass().getClassLoader().getResource("bla.jar").getFile());
+        final InputStream is = new FileInputStream(input);
+        final ArchiveInputStream in = new ArchiveStreamFactory().createArchiveInputStream("jar", is);
+        
+        ZipArchiveEntry entry = (ZipArchiveEntry)in.getNextEntry();
+        File o = new File(dir, entry.getName());
+        o.getParentFile().mkdirs();
+        OutputStream out = new FileOutputStream(o);
+        IOUtils.copy(in, out);
+        out.close();
+        
+        entry = (ZipArchiveEntry)in.getNextEntry();
+        o = new File(dir, entry.getName());
+        o.getParentFile().mkdirs();
+        out = new FileOutputStream(o);
+        IOUtils.copy(in, out);
+        out.close();
+        
+        entry = (ZipArchiveEntry)in.getNextEntry();
+        o = new File(dir, entry.getName());
+        o.getParentFile().mkdirs();
+        out = new FileOutputStream(o);
+        IOUtils.copy(in, out);
+        out.close();
+        
+        in.close();
+    }
+	
+	
+	public void testDetection() throws Exception {
+		final ArchiveStreamFactory factory = new ArchiveStreamFactory();
+
+		final ArchiveInputStream ar = factory.createArchiveInputStream(
+				new BufferedInputStream(new FileInputStream(
+						new File(getClass().getClassLoader().getResource("bla.ar").getFile())))); 
+		assertTrue(ar instanceof ArArchiveInputStream);
+
+		final ArchiveInputStream tar = factory.createArchiveInputStream(
+				new BufferedInputStream(new FileInputStream(
+						new File(getClass().getClassLoader().getResource("bla.tar").getFile()))));
+		assertTrue(tar instanceof TarArchiveInputStream);
+
+		final ArchiveInputStream zip = factory.createArchiveInputStream(
+				new BufferedInputStream(new FileInputStream(
+						new File(getClass().getClassLoader().getResource("bla.zip").getFile()))));
+		assertTrue(zip instanceof ZipArchiveInputStream);
+
+		final ArchiveInputStream jar = factory.createArchiveInputStream(
+				new BufferedInputStream(new FileInputStream(
+						new File(getClass().getClassLoader().getResource("bla.jar").getFile()))));
+		assertTrue(jar instanceof JarArchiveInputStream);
+
+//		final ArchiveInputStream tgz = factory.createArchiveInputStream(
+//				new BufferedInputStream(new FileInputStream(
+//						new File(getClass().getClassLoader().getResource("bla.tgz").getFile()))));
+//		assertTrue(tgz instanceof TarArchiveInputStream);
+		
+	}
+	
+	public void testArArchiveCreation() throws Exception {
+		final File output = new File(dir, "bla.ar");
+		
+		final File file1 = new File(getClass().getClassLoader().getResource("test1.xml").getFile());
+		final File file2 = new File(getClass().getClassLoader().getResource("test2.xml").getFile());
+		
+		final OutputStream out = new FileOutputStream(output);
+        final ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream("ar", out);
+		os.putArchiveEntry(new ArArchiveEntry("test1.xml", file1.length()));
+		IOUtils.copy(new FileInputStream(file1), os);
+		os.closeArchiveEntry();
+		
+		os.putArchiveEntry(new ArArchiveEntry("test2.xml", file2.length()));
+		IOUtils.copy(new FileInputStream(file2), os);
+		os.closeArchiveEntry();
+		
+		os.close();
+	}
+	
+	public void testArUnarchive() throws Exception {
+		final File output = new File(dir, "bla.ar");
+		{
+			final File file1 = new File(getClass().getClassLoader().getResource("test1.xml").getFile());
+			final File file2 = new File(getClass().getClassLoader().getResource("test2.xml").getFile());
+			
+			final OutputStream out = new FileOutputStream(output);
+	        final ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream("ar", out);
+			os.putArchiveEntry(new ArArchiveEntry("test1.xml", file1.length()));
+			IOUtils.copy(new FileInputStream(file1), os);
+			os.closeArchiveEntry();
+			
+			os.putArchiveEntry(new ArArchiveEntry("test2.xml", file2.length()));
+			IOUtils.copy(new FileInputStream(file2), os);
+			os.closeArchiveEntry();
+			os.close();
+		}
+		
+		// UnArArchive Operation
+		final File input = output;
+		final InputStream is = new FileInputStream(input);
+		final ArchiveInputStream in = new ArchiveStreamFactory().createArchiveInputStream("ar", is);
+		final ArArchiveEntry entry = (ArArchiveEntry)in.getNextEntry();
+		
+		File target = new File(dir, entry.getName());
+        final OutputStream out = new FileOutputStream(target);
+        
+        IOUtils.copy(in, out);
+    
+        out.close();
+        in.close();
+	}
+	
+	public void testZipArchiveCreation() throws Exception {
+		
+		final File output = new File(dir, "bla.zip");
+		
+		final File file1 = new File(getClass().getClassLoader().getResource("test1.xml").getFile());
+		final File file2 = new File(getClass().getClassLoader().getResource("test2.xml").getFile());
+		
+        final OutputStream out = new FileOutputStream(output);
+        
+        final ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream("zip", out);
+
+        os.putArchiveEntry(new ZipArchiveEntry("testdata/test1.xml"));
+        IOUtils.copy(new FileInputStream(file1), os);
+        os.closeArchiveEntry();
+        
+        os.putArchiveEntry(new ZipArchiveEntry("testdata/test2.xml"));
+        IOUtils.copy(new FileInputStream(file2), os);
+        os.closeArchiveEntry();
+        
+        os.close();
+    }
+    
+    public void testTarArchiveCreation() throws Exception {
+
+		final File output = new File(dir, "bla.tar");
+
+		final File file1 = new File(getClass().getClassLoader().getResource("test1.xml").getFile());
+
+    	final OutputStream out = new FileOutputStream(output);
+        
+        final ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream("tar", out);
+        
+        final TarArchiveEntry entry = new TarArchiveEntry("testdata/test1.xml");
+        entry.setModTime(0);
+        entry.setSize(file1.length());
+        entry.setUserID(0);
+        entry.setGroupID(0);
+        entry.setUserName("avalon");
+        entry.setGroupName("excalibur");
+        entry.setMode(0100000);
+        
+        os.putArchiveEntry(entry);
+        IOUtils.copy(new FileInputStream(file1), os);
+
+        os.closeArchiveEntry();
+        os.close();
+    }
+    
+    public void testZipUnarchive() throws Exception {
+
+		final File input = new File(getClass().getClassLoader().getResource("bla.zip").getFile());
+    	
+        final InputStream is = new FileInputStream(input);
+        final ArchiveInputStream in = new ArchiveStreamFactory().createArchiveInputStream("zip", is);
+ 
+        final ZipArchiveEntry entry = (ZipArchiveEntry)in.getNextEntry();
+        final OutputStream out = new FileOutputStream(new File(dir, entry.getName()));
+        
+        IOUtils.copy(in, out);
+    
+        out.close();
+        in.close();
+    }
+        
+    public void testTarUnarchive() throws Exception {
+		final File input = new File(getClass().getClassLoader().getResource("bla.tar").getFile());
+		final InputStream is = new FileInputStream(input);
+        final ArchiveInputStream in = new ArchiveStreamFactory().createArchiveInputStream("tar", is);
+        final TarArchiveEntry entry = (TarArchiveEntry)in.getNextEntry();
+        final OutputStream out = new FileOutputStream(new File(dir, entry.getName()));
+        IOUtils.copy(in, out);
+        out.close();
+        in.close();
+    }
+    
+//  public void testZipUnarchive() throws Exception {
+//        ZipInputStream zip = 
+//            new ZipInputStream(new FileInputStream("C:\\dev\\sources\\compress\\testdata\\bla.zip"));
+//        Iterator iterator = zip.getEntryIterator();
+//        while (iterator.hasNext()) {
+//            ArchiveEntry entry = (ArchiveEntry) iterator.next();
+//            OutputStream output = new FileOutputStream("testdata\\blub\\" + entry.getName());
+//            IOUtils.copy(zip, output);
+//        }
+//        zip.close();
+//    }
+
+    
+//	public void xtestFactoryUnarchive() throws Exception {
+//		CompressUtils.unpack(new FileInputStream("bla.tgz"), new File("output"));
+//	}
+//
+//	
+//	public void xtestArUnarchive() throws Exception {
+//		ArchiveInputStream ar = new ArArchiveInputStream(new FileInputStream("bla.tgz"));
+//		Iterator iterator = ar.getEntryIterator();
+//		while(iterator.hasNext()) {
+//			ArchiveEntry entry = (ArchiveEntry) iterator.next();
+//			OutputStream output = new FileOutputStream(entry.getName());
+//			IOUtils.copy(ar, output);
+//		}
+//		ar.close();
+//	}
+//
+
+//
+
+}
diff --git a/src/test/java/org/apache/commons/compress/archivers/memory/MemoryArchiveEntry.java b/src/test/java/org/apache/commons/compress/archivers/memory/MemoryArchiveEntry.java
new file mode 100644
index 0000000..f670a08
--- /dev/null
+++ b/src/test/java/org/apache/commons/compress/archivers/memory/MemoryArchiveEntry.java
@@ -0,0 +1,40 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.memory;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+
+public final class MemoryArchiveEntry implements ArchiveEntry {
+
+	private final String name;
+	
+	public MemoryArchiveEntry( final String pName ) {
+		name = pName;
+	}
+	
+	public String getName() {
+		return name;
+	}
+
+	public long getSize() {
+		// TODO Auto-generated method stub
+		return 0;
+	}
+
+}
diff --git a/src/test/java/org/apache/commons/compress/archivers/memory/MemoryArchiveInputStream.java b/src/test/java/org/apache/commons/compress/archivers/memory/MemoryArchiveInputStream.java
new file mode 100644
index 0000000..616f292
--- /dev/null
+++ b/src/test/java/org/apache/commons/compress/archivers/memory/MemoryArchiveInputStream.java
@@ -0,0 +1,60 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.archivers.memory;
+
+import java.io.IOException;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.ArchiveInputStream;
+
+public final class MemoryArchiveInputStream extends ArchiveInputStream {
+
+	private final String[] filenames;
+	private final String[] content;
+	private int p;
+	
+	public MemoryArchiveInputStream( final String[][] pFiles ) {
+		filenames = new String[pFiles.length];
+		content = new String[pFiles.length];
+		
+		for (int i = 0; i < pFiles.length; i++) {
+			String[] nameAndContent = pFiles[i];
+			filenames[i] = nameAndContent[0];
+			content[i] = nameAndContent[1];
+		}
+		p = 0;
+	}
+	
+	public ArchiveEntry getNextEntry() throws IOException {
+		if (p >= filenames.length) {
+			return null;
+		}
+
+		return new MemoryArchiveEntry(filenames[p]);
+	}
+
+	public String readString() {
+		return content[p++];
+	}
+	
+	public int read() throws IOException {
+		return 0;
+	}
+
+}
diff --git a/src/test/java/org/apache/commons/compress/archivers/memory/MemoryArchiveTestCase.java b/src/test/java/org/apache/commons/compress/archivers/memory/MemoryArchiveTestCase.java
new file mode 100644
index 0000000..3df4b0e
--- /dev/null
+++ b/src/test/java/org/apache/commons/compress/archivers/memory/MemoryArchiveTestCase.java
@@ -0,0 +1,35 @@
+package org.apache.commons.compress.archivers.memory;
+
+import java.io.IOException;
+
+import junit.framework.TestCase;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+
+public final class MemoryArchiveTestCase extends TestCase {
+
+	public void testReading() throws IOException {
+		
+		final MemoryArchiveInputStream is = new MemoryArchiveInputStream(new String[][] {
+				{ "test1",     "content1" },
+				{ "test2",     "content2" },
+				});
+
+		final ArchiveEntry entry1 = is.getNextEntry();
+		assertNotNull(entry1);
+		assertEquals("test1", entry1.getName());
+		final String content1 = is.readString();
+		assertEquals("content1", content1);
+		
+		final ArchiveEntry entry2 = is.getNextEntry();
+		assertNotNull(entry2);
+		assertEquals("test2", entry2.getName());
+		final String content2 = is.readString();
+		assertEquals("content2", content2);
+		
+		final ArchiveEntry entry3 = is.getNextEntry();
+		assertNull(entry3);
+		
+	}
+
+}
diff --git a/src/test/java/org/apache/commons/compress/changes/ChangeSetTestCase.java b/src/test/java/org/apache/commons/compress/changes/ChangeSetTestCase.java
new file mode 100644
index 0000000..0cdbb55
--- /dev/null
+++ b/src/test/java/org/apache/commons/compress/changes/ChangeSetTestCase.java
@@ -0,0 +1,53 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.commons.compress.changes;
+
+import java.io.IOException;
+
+import junit.framework.TestCase;
+
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.ArchiveInputStream;
+import org.apache.commons.compress.archivers.memory.MemoryArchiveInputStream;
+
+public final class ChangeSetTestCase extends TestCase {
+
+	private void apply( final ChangeSet cs ) throws IOException {
+		
+		final ArchiveInputStream is = new MemoryArchiveInputStream(new String[][] {
+				{ "test1",      "" },
+				{ "test2",      "" },
+				{ "dir1/test1", "" },
+				{ "dir1/test2", "" },
+				{ "dir2/test1", "" },
+				{ "dir2/test2", "" }
+				});
+		
+		while(true) {
+			final ArchiveEntry entry = is.getNextEntry();
+			
+			if (entry == null) {
+				break;
+			}
+			
+			// delete, new name, new content
+		}
+	}
+	
+}
diff --git a/src/test/java/org/apache/commons/compress/changes/ChangeWorkerTest.java b/src/test/java/org/apache/commons/compress/changes/ChangeWorkerTest.java
new file mode 100644
index 0000000..a491e8d
--- /dev/null
+++ b/src/test/java/org/apache/commons/compress/changes/ChangeWorkerTest.java
@@ -0,0 +1,64 @@
+/**
+ * 
+ */
+package org.apache.commons.compress.changes;
+
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.InputStream;
+
+import junit.framework.TestCase;
+
+import org.apache.commons.compress.archivers.ArchiveInputStream;
+import org.apache.commons.compress.archivers.memory.MemoryArchiveInputStream;
+import org.apache.commons.compress.archivers.*;
+/**
+ * @author Cy
+ *
+ */
+public class ChangeWorkerTest extends TestCase {
+
+	final ArchiveInputStream is = null;
+	
+	/* (non-Javadoc)
+	 * @see junit.framework.TestCase#setUp()
+	 */
+	protected void setUp() throws Exception {
+		super.setUp();
+		final ArchiveInputStream is = new MemoryArchiveInputStream(new String[][] {
+				{ "test1",      "" },
+				{ "test2",      "" },
+				{ "dir1/test1", "" },
+				{ "dir1/test2", "" },
+				{ "dir2/test1", "" },
+				{ "dir2/test2", "" }
+				});
+	}
+
+	/* (non-Javadoc)
+	 * @see junit.framework.TestCase#tearDown()
+	 */
+	protected void tearDown() throws Exception {
+		super.tearDown();
+	}
+
+	/**
+	 * Test method for {@link org.apache.commons.compress.changes.ChangeWorker#perform(org.apache.commons.compress.changes.ChangeSet, java.io.InputStream, java.io.OutputStream)}.
+	 */
+	public void testPerform() throws Exception {
+		ChangeSet changes = new ChangeSet();
+		changes.delete("test2.xml");
+		
+		final File input = new File(getClass().getClassLoader().getResource("bla.zip").getFile());
+		final InputStream is = new FileInputStream(input);
+		ArchiveInputStream ais = new ArchiveStreamFactory().createArchiveInputStream("zip", is);
+		
+		File temp = File.createTempFile("test", ".zip");
+		ArchiveOutputStream out = new ArchiveStreamFactory().createArchiveOutputStream("zip", new FileOutputStream(temp));
+		
+		System.out.println(temp.getAbsolutePath());
+		ChangeWorker.perform(changes, ais, out);
+	}
+
+}
diff --git a/src/test/resources/bla.ar b/src/test/resources/bla.ar
new file mode 100644
index 0000000..c98e9b7
--- /dev/null
+++ b/src/test/resources/bla.ar
@@ -0,0 +1,27 @@
+!<arch>
+test1.xml       1201445869  501   501   100644  610       `
+<?xml version = '1.0'?>
+<!DOCTYPE connections>
+<connections>
+<<<<<<< HEAD:testdata/test.xml
+=======
+    as
+>>>>>>> 75cb63ff7005344589b57d17338b64783f8f430c:testdata/test.xml
+   <connection>
+      <JDBC_PORT>1521</JDBC_PORT>
+      <HOSTNAME>10.248.40.111</HOSTNAME>
+      <ConnectionType>JDBC</ConnectionType>
+      <DeployPassword>false</DeployPassword>
+      <user>appsrv</user>
+      <ConnectionName>Dev-DB</ConnectionName>
+      <SID>O10gIN1</SID>
+      <JdbcDriver>oracle.jdbc.driver.OracleDriver</JdbcDriver>
+      <ORACLE_JDBC_TYPE>thin</ORACLE_JDBC_TYPE>
+   </connection>
+</connections>
+test2.xml       1201445869  501   501   100644  82        `
+<?xml version = '1.0'?>
+<!DOCTYPE connections>
+<meinxml>
+	<leer />
+</meinxml>
diff --git a/src/test/resources/bla.jar b/src/test/resources/bla.jar
new file mode 100644
index 0000000..ad3ed82
--- /dev/null
+++ b/src/test/resources/bla.jar
Binary files differ
diff --git a/src/test/resources/bla.tar b/src/test/resources/bla.tar
new file mode 100644
index 0000000..c7af537
--- /dev/null
+++ b/src/test/resources/bla.tar
Binary files differ
diff --git a/src/test/resources/bla.tgz b/src/test/resources/bla.tgz
new file mode 100644
index 0000000..d741f1e
--- /dev/null
+++ b/src/test/resources/bla.tgz
Binary files differ
diff --git a/src/test/resources/bla.txt.bz2 b/src/test/resources/bla.txt.bz2
new file mode 100644
index 0000000..997cb62
--- /dev/null
+++ b/src/test/resources/bla.txt.bz2
Binary files differ
diff --git a/src/test/resources/bla.xml.bz2 b/src/test/resources/bla.xml.bz2
new file mode 100644
index 0000000..a2bbcfc
--- /dev/null
+++ b/src/test/resources/bla.xml.bz2
Binary files differ
diff --git a/src/test/resources/bla.zip b/src/test/resources/bla.zip
new file mode 100644
index 0000000..160eedc
--- /dev/null
+++ b/src/test/resources/bla.zip
Binary files differ
diff --git a/src/test/resources/test.txt b/src/test/resources/test.txt
new file mode 100644
index 0000000..beecb75
--- /dev/null
+++ b/src/test/resources/test.txt
@@ -0,0 +1,10 @@
+111111111111111111111111111000101011
+111111111111111111111111111000101011
+111111111111111111111111111000101011
+111111111111111111111111111000101011
+111111111111111111111111111000101011
+111111111111111111111111111000101011
+111111111111111111111111111000101011
+111111111111111111111111111000101011
+111111111111111111111111111000101011
+111111111111111111111111111000101011
\ No newline at end of file
diff --git a/src/test/resources/test1.xml b/src/test/resources/test1.xml
new file mode 100644
index 0000000..9e1a188
--- /dev/null
+++ b/src/test/resources/test1.xml
@@ -0,0 +1,19 @@
+<?xml version = '1.0'?>
+<!DOCTYPE connections>
+<connections>
+<<<<<<< HEAD:testdata/test.xml
+=======
+    as
+>>>>>>> 75cb63ff7005344589b57d17338b64783f8f430c:testdata/test.xml
+   <connection>
+      <JDBC_PORT>1521</JDBC_PORT>
+      <HOSTNAME>10.248.40.111</HOSTNAME>
+      <ConnectionType>JDBC</ConnectionType>
+      <DeployPassword>false</DeployPassword>
+      <user>appsrv</user>
+      <ConnectionName>Dev-DB</ConnectionName>
+      <SID>O10gIN1</SID>
+      <JdbcDriver>oracle.jdbc.driver.OracleDriver</JdbcDriver>
+      <ORACLE_JDBC_TYPE>thin</ORACLE_JDBC_TYPE>
+   </connection>
+</connections>
diff --git a/src/test/resources/test2.xml b/src/test/resources/test2.xml
new file mode 100644
index 0000000..00c6dc9
--- /dev/null
+++ b/src/test/resources/test2.xml
@@ -0,0 +1,5 @@
+<?xml version = '1.0'?>
+<!DOCTYPE connections>
+<meinxml>
+	<leer />
+</meinxml>
