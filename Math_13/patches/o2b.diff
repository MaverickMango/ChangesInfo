diff -r -u original/src/main/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizer.java buggy/src/main/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizer.java
--- original/src/main/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizer.java	2023-06-13 15:31:52.047143686 +0800
+++ buggy/src/main/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizer.java	2023-06-12 11:40:40.402082620 +0800
@@ -20,14 +20,16 @@
 import org.apache.commons.math3.analysis.DifferentiableMultivariateVectorFunction;
 import org.apache.commons.math3.analysis.FunctionUtils;
 import org.apache.commons.math3.analysis.differentiation.DerivativeStructure;
-import org.apache.commons.math3.analysis.differentiation.JacobianFunction;
 import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction;
 import org.apache.commons.math3.exception.DimensionMismatchException;
 import org.apache.commons.math3.exception.NumberIsTooSmallException;
 import org.apache.commons.math3.exception.util.LocalizedFormats;
+import org.apache.commons.math3.linear.ArrayRealVector;
+import org.apache.commons.math3.linear.RealMatrix;
 import org.apache.commons.math3.linear.DecompositionSolver;
 import org.apache.commons.math3.linear.MatrixUtils;
 import org.apache.commons.math3.linear.QRDecomposition;
+import org.apache.commons.math3.linear.EigenDecomposition;
 import org.apache.commons.math3.optimization.OptimizationData;
 import org.apache.commons.math3.optimization.InitialGuess;
 import org.apache.commons.math3.optimization.Target;
@@ -41,23 +43,30 @@
 /**
  * Base class for implementing least squares optimizers.
  * It handles the boilerplate methods associated to thresholds settings,
- * jacobian and error estimation.
+ * Jacobian and error estimation.
  * <br/>
- * This class uses the {@link JacobianFunction Jacobian} of the function argument in method
- * {@link #optimize(int, MultivariateDifferentiableVectorFunction, double[], double[], double[])
- * optimize} and assumes that, in the matrix returned by the
- * {@link JacobianFunction#value(double[]) value} method, the rows
- * iterate on the model functions while the columns iterate on the parameters; thus,
- * the numbers of rows is equal to the length of the {@code target} array while the
- * number of columns is equal to the length of the {@code startPoint} array.
+ * This class constructs the Jacobian matrix of the function argument in method
+ * {@link BaseAbstractMultivariateVectorOptimizer#optimize(int,MultivariateVectorFunction,OptimizationData[])
+ * optimize} and assumes that the rows of that matrix iterate on the model
+ * functions while the columns iterate on the parameters; thus, the numbers
+ * of rows is equal to the dimension of the
+ * {@link org.apache.commons.math3.optimization.Target Target} while
+ * the number of columns is equal to the dimension of the
+ * {@link org.apache.commons.math3.optimization.InitialGuess InitialGuess}.
  *
  * @version $Id$
+ * @deprecated As of 3.1 (to be removed in 4.0).
  * @since 1.2
  */
+@Deprecated
 public abstract class AbstractLeastSquaresOptimizer
     extends BaseAbstractMultivariateVectorOptimizer<DifferentiableMultivariateVectorFunction>
     implements DifferentiableMultivariateVectorOptimizer {
-    /** Singularity threshold (cf. {@link #getCovariances(double)}). */
+    /**
+     * Singularity threshold (cf. {@link #getCovariances(double)}).
+     * @deprecated As of 3.1.
+     */
+    @Deprecated
     private static final double DEFAULT_SINGULARITY_THRESHOLD = 1e-14;
     /**
      * Jacobian matrix of the weighted residuals.
@@ -65,24 +74,48 @@
      * {@link #updateJacobian()}, but may be modified by the solver
      * in the derived class (the {@link LevenbergMarquardtOptimizer
      * Levenberg-Marquardt optimizer} does this).
+     * @deprecated As of 3.1. To be removed in 4.0. Please use
+     * {@link #computeWeightedJacobian(double[])} instead.
      */
+    @Deprecated
     protected double[][] weightedResidualJacobian;
-    /** Number of columns of the jacobian matrix. */
+    /** Number of columns of the jacobian matrix.
+     * @deprecated As of 3.1.
+     */
+    @Deprecated
     protected int cols;
-    /** Number of rows of the jacobian matrix. */
+    /** Number of rows of the jacobian matrix.
+     * @deprecated As of 3.1.
+     */
+    @Deprecated
     protected int rows;
-    /** Current point. */
+    /** Current point.
+     * @deprecated As of 3.1.
+     */
+    @Deprecated
     protected double[] point;
-    /** Current objective function value. */
+    /** Current objective function value.
+     * @deprecated As of 3.1.
+     */
+    @Deprecated
     protected double[] objective;
-    /** Weighted residuals */
+    /** Weighted residuals
+     * @deprecated As of 3.1.
+     */
+    @Deprecated
     protected double[] weightedResiduals;
-    /** Cost value (square root of the sum of the residuals). */
+    /** Cost value (square root of the sum of the residuals).
+     * @deprecated As of 3.1. Field to become "private" in 4.0.
+     * Please use {@link #setCost(double)}.
+     */
+    @Deprecated
     protected double cost;
     /** Objective function derivatives. */
     private MultivariateDifferentiableVectorFunction jF;
     /** Number of evaluations of the Jacobian. */
     private int jacobianEvaluations;
+    /** Square-root of the weight matrix. */
+    private RealMatrix weightMatrixSqrt;
 
     /**
      * Simple constructor with default settings.
@@ -112,37 +145,48 @@
      *
      * @throws DimensionMismatchException if the Jacobian dimension does not
      * match problem dimension.
+     * @deprecated As of 3.1. Please use {@link #computeWeightedJacobian(double[])}
+     * instead.
      */
+    @Deprecated
     protected void updateJacobian() {
+        final RealMatrix weightedJacobian = computeWeightedJacobian(point);
+        weightedResidualJacobian = weightedJacobian.scalarMultiply(-1).getData();
+    }
+
+    /**
+     * Computes the Jacobian matrix.
+     *
+     * @param params Model parameters at which to compute the Jacobian.
+     * @return the weighted Jacobian: W<sup>1/2</sup> J.
+     * @throws DimensionMismatchException if the Jacobian dimension does not
+     * match problem dimension.
+     * @since 3.1
+     */
+    protected RealMatrix computeWeightedJacobian(double[] params) {
         ++jacobianEvaluations;
 
-        DerivativeStructure[] dsPoint = new DerivativeStructure[point.length];
-        for (int i = 0; i < point.length; ++i) {
-            dsPoint[i] = new DerivativeStructure(point.length, 1, i, point[i]);
+        final DerivativeStructure[] dsPoint = new DerivativeStructure[params.length];
+        final int nC = params.length;
+        for (int i = 0; i < nC; ++i) {
+            dsPoint[i] = new DerivativeStructure(nC, 1, i, params[i]);
         }
-        DerivativeStructure[] dsValue = jF.value(dsPoint);
-        if (dsValue.length != rows) {
-            throw new DimensionMismatchException(dsValue.length, rows);
+        final DerivativeStructure[] dsValue = jF.value(dsPoint);
+        final int nR = getTarget().length;
+        if (dsValue.length != nR) {
+            throw new DimensionMismatchException(dsValue.length, nR);
         }
-        for (int i = 0; i < rows; ++i) {
-            int[] orders = new int[point.length];
-            for (int j = 0; j < point.length; ++j) {
+        final double[][] jacobianData = new double[nR][nC];
+        for (int i = 0; i < nR; ++i) {
+            int[] orders = new int[nC];
+            for (int j = 0; j < nC; ++j) {
                 orders[j] = 1;
-                weightedResidualJacobian[i][j] = dsValue[i].getPartialDerivative(orders);
+                jacobianData[i][j] = dsValue[i].getPartialDerivative(orders);
                 orders[j] = 0;
             }
         }
 
-        final double[] residualsWeights = getWeightRef();
-
-        for (int i = 0; i < rows; i++) {
-            final double[] ji = weightedResidualJacobian[i];
-            double wi = FastMath.sqrt(residualsWeights[i]);
-            for (int j = 0; j < cols; ++j) {
-                //ji[j] *=  -1.0;
-                weightedResidualJacobian[i][j] = -ji[j]*wi;
-            }
-        }
+        return weightMatrixSqrt.multiply(MatrixUtils.createRealMatrix(jacobianData));
     }
 
     /**
@@ -151,23 +195,34 @@
      * problem dimension.
      * @throws org.apache.commons.math3.exception.TooManyEvaluationsException
      * if the maximal number of evaluations is exceeded.
+     * @deprecated As of 3.1. Please use {@link #computeResiduals(double[])},
+     * {@link #computeObjectiveValue(double[])}, {@link #computeCost(double[])}
+     * and {@link #setCost(double)} instead.
      */
+    @Deprecated
     protected void updateResidualsAndCost() {
         objective = computeObjectiveValue(point);
-        if (objective.length != rows) {
-            throw new DimensionMismatchException(objective.length, rows);
-        }
+        final double[] res = computeResiduals(objective);
 
-        final double[] targetValues = getTargetRef();
-        final double[] residualsWeights = getWeightRef();
+        // Compute cost.
+        cost = computeCost(res);
 
-        cost = 0;
-        for (int i = 0; i < rows; i++) {
-            final double residual = targetValues[i] - objective[i];
-            weightedResiduals[i]= residual*FastMath.sqrt(residualsWeights[i]);
-            cost += residualsWeights[i] * residual * residual;
-        }
-        cost = FastMath.sqrt(cost);
+        // Compute weighted residuals.
+        final ArrayRealVector residuals = new ArrayRealVector(res);
+        weightedResiduals = weightMatrixSqrt.operate(residuals).toArray();
+    }
+
+    /**
+     * Computes the cost.
+     *
+     * @param residuals Residuals.
+     * @return the cost.
+     * @see #computeResiduals(double[])
+     * @since 3.1
+     */
+    protected double computeCost(double[] residuals) {
+        final ArrayRealVector r = new ArrayRealVector(residuals);
+        return FastMath.sqrt(r.dotProduct(getWeight().operate(r)));
     }
 
     /**
@@ -195,14 +250,36 @@
     }
 
     /**
+     * Gets the square-root of the weight matrix.
+     *
+     * @return the square-root of the weight matrix.
+     * @since 3.1
+     */
+    public RealMatrix getWeightSquareRoot() {
+        return weightMatrixSqrt.copy();
+    }
+
+    /**
+     * Sets the cost.
+     *
+     * @param cost Cost value.
+     * @since 3.1
+     */
+    protected void setCost(double cost) {
+        this.cost = cost;
+    }
+
+    /**
      * Get the covariance matrix of the optimized parameters.
      *
      * @return the covariance matrix.
      * @throws org.apache.commons.math3.linear.SingularMatrixException
      * if the covariance matrix cannot be computed (singular problem).
-     *
      * @see #getCovariances(double)
+     * @deprecated As of 3.1. Please use {@link #computeCovariances(double[],double)}
+     * instead.
      */
+    @Deprecated
     public double[][] getCovariances() {
         return getCovariances(DEFAULT_SINGULARITY_THRESHOLD);
     }
@@ -221,27 +298,42 @@
      * @return the covariance matrix.
      * @throws org.apache.commons.math3.linear.SingularMatrixException
      * if the covariance matrix cannot be computed (singular problem).
+     * @deprecated As of 3.1. Please use {@link #computeCovariances(double[],double)}
+     * instead.
      */
+    @Deprecated
     public double[][] getCovariances(double threshold) {
-        // Set up the jacobian.
-        updateJacobian();
+        return computeCovariances(point, threshold);
+    }
 
-        // Compute transpose(J)J, without building intermediate matrices.
-        double[][] jTj = new double[cols][cols];
-        for (int i = 0; i < cols; ++i) {
-            for (int j = i; j < cols; ++j) {
-                double sum = 0;
-                for (int k = 0; k < rows; ++k) {
-                    sum += weightedResidualJacobian[k][i] * weightedResidualJacobian[k][j];
-                }
-                jTj[i][j] = sum;
-                jTj[j][i] = sum;
-            }
-        }
+    /**
+     * Get the covariance matrix of the optimized parameters.
+     * <br/>
+     * Note that this operation involves the inversion of the
+     * <code>J<sup>T</sup>J</code> matrix, where {@code J} is the
+     * Jacobian matrix.
+     * The {@code threshold} parameter is a way for the caller to specify
+     * that the result of this computation should be considered meaningless,
+     * and thus trigger an exception.
+     *
+     * @param params Model parameters.
+     * @param threshold Singularity threshold.
+     * @return the covariance matrix.
+     * @throws org.apache.commons.math3.linear.SingularMatrixException
+     * if the covariance matrix cannot be computed (singular problem).
+     * @since 3.1
+     */
+    public double[][] computeCovariances(double[] params,
+                                         double threshold) {
+        // Set up the Jacobian.
+        final RealMatrix j = computeWeightedJacobian(params);
+
+        // Compute transpose(J)J.
+        final RealMatrix jTj = j.transpose().multiply(j);
 
         // Compute the covariances matrix.
         final DecompositionSolver solver
-            = new QRDecomposition(MatrixUtils.createRealMatrix(jTj), threshold).getSolver();
+            = new QRDecomposition(jTj, threshold).getSolver();
         return solver.getInverse().getData();
     }
 
@@ -270,9 +362,9 @@
      * @throws NumberIsTooSmallException if the number of degrees of freedom is not
      * positive, i.e. the number of measurements is less or equal to the number of
      * parameters.
-     * @deprecated as of version 3.1, {@link #getSigma()} should be used
-     * instead. It should be emphasized that {@link #guessParametersErrors()} and
-     * {@link #getSigma()} are <em>not</em> strictly equivalent.
+     * @deprecated as of version 3.1, {@link #computeSigma(double[],double)} should be used
+     * instead. It should be emphasized that {@code guessParametersErrors} and
+     * {@code computeSigma} are <em>not</em> strictly equivalent.
      */
     @Deprecated
     public double[] guessParametersErrors() {
@@ -282,7 +374,7 @@
         }
         double[] errors = new double[cols];
         final double c = FastMath.sqrt(getChiSquare() / (rows - cols));
-        double[][] covar = getCovariances();
+        double[][] covar = computeCovariances(point, 1e-14);
         for (int i = 0; i < errors.length; ++i) {
             errors[i] = FastMath.sqrt(covar[i][i]) * c;
         }
@@ -290,22 +382,26 @@
     }
 
     /**
-     * <p>
-     * Returns an estimate of the standard deviation of the parameters. The
+     * Computes an estimate of the standard deviation of the parameters. The
      * returned values are the square root of the diagonal coefficients of the
      * covariance matrix, {@code sd(a[i]) ~= sqrt(C[i][i])}, where {@code a[i]}
      * is the optimized value of the {@code i}-th parameter, and {@code C} is
      * the covariance matrix.
-     * </p>
      *
+     * @param params Model parameters.
+     * @param covarianceSingularityThreshold Singularity threshold (see
+     * {@link #computeCovariances(double[],double) computeCovariances}).
      * @return an estimate of the standard deviation of the optimized parameters
      * @throws org.apache.commons.math3.linear.SingularMatrixException
      * if the covariance matrix cannot be computed.
+     * @since 3.1
      */
-    public double[] getSigma() {
-        final double[] sig = new double[cols];
-        final double[][] cov = getCovariances();
-        for (int i = 0; i < sig.length; ++i) {
+    public double[] computeSigma(double[] params,
+                                 double covarianceSingularityThreshold) {
+        final int nC = params.length;
+        final double[] sig = new double[nC];
+        final double[][] cov = computeCovariances(params, covarianceSingularityThreshold);
+        for (int i = 0; i < nC; ++i) {
             sig[i] = FastMath.sqrt(cov[i][i]);
         }
         return sig;
@@ -381,14 +477,16 @@
      * </ul>
      * @return the point/value pair giving the optimal value of the objective
      * function.
-     * @throws TooManyEvaluationsException if the maximal number of
-     * evaluations is exceeded.
+     * @throws org.apache.commons.math3.exception.TooManyEvaluationsException if
+     * the maximal number of evaluations is exceeded.
      * @throws DimensionMismatchException if the target, and weight arguments
      * have inconsistent dimensions.
      * @see BaseAbstractMultivariateVectorOptimizer#optimizeInternal(int,MultivariateVectorFunction,OptimizationData[])
-     *
      * @since 3.1
+     * @deprecated As of 3.1. Override is necessary only until this class's generic
+     * argument is changed to {@code MultivariateDifferentiableVectorFunction}.
      */
+    @Deprecated
     protected PointVectorValuePair optimizeInternal(final int maxEval,
                                                     final MultivariateDifferentiableVectorFunction f,
                                                     OptimizationData... optData) {
@@ -405,6 +503,9 @@
         // Reset counter.
         jacobianEvaluations = 0;
 
+        // Square-root of the weight matrix.
+        weightMatrixSqrt = squareRoot(getWeight());
+
         // Store least squares problem characteristics.
         // XXX The conversion won't be necessary when the generic argument of
         // the base class becomes "MultivariateDifferentiableVectorFunction".
@@ -413,14 +514,51 @@
         // every time it is used.
         jF = FunctionUtils.toMultivariateDifferentiableVectorFunction((DifferentiableMultivariateVectorFunction) getObjectiveFunction());
 
-        // Arrays shared with the other private methods.
+        // Arrays shared with "private" and "protected" methods.
         point = getStartPoint();
         rows = getTarget().length;
         cols = point.length;
+    }
 
-        weightedResidualJacobian = new double[rows][cols];
-        this.weightedResiduals = new double[rows];
+    /**
+     * Computes the residuals.
+     * The residual is the difference between the observed (target)
+     * values and the model (objective function) value.
+     * There is one residual for each element of the vector-valued
+     * function.
+     *
+     * @param objectiveValue Value of the the objective function. This is
+     * the value returned from a call to
+     * {@link #computeObjectiveValue(double[]) computeObjectiveValue}
+     * (whose array argument contains the model parameters).
+     * @return the residuals.
+     * @throws DimensionMismatchException if {@code params} has a wrong
+     * length.
+     * @since 3.1
+     */
+    protected double[] computeResiduals(double[] objectiveValue) {
+        final double[] target = getTarget();
+        if (objectiveValue.length != target.length) {
+            throw new DimensionMismatchException(target.length,
+                                                 objectiveValue.length);
+        }
+
+        final double[] residuals = new double[target.length];
+        for (int i = 0; i < target.length; i++) {
+            residuals[i] = target[i] - objectiveValue[i];
+        }
 
-        cost = Double.POSITIVE_INFINITY;
+        return residuals;
+    }
+
+    /**
+     * Computes the square-root of the weight matrix.
+     *
+     * @param m Symmetric, positive-definite (weight) matrix.
+     * @return the square-root of the weight matrix.
+     */
+    private RealMatrix squareRoot(RealMatrix m) {
+        final EigenDecomposition dec = new EigenDecomposition(m);
+        return dec.getSquareRoot();
     }
 }
diff -r -u original/src/test/java/org/apache/commons/math3/optimization/fitting/PolynomialFitterTest.java buggy/src/test/java/org/apache/commons/math3/optimization/fitting/PolynomialFitterTest.java
--- original/src/test/java/org/apache/commons/math3/optimization/fitting/PolynomialFitterTest.java	2023-06-13 15:31:52.047143686 +0800
+++ buggy/src/test/java/org/apache/commons/math3/optimization/fitting/PolynomialFitterTest.java	2023-06-12 11:40:40.454080298 +0800
@@ -138,11 +138,28 @@
         final double[] init = new double[] { 0, 0 };
         final int maxEval = 10000; // Trying hard to fit.
 
+        final double[] gn = doMath798(new GaussNewtonOptimizer(checker), maxEval, init);
+    }
+
+    /**
+     * This test shows that the user can set the maximum number of iterations
+     * to avoid running for too long.
+     * Even if the real problem is that the tolerance is way too stringent, it
+     * is possible to get the best solution so far, i.e. a checker will return
+     * the point when the maximum iteration count has been reached.
+     */
+    @Test
+    public void testMath798WithToleranceTooLowButNoException() {
+        final double tol = 1e-100;
+        final double[] init = new double[] { 0, 0 };
+        final int maxEval = 10000; // Trying hard to fit.
+        final SimpleVectorValueChecker checker = new SimpleVectorValueChecker(tol, tol, maxEval);
+
         final double[] lm = doMath798(new LevenbergMarquardtOptimizer(checker), maxEval, init);
         final double[] gn = doMath798(new GaussNewtonOptimizer(checker), maxEval, init);
 
         for (int i = 0; i <= 1; i++) {
-            Assert.assertEquals(lm[i], gn[i], tol);
+            Assert.assertEquals(lm[i], gn[i], 1e-15);
         }
     }
 
